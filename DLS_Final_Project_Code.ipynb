{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d79446f7-87f1-47b6-a176-ea6810e68334",
      "metadata": {
        "id": "d79446f7-87f1-47b6-a176-ea6810e68334"
      },
      "source": [
        "# Comparative OCR Experiments on the Bentham Dataset\n",
        "\n",
        "This notebook documents an academic assignment in which we design and evaluate three different OCR/HTR approaches on the Bentham collection of English manuscripts:\n",
        "\n",
        "1. A **PyTorch baseline** CRNN model trained from scratch.\n",
        "2. A **Transformer-based TrOCR model** fine-tuned on Bentham line images.\n",
        "3. A **Kraken CNN–RNN–CTC model** trained with the `ketos` tool.\n",
        "\n",
        "The goal is to build a reproducible experimental pipeline, compare the behaviour of these models under similar conditions, and reflect on their strengths and weaknesses for historical English handwriting.\n",
        "\n",
        "The experiments are run in Google Colab, using data stored on Google Drive.  \n",
        "All code cells are executable; markdown cells provide the methodological and academic commentary needed for formal submission.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f8d257a-3f5a-4090-98fd-43b6b86dc761",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7f8d257a-3f5a-4090-98fd-43b6b86dc761",
        "outputId": "e94697fc-1903-4bea-d127-eae75f4e9f54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c6c4f3d-a768-4110-9b7c-b971d3757975",
      "metadata": {
        "id": "7c6c4f3d-a768-4110-9b7c-b971d3757975"
      },
      "source": [
        "## 1. Data Access and Environment Setup\n",
        "\n",
        "The Bentham dataset used in this assignment is distributed via Zenodo.  \n",
        "After downloading the archive into Google Drive, we mount the drive in Colab and unzip the data into a working directory.\n",
        "\n",
        "The next code cell performs the one-time mounting step; subsequent cells assume that the Bentham directory is available under the configured path in Drive.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "C9zR4HfWYCAB",
      "metadata": {
        "id": "C9zR4HfWYCAB"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import tarfile\n",
        "from pathlib import Path\n",
        "\n",
        "# 1. Point this to where Bentham.zip actually is on your Drive / machine\n",
        "# Example for Google Colab after mounting Drive:\n",
        "# zip_path = Path(\"/content/drive/MyDrive/Bentham.zip\")\n",
        "zip_path = Path(\"/content/drive/MyDrive/Bentham.zip\")   # change this if needed\n",
        "\n",
        "# 2. Create a directory where the zip will be extracted\n",
        "data_root = zip_path.with_suffix('')  # e.g. Bentham.zip -> Bentham\n",
        "data_root.mkdir(exist_ok=True)\n",
        "\n",
        "# 3. Extract the ZIP so the .tbz files exist as real files\n",
        "print(f\"Unzipping {zip_path} to {data_root}\")\n",
        "with zipfile.ZipFile(zip_path, \"r\") as zf:\n",
        "    zf.extractall(data_root)\n",
        "\n",
        "# 4. Now extract the .tbz archives inside that folder\n",
        "for fname in [\"BenthamDatasetR0-GT.tbz\", \"BenthamDatasetR0-Images.tbz\"]:\n",
        "    fpath = data_root / fname\n",
        "    print(\"Extracting\", fpath)\n",
        "    with tarfile.open(fpath, \"r:bz2\") as tar:\n",
        "        # For untrusted archives, you'd want a safer extractor than extractall\n",
        "        tar.extractall(path=data_root)\n",
        "\n",
        "print(\"Done.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0890efb-74b5-4994-8606-7cfb6ee62be9",
      "metadata": {
        "id": "d0890efb-74b5-4994-8606-7cfb6ee62be9"
      },
      "source": [
        "## 2. Dataset Structure and Inspection\n",
        "\n",
        "Before training any model, we inspect the structure of the Bentham data on disk:\n",
        "\n",
        "- top-level directories containing page images, line images and ground-truth transcriptions,\n",
        "- file name conventions linking images to transcriptions,\n",
        "- the overall size of the collection.\n",
        "\n",
        "This exploratory step ensures that we correctly identify the line-level image files and their corresponding text files, which are required by all three OCR pipelines.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11b67a9e-19e8-4c2f-ae51-890483bf59da",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11b67a9e-19e8-4c2f-ae51-890483bf59da",
        "outputId": "9ade74b0-d703-4686-8dcf-4399eb4fd81b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-Images\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/Partitions\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/Images\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/Transcriptions\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-Images/Images\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/Images/Lines\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/Images/Pages\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-Images/Images/Pages\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "root = Path(r\"/content/drive/MyDrive/Bentham\")\n",
        "\n",
        "for p in root.rglob(\"*\"):\n",
        "    if p.is_dir():\n",
        "        print(p)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3dffec32-28e1-4dde-a448-a51f4b8978c7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "3dffec32-28e1-4dde-a448-a51f4b8978c7",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "ca28a2f8-a302-4bbb-c087-ba2224bd3be9",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "         072_169_002_04_10.txt\n",
            "         073_071_004_01_02.txt\n",
            "         071_140_001_01_01.txt\n",
            "         071_183_004_04_04.txt\n",
            "         115_108_003_01_14.txt\n",
            "         096_008_004_01_06.txt\n",
            "         115_112_003_02_20.txt\n",
            "         072_048_003_04_13.txt\n",
            "         072_049_004_04_04.txt\n",
            "         071_130_003_02_01.txt\n",
            "         115_008_001_02_05.txt\n",
            "         115_111_003_02_01.txt\n",
            "         096_051_002_03_18.txt\n",
            "         115_084_002_02_07.txt\n",
            "         116_294_001_02_01.txt\n",
            "         071_184_001_04_06.txt\n",
            "         115_075_004_02_25.txt\n",
            "         116_279_002_01_01.txt\n",
            "         115_008_001_02_04.txt\n",
            "         116_639_002_02_02.txt\n",
            "         115_072_003_02_22.txt\n",
            "         116_072_001_02_26.txt\n",
            "         115_107_002_01_02.txt\n",
            "         096_053_004_03_15.txt\n",
            "         116_627_001_03_17.txt\n",
            "         115_078_002_02_08.txt\n",
            "         115_016_003_01_06.txt\n",
            "         071_165_003_05_01.txt\n",
            "         071_182_001_05_07.txt\n",
            "         115_086_004_02_07.txt\n",
            "         116_291_001_04_14.txt\n",
            "         116_068_001_02_31.txt\n",
            "         071_181_003_02_01.txt\n",
            "         115_077_002_02_24.txt\n",
            "         115_077_001_02_23.txt\n",
            "         096_028_001_01_04.txt\n",
            "         096_021_003_02_02.txt\n",
            "         116_392_001_04_07.txt\n",
            "         115_073_002_02_17.txt\n",
            "         071_054_001_03_02.txt\n",
            "         071_185_001_04_05.txt\n",
            "         071_184_001_04_01.txt\n",
            "         115_016_001_01_10.txt\n",
            "         115_087_004_02_17.txt\n",
            "         115_010_002_02_12.txt\n",
            "         096_051_004_03_05.txt\n",
            "         071_131_004_05_03.txt\n",
            "         115_080_004_02_18.txt\n",
            "         071_018_002_05_08.txt\n",
            "         115_009_001_03_16.txt\n",
            "         115_072_003_02_06.txt\n",
            "         115_082_004_02_30.txt\n",
            "         116_627_002_03_16.txt\n",
            "         073_067_001_03_18.txt\n",
            "         115_010_002_02_01.txt\n",
            "         115_065_003_02_11.txt\n",
            "         072_169_002_04_13.txt\n",
            "         073_071_003_03_07.txt\n",
            "         115_111_004_02_02.txt\n",
            "         096_052_002_03_19.txt\n",
            "         096_053_004_03_24.txt\n",
            "         115_075_003_02_14.txt\n",
            "         071_044_003_04_20.txt\n",
            "         072_210_004_04_17.txt\n",
            "         071_192_004_04_09.txt\n",
            "         071_054_002_02_01.txt\n",
            "         071_185_002_04_10.txt\n",
            "         116_387_001_01_22.txt\n",
            "         071_002_002_04_03.txt\n",
            "         116_616_001_03_17.txt\n",
            "         116_630_002_01_01.txt\n",
            "         071_168_004_05_17.txt\n",
            "         071_002_003_04_05.txt\n",
            "         115_111_004_02_01.txt\n",
            "         071_032_002_04_18.txt\n",
            "         115_082_004_02_02.txt\n",
            "         071_168_003_05_05.txt\n",
            "         115_067_004_02_32.txt\n",
            "         072_105_001_04_17.txt\n",
            "         071_163_003_04_15.txt\n",
            "         071_112_001_04_09.txt\n",
            "         071_182_004_05_03.txt\n",
            "         071_202_001_03_01.txt\n",
            "         071_130_003_04_02.txt\n",
            "         116_648_001_02_01.txt\n",
            "         115_112_001_02_17.txt\n",
            "         072_210_001_04_20.txt\n",
            "         096_052_003_02_19.txt\n",
            "         116_074_001_02_12.txt\n",
            "         071_159_003_03_01.txt\n",
            "         115_080_003_02_20.txt\n",
            "         116_287_002_02_12.txt\n",
            "         071_163_002_03_01.txt\n",
            "         116_100_001_01_02.txt\n",
            "         115_088_001_02_04.txt\n",
            "         115_080_003_02_23.txt\n",
            "         115_082_003_02_10.txt\n",
            "         072_168_001_04_04.txt\n",
            "         072_167_003_04_05.txt\n",
            "         096_021_003_02_03.txt\n",
            "         071_167_001_04_04.txt\n",
            "         071_008_004_03_08.txt\n",
            "         096_051_002_03_03.txt\n",
            "         115_102_001_02_09.txt\n",
            "         072_168_001_04_08.txt\n",
            "         116_275_001_03_03.txt\n",
            "         115_112_002_02_11.txt\n",
            "         072_102_004_04_02.txt\n",
            "         071_018_002_02_01.txt\n",
            "         096_100_003_01_12.txt\n",
            "         071_185_002_03_01.txt\n",
            "         116_405_001_01_28.txt\n",
            "         072_101_003_01_01.txt\n",
            "         071_102_002_04_03.txt\n",
            "         096_100_001_02_24.txt\n",
            "         071_169_002_05_09.txt\n",
            "         071_008_004_03_07.txt\n",
            "         115_007_004_01_01.txt\n",
            "         115_085_004_02_27.txt\n",
            "         071_157_001_04_18.txt\n",
            "         116_072_001_01_01.txt\n",
            "         071_157_002_04_02.txt\n",
            "         096_002_003_02_14.txt\n",
            "         072_167_002_05_16.txt\n",
            "         071_162_001_04_13.txt\n",
            "         073_071_002_01_03.txt\n",
            "         116_643_002_02_28.txt\n",
            "         071_139_004_04_17.txt\n",
            "         115_084_001_02_01.txt\n",
            "         071_112_001_05_01.txt\n",
            "         116_300_002_02_05.txt\n",
            "         035_325_001_02_14.txt\n",
            "         072_049_004_04_16.txt\n",
            "         073_072_002_02_01.txt\n",
            "         116_607_001_03_01.txt\n",
            "         071_185_003_05_06.txt\n",
            "         071_010_002_04_12.txt\n",
            "         071_107_001_04_12.txt\n",
            "         072_210_001_04_18.txt\n",
            "         116_405_003_01_01.txt\n",
            "         072_094_003_04_21.txt\n",
            "         115_110_001_03_09.txt\n",
            "         071_192_002_04_03.txt\n",
            "         115_012_001_01_08.txt\n",
            "         072_095_001_04_08.txt\n",
            "         035_322_001_02_16.txt\n",
            "         071_182_002_04_05.txt\n",
            "         116_063_001_02_11.txt\n",
            "         116_607_001_03_25.txt\n",
            "         071_107_001_04_14.txt\n",
            "         073_002_002_01_14.txt\n",
            "         073_071_002_01_12.txt\n",
            "         073_003_001_02_17.txt\n",
            "         116_064_001_02_05.txt\n",
            "         116_616_001_02_01.txt\n",
            "         096_051_002_03_20.txt\n",
            "         071_043_003_04_24.txt\n",
            "         071_146_002_04_05.txt\n",
            "         116_643_001_02_05.txt\n",
            "         073_073_003_01_01.txt\n",
            "         071_169_001_05_03.txt\n",
            "         096_051_004_03_16.txt\n",
            "         072_051_003_04_19.txt\n",
            "         072_072_001_04_22.txt\n",
            "         115_101_003_02_25.txt\n",
            "         116_405_004_01_09.txt\n",
            "         071_159_001_04_04.txt\n",
            "         116_067_001_02_17.txt\n",
            "         096_100_001_02_17.txt\n",
            "         073_071_003_03_06.txt\n",
            "         116_639_001_02_07.txt\n",
            "         096_052_001_02_01.txt\n",
            "         071_003_003_04_22.txt\n",
            "         072_051_003_04_16.txt\n",
            "         071_117_002_05_13.txt\n",
            "         096_039_001_01_10.txt\n",
            "         071_132_001_04_13.txt\n",
            "         071_128_001_05_21.txt\n",
            "         071_109_001_02_01.txt\n",
            "         116_607_001_03_26.txt\n",
            "         096_032_004_02_08.txt\n",
            "         116_627_001_03_23.txt\n",
            "         072_103_004_04_03.txt\n",
            "         115_007_004_02_12.txt\n",
            "         096_118_001_01_10.txt\n",
            "         071_008_004_03_26.txt\n",
            "         115_070_002_02_16.txt\n",
            "         071_102_001_04_04.txt\n",
            "         072_050_001_04_14.txt\n",
            "         115_082_003_02_06.txt\n",
            "         071_112_003_02_01.txt\n",
            "         071_059_003_04_15.txt\n",
            "         071_146_003_04_02.txt\n",
            "         116_100_001_01_08.txt\n",
            "         116_063_001_02_17.txt\n",
            "         096_002_002_01_15.txt\n",
            "         071_139_003_04_03.txt\n",
            "         071_166_001_04_19.txt\n",
            "         035_325_001_02_15.txt\n",
            "         116_631_001_02_17.txt\n",
            "         116_067_001_02_20.txt\n",
            "         072_099_001_03_01.txt\n",
            "         071_169_001_03_01.txt\n",
            "         071_192_002_04_08.txt\n",
            "         072_031_001_03_19.txt\n",
            "         115_077_003_02_02.txt\n",
            "         072_048_003_04_10.txt\n",
            "         116_617_001_03_09.txt\n",
            "         116_616_001_04_04.txt\n",
            "         071_166_001_04_09.txt\n",
            "         115_080_002_02_14.txt\n",
            "         071_108_002_04_14.txt\n",
            "         072_072_001_04_08.txt\n",
            "         035_321_001_02_17.txt\n",
            "         073_055_001_03_06.txt\n",
            "         096_098_003_01_17.txt\n",
            "         072_102_002_04_01.txt\n",
            "         115_082_003_02_07.txt\n",
            "         071_102_002_05_06.txt\n",
            "         116_135_001_02_29.txt\n",
            "         115_087_003_02_15.txt\n",
            "         115_009_001_03_13.txt\n",
            "         073_031_001_02_01.txt\n",
            "         115_082_002_02_23.txt\n",
            "         071_168_004_05_11.txt\n",
            "         071_157_001_04_05.txt\n",
            "         071_002_003_04_12.txt\n",
            "         071_163_003_04_09.txt\n",
            "         116_636_002_02_23.txt\n",
            "         071_108_001_04_01.txt\n",
            "         072_210_004_04_13.txt\n",
            "         115_012_001_01_23.txt\n",
            "         115_065_001_02_28.txt\n",
            "         096_101_001_02_09.txt\n",
            "         071_180_003_05_14.txt\n",
            "         072_103_001_05_01.txt\n",
            "         115_009_002_02_18.txt\n",
            "         115_011_001_02_33.txt\n",
            "         115_101_003_02_13.txt\n",
            "         071_042_002_02_01.txt\n",
            "         116_066_001_02_12.txt\n",
            "         115_084_003_02_23.txt\n",
            "         115_107_001_01_06.txt\n",
            "         115_010_002_02_13.txt\n",
            "         115_078_001_02_07.txt\n",
            "         115_085_004_02_25.txt\n",
            "         116_636_002_02_08.txt\n",
            "         073_072_002_03_06.txt\n",
            "         116_405_001_01_24.txt\n",
            "         096_051_002_02_01.txt\n",
            "         116_633_002_02_03.txt\n",
            "         071_169_001_05_08.txt\n",
            "         116_064_001_01_01.txt\n",
            "         116_631_001_02_23.txt\n",
            "         115_085_004_02_15.txt\n",
            "         073_072_003_01_08.txt\n",
            "         115_011_001_02_08.txt\n",
            "         096_028_001_01_05.txt\n",
            "         116_066_001_02_02.txt\n",
            "         116_617_001_03_23.txt\n",
            "         071_021_002_01_01.txt\n",
            "         115_108_003_01_13.txt\n",
            "         116_291_001_04_09.txt\n",
            "         116_288_001_03_10.txt\n",
            "         071_151_003_04_11.txt\n",
            "         073_057_002_01_10.txt\n",
            "         116_616_001_03_03.txt\n",
            "         071_043_003_04_17.txt\n",
            "         096_039_001_01_08.txt\n",
            "         115_007_003_02_22.txt\n",
            "         115_010_001_02_22.txt\n",
            "         115_077_003_02_16.txt\n",
            "         071_141_003_04_19.txt\n",
            "         116_303_002_02_23.txt\n",
            "         071_010_002_04_08.txt\n",
            "         071_146_002_04_06.txt\n",
            "         071_185_003_04_10.txt\n",
            "         116_300_002_02_19.txt\n",
            "         116_055_001_02_29.txt\n",
            "         115_069_001_02_06.txt\n",
            "         097_186_001_01_28.txt\n",
            "         096_032_004_02_09.txt\n",
            "         071_144_002_04_06.txt\n",
            "         071_163_002_04_03.txt\n",
            "         115_011_002_02_22.txt\n",
            "         071_159_002_04_21.txt\n",
            "         035_320_001_02_19.txt\n",
            "         096_038_003_01_10.txt\n",
            "         072_052_002_04_21.txt\n",
            "         071_151_003_04_06.txt\n",
            "         115_011_001_02_22.txt\n",
            "         071_157_002_04_15.txt\n",
            "         072_094_004_04_21.txt\n",
            "         071_108_001_02_01.txt\n",
            "         115_086_004_02_13.txt\n",
            "         116_639_001_02_03.txt\n",
            "         071_165_001_04_04.txt\n",
            "         071_102_003_05_12.txt\n",
            "         116_617_001_03_20.txt\n",
            "         116_291_001_04_04.txt\n",
            "         072_100_001_02_01.txt\n",
            "         071_105_003_04_07.txt\n",
            "         115_072_001_01_01.txt\n",
            "         115_065_002_02_02.txt\n",
            "         071_157_002_04_10.txt\n",
            "         096_021_003_02_10.txt\n",
            "         071_018_003_04_02.txt\n",
            "         116_405_001_01_10.txt\n",
            "         071_181_001_04_10.txt\n",
            "         073_003_001_02_01.txt\n",
            "         115_108_002_01_03.txt\n",
            "         115_010_002_02_14.txt\n",
            "         116_643_002_02_07.txt\n",
            "         116_625_001_02_14.txt\n",
            "         115_086_003_02_24.txt\n",
            "         116_648_001_03_02.txt\n",
            "         071_164_001_04_16.txt\n",
            "         071_120_001_05_19.txt\n",
            "         116_627_002_01_01.txt\n",
            "         116_275_001_03_15.txt\n",
            "         115_084_002_02_08.txt\n",
            "         072_095_001_04_19.txt\n",
            "         072_052_002_04_06.txt\n",
            "         072_094_003_04_10.txt\n",
            "         115_101_002_01_16.txt\n",
            "         116_073_001_02_27.txt\n",
            "         115_065_004_02_05.txt\n",
            "         035_323_001_03_09.txt\n",
            "         071_018_003_04_24.txt\n",
            "         071_182_001_05_09.txt\n",
            "         071_163_002_01_01.txt\n",
            "         115_067_004_02_15.txt\n",
            "         071_054_001_03_04.txt\n",
            "         071_181_001_01_01.txt\n",
            "         071_159_001_04_03.txt\n",
            "         115_072_001_02_12.txt\n",
            "         115_080_002_02_09.txt\n",
            "         071_010_003_04_20.txt\n",
            "         072_095_001_04_17.txt\n",
            "         071_146_001_02_01.txt\n",
            "         071_180_003_05_17.txt\n",
            "         072_102_003_04_13.txt\n",
            "         116_303_002_02_19.txt\n",
            "         115_086_001_02_03.txt\n",
            "         116_618_001_03_09.txt\n",
            "         116_279_001_03_18.txt\n",
            "         072_101_003_04_14.txt\n",
            "         071_003_004_04_02.txt\n",
            "         071_018_003_04_25.txt\n",
            "         073_053_001_03_14.txt\n",
            "         071_181_003_04_08.txt\n",
            "         115_007_002_01_12.txt\n",
            "         116_642_002_02_03.txt\n",
            "         115_009_002_02_24.txt\n",
            "         072_032_002_04_06.txt\n",
            "         115_016_003_01_01.txt\n",
            "         116_067_001_02_32.txt\n",
            "         072_168_003_04_15.txt\n",
            "         071_168_003_03_01.txt\n",
            "         071_030_001_04_32.txt\n",
            "         116_078_001_02_17.txt\n",
            "         115_108_003_01_11.txt\n",
            "         071_107_001_04_06.txt\n",
            "         116_078_001_02_16.txt\n",
            "         115_112_002_02_13.txt\n",
            "         073_067_001_03_25.txt\n",
            "         096_034_004_01_16.txt\n",
            "         072_070_002_06_04.txt\n",
            "         073_053_001_03_20.txt\n",
            "         096_100_002_01_05.txt\n",
            "         071_010_003_04_10.txt\n",
            "         115_107_001_01_18.txt\n",
            "         116_100_001_01_01.txt\n",
            "         115_078_002_02_26.txt\n",
            "         115_070_001_02_24.txt\n",
            "         071_008_004_02_01.txt\n",
            "         072_102_002_05_04.txt\n",
            "         071_167_002_04_08.txt\n",
            "         035_323_001_03_06.txt\n",
            "         116_643_001_02_25.txt\n",
            "         096_008_004_01_11.txt\n",
            "         116_633_001_02_18.txt\n",
            "         071_102_001_04_10.txt\n",
            "         115_016_001_01_08.txt\n",
            "         072_212_001_04_01.txt\n",
            "         035_327_001_02_13.txt\n",
            "         071_185_003_05_04.txt\n",
            "         071_101_002_04_04.txt\n",
            "         072_105_002_04_03.txt\n",
            "         072_032_002_04_05.txt\n",
            "         073_068_001_02_01.txt\n",
            "         072_032_002_04_03.txt\n",
            "         116_639_001_02_02.txt\n",
            "         115_009_003_02_01.txt\n",
            "         071_042_001_03_01.txt\n",
            "         116_290_001_04_12.txt\n",
            "         071_168_003_05_17.txt\n",
            "         073_054_001_03_16.txt\n",
            "         071_112_001_04_02.txt\n",
            "         072_066_003_04_20.txt\n",
            "         073_069_001_03_13.txt\n",
            "         115_069_001_02_16.txt\n",
            "         071_131_004_04_05.txt\n",
            "         115_007_004_02_08.txt\n",
            "         072_070_002_04_05.txt\n",
            "         096_002_003_02_04.txt\n",
            "         115_011_002_02_12.txt\n",
            "         035_325_001_02_18.txt\n",
            "         115_111_002_02_11.txt\n",
            "         115_073_002_02_32.txt\n",
            "         072_094_003_04_24.txt\n",
            "         072_100_003_04_09.txt\n",
            "         115_108_003_01_20.txt\n",
            "         071_059_003_04_07.txt\n",
            "         072_036_002_04_07.txt\n",
            "         115_086_004_02_06.txt\n",
            "         116_290_001_04_19.txt\n",
            "         071_128_003_04_18.txt\n",
            "         096_039_001_01_03.txt\n",
            "         071_190_002_04_02.txt\n",
            "         115_110_004_02_01.txt\n",
            "         071_164_002_04_02.txt\n",
            "         115_065_001_02_06.txt\n",
            "         071_146_001_04_03.txt\n",
            "         115_082_001_02_08.txt\n",
            "         071_184_003_04_08.txt\n",
            "         071_181_002_04_08.txt\n",
            "         096_017_003_02_08.txt\n",
            "         071_003_003_04_01.txt\n",
            "         072_049_004_04_06.txt\n",
            "         116_300_002_02_15.txt\n",
            "         116_078_001_01_01.txt\n",
            "         115_011_002_02_23.txt\n",
            "         072_069_002_04_13.txt\n",
            "         115_073_001_01_01.txt\n",
            "         071_022_003_04_02.txt\n",
            "         071_102_001_04_01.txt\n",
            "         115_101_004_02_28.txt\n",
            "         071_184_003_04_16.txt\n",
            "         073_003_001_02_23.txt\n",
            "         115_107_001_01_21.txt\n",
            "         072_094_003_04_04.txt\n",
            "         071_183_004_02_01.txt\n",
            "         072_099_001_04_16.txt\n",
            "         072_167_002_04_01.txt\n",
            "         071_111_002_02_01.txt\n",
            "         116_393_003_01_05.txt\n",
            "         116_393_003_01_04.txt\n",
            "         116_400_001_03_29.txt\n",
            "         116_131_001_01_07.txt\n",
            "         116_631_001_02_21.txt\n",
            "         115_007_004_02_23.txt\n",
            "         116_070_001_02_08.txt\n",
            "         115_101_003_02_14.txt\n",
            "         115_070_001_02_26.txt\n",
            "         071_139_003_04_12.txt\n",
            "         071_201_003_04_08.txt\n",
            "         116_631_002_02_05.txt\n",
            "         071_131_002_04_28.txt\n",
            "         071_043_003_03_01.txt\n",
            "         115_102_001_02_07.txt\n",
            "         071_169_002_05_01.txt\n",
            "         072_100_001_04_10.txt\n",
            "         115_067_002_02_18.txt\n",
            "         116_135_001_02_30.txt\n",
            "         096_038_003_01_17.txt\n",
            "         115_087_001_02_21.txt\n",
            "         072_100_003_04_14.txt\n",
            "         073_074_002_03_13.txt\n",
            "         071_120_001_05_16.txt\n",
            "         071_183_004_03_01.txt\n",
            "         072_050_003_04_18.txt\n",
            "         115_073_002_02_23.txt\n",
            "         071_032_002_03_01.txt\n",
            "         116_076_001_02_18.txt\n",
            "         116_294_001_03_17.txt\n",
            "         116_291_001_04_18.txt\n",
            "         116_406_001_01_04.txt\n",
            "         115_110_002_03_03.txt\n",
            "         071_185_004_04_08.txt\n",
            "         027_029_001_02_09.txt\n",
            "         071_102_002_05_08.txt\n",
            "         071_059_003_04_05.txt\n",
            "         073_060_001_01_01.txt\n",
            "         071_102_002_06_02.txt\n",
            "         115_111_003_01_01.txt\n",
            "         035_320_001_02_12.txt\n",
            "         115_086_004_02_08.txt\n",
            "         071_163_004_03_01.txt\n",
            "         115_016_001_01_20.txt\n",
            "         073_070_002_03_12.txt\n",
            "         071_192_004_01_01.txt\n",
            "         116_405_002_01_26.txt\n",
            "         115_008_002_02_02.txt\n",
            "         115_080_001_02_08.txt\n",
            "         071_111_001_04_18.txt\n",
            "         116_406_001_01_15.txt\n",
            "         116_279_002_03_05.txt\n",
            "         096_051_004_03_19.txt\n",
            "         116_294_002_02_19.txt\n",
            "         096_099_003_02_10.txt\n",
            "         073_072_001_03_17.txt\n",
            "         071_112_003_01_01.txt\n",
            "         116_295_001_03_18.txt\n",
            "         115_111_003_02_17.txt\n",
            "         035_323_001_03_20.txt\n",
            "         115_086_004_02_14.txt\n",
            "         071_043_003_04_09.txt\n",
            "         027_029_001_02_04.txt\n",
            "         116_291_001_03_05.txt\n",
            "         071_169_004_04_01.txt\n",
            "         115_111_001_02_06.txt\n",
            "         071_169_001_05_21.txt\n",
            "         035_321_001_02_22.txt\n",
            "         115_086_003_02_14.txt\n",
            "         073_049_002_01_04.txt\n",
            "         116_068_001_02_23.txt\n",
            "         116_301_002_02_14.txt\n",
            "         115_084_001_02_07.txt\n",
            "         115_010_001_02_30.txt\n",
            "         115_101_003_02_15.txt\n",
            "         116_303_002_02_15.txt\n",
            "         096_051_001_02_02.txt\n",
            "         073_050_001_02_09.txt\n",
            "         072_168_001_04_19.txt\n",
            "         116_301_002_02_31.txt\n",
            "         115_076_002_02_21.txt\n",
            "         115_108_001_01_10.txt\n",
            "         073_031_001_04_18.txt\n",
            "         072_104_002_04_20.txt\n",
            "         072_212_001_04_02.txt\n",
            "         115_070_001_02_32.txt\n",
            "         116_131_001_01_15.txt\n",
            "         116_625_001_02_26.txt\n",
            "         116_286_002_02_21.txt\n",
            "         115_067_003_02_18.txt\n",
            "         115_075_003_02_07.txt\n",
            "         073_051_001_03_08.txt\n",
            "         115_007_002_01_10.txt\n",
            "         073_067_001_01_01.txt\n",
            "         071_158_002_04_07.txt\n",
            "         116_072_001_02_16.txt\n",
            "         115_065_001_02_05.txt\n",
            "         116_639_002_02_04.txt\n",
            "         071_186_002_04_10.txt\n",
            "         115_101_004_02_06.txt\n",
            "         071_188_002_03_08.txt\n",
            "         116_068_001_02_10.txt\n",
            "         073_002_002_01_13.txt\n",
            "         116_631_002_02_24.txt\n",
            "         072_032_002_04_04.txt\n",
            "         071_032_001_04_02.txt\n",
            "         072_070_002_06_17.txt\n",
            "         115_080_003_02_24.txt\n",
            "         072_069_002_05_02.txt\n",
            "         115_077_001_02_24.txt\n",
            "         072_069_002_04_05.txt\n",
            "         116_639_002_02_10.txt\n",
            "         071_181_004_04_19.txt\n",
            "         073_067_001_03_05.txt\n",
            "         071_139_003_04_18.txt\n",
            "         115_082_001_02_18.txt\n",
            "         116_616_001_03_05.txt\n",
            "         071_182_001_05_08.txt\n",
            "         072_054_003_03_07.txt\n",
            "         116_100_002_01_05.txt\n",
            "         071_035_002_06_01.txt\n",
            "         072_167_004_04_03.txt\n",
            "         071_192_002_04_20.txt\n",
            "         116_078_001_02_33.txt\n",
            "         115_065_004_02_21.txt\n",
            "         116_633_001_02_20.txt\n",
            "         116_405_001_01_19.txt\n",
            "         116_076_001_02_09.txt\n",
            "         072_048_003_04_05.txt\n",
            "         071_112_003_04_02.txt\n",
            "         035_321_001_02_03.txt\n",
            "         071_101_004_04_08.txt\n",
            "         115_112_002_02_05.txt\n",
            "         073_053_001_03_12.txt\n",
            "         073_073_001_03_09.txt\n",
            "         115_087_002_02_23.txt\n",
            "         096_028_001_01_10.txt\n",
            "         071_157_001_04_07.txt\n",
            "         071_053_004_03_19.txt\n",
            "         071_146_001_05_19.txt\n",
            "         096_098_004_01_02.txt\n",
            "         071_169_004_05_11.txt\n",
            "         071_162_001_02_01.txt\n",
            "         072_049_001_04_19.txt\n",
            "         116_648_001_03_22.txt\n",
            "         071_035_003_05_08.txt\n",
            "         115_076_002_02_18.txt\n",
            "         116_643_001_02_01.txt\n",
            "         071_139_003_03_02.txt\n",
            "         073_052_001_03_06.txt\n",
            "         115_007_002_01_06.txt\n",
            "         115_110_003_02_08.txt\n",
            "         073_051_001_03_03.txt\n",
            "         071_010_002_04_06.txt\n",
            "         116_073_001_02_24.txt\n",
            "         115_107_003_01_01.txt\n",
            "         035_327_001_02_17.txt\n",
            "         073_067_001_03_14.txt\n",
            "         071_085_004_05_01.txt\n",
            "         116_393_003_03_05.txt\n",
            "         071_101_004_04_16.txt\n",
            "         116_275_001_02_01.txt\n",
            "         071_107_001_04_23.txt\n",
            "         072_095_001_01_01.txt\n",
            "         071_184_002_04_07.txt\n",
            "         071_139_003_01_01.txt\n",
            "         116_631_002_02_06.txt\n",
            "         115_084_003_02_12.txt\n",
            "         115_073_001_02_05.txt\n",
            "         071_180_004_04_17.txt\n",
            "         115_009_003_02_02.txt\n",
            "         115_087_004_02_08.txt\n",
            "         071_201_001_04_19.txt\n",
            "         035_328_001_02_07.txt\n",
            "         071_131_002_04_02.txt\n",
            "         096_098_004_01_01.txt\n",
            "         115_065_001_02_11.txt\n",
            "         072_049_001_03_01.txt\n",
            "         072_051_003_04_12.txt\n",
            "         071_165_001_05_01.txt\n",
            "         115_008_001_02_17.txt\n",
            "         096_032_004_02_15.txt\n",
            "         116_405_002_01_06.txt\n",
            "         115_082_001_02_15.txt\n",
            "         071_102_002_05_13.txt\n",
            "         115_016_003_01_14.txt\n",
            "         115_009_002_02_12.txt\n",
            "         072_105_003_04_08.txt\n",
            "         116_617_001_03_22.txt\n",
            "         116_063_001_02_30.txt\n",
            "         115_083_001_02_22.txt\n",
            "         115_016_003_01_09.txt\n",
            "         071_043_004_04_08.txt\n",
            "         073_054_001_03_12.txt\n",
            "         072_066_001_04_18.txt\n",
            "         116_076_001_02_31.txt\n",
            "         096_052_001_02_02.txt\n",
            "         073_052_001_01_01.txt\n",
            "         116_131_001_01_22.txt\n",
            "         071_018_002_05_05.txt\n",
            "         115_007_003_02_21.txt\n",
            "         096_024_001_02_21.txt\n",
            "         115_086_003_02_04.txt\n",
            "         035_324_001_02_16.txt\n",
            "         116_649_001_03_09.txt\n",
            "         071_181_003_04_10.txt\n",
            "         027_029_001_02_26.txt\n",
            "         096_032_004_02_12.txt\n",
            "         071_159_002_04_04.txt\n",
            "         096_051_001_02_07.txt\n",
            "         115_107_002_01_11.txt\n",
            "         115_080_002_02_16.txt\n",
            "         115_110_002_03_06.txt\n",
            "         071_184_002_04_21.txt\n",
            "         115_111_004_02_12.txt\n",
            "         071_182_002_04_11.txt\n",
            "         071_165_003_04_14.txt\n",
            "         071_108_001_04_19.txt\n",
            "         073_073_001_03_19.txt\n",
            "         071_030_001_04_09.txt\n",
            "         071_166_001_04_05.txt\n",
            "         115_065_002_02_25.txt\n",
            "         115_010_001_02_18.txt\n",
            "         115_065_004_02_04.txt\n",
            "         002_112_001_03_07.txt\n",
            "         071_032_001_03_01.txt\n",
            "         071_131_004_05_12.txt\n",
            "         115_087_002_02_02.txt\n",
            "         071_043_004_04_13.txt\n",
            "         071_202_001_04_03.txt\n",
            "         072_036_002_04_16.txt\n",
            "         116_643_002_02_29.txt\n",
            "         115_081_001_03_25.txt\n",
            "         071_182_004_04_09.txt\n",
            "         071_165_001_04_05.txt\n",
            "         116_620_001_03_13.txt\n",
            "         115_088_001_02_02.txt\n",
            "         116_291_001_04_06.txt\n",
            "         071_164_001_04_05.txt\n",
            "         116_275_001_03_06.txt\n",
            "         071_192_004_04_10.txt\n",
            "         072_071_004_04_25.txt\n",
            "         115_101_001_02_15.txt\n",
            "         071_108_002_04_05.txt\n",
            "         072_049_002_04_08.txt\n",
            "         096_052_002_02_01.txt\n",
            "         115_075_001_02_02.txt\n",
            "         071_128_001_05_09.txt\n",
            "         071_181_003_04_11.txt\n",
            "         116_133_001_02_38.txt\n",
            "         002_112_001_03_08.txt\n",
            "         071_109_001_04_01.txt\n",
            "         116_648_001_03_06.txt\n",
            "         116_279_002_03_02.txt\n",
            "         116_135_001_02_24.txt\n",
            "         073_071_001_03_03.txt\n",
            "         116_073_001_02_16.txt\n",
            "         115_065_003_02_35.txt\n",
            "         071_107_002_04_08.txt\n",
            "         071_165_001_05_02.txt\n",
            "         072_031_001_01_01.txt\n",
            "         071_018_003_04_13.txt\n",
            "         096_051_002_03_16.txt\n",
            "         071_167_002_02_01.txt\n",
            "         071_131_004_03_01.txt\n",
            "         073_053_001_01_01.txt\n",
            "         071_053_003_03_09.txt\n",
            "         071_185_002_04_12.txt\n",
            "         115_008_001_02_08.txt\n",
            "         073_070_002_03_14.txt\n",
            "         116_133_001_02_15.txt\n",
            "         071_159_002_04_18.txt\n",
            "         116_074_001_02_42.txt\n",
            "         115_111_001_02_25.txt\n",
            "         116_627_001_03_29.txt\n",
            "         115_102_001_02_17.txt\n",
            "         071_181_002_03_01.txt\n",
            "         115_011_001_02_30.txt\n",
            "         096_118_001_01_08.txt\n",
            "         116_643_001_01_01.txt\n",
            "         096_015_002_02_09.txt\n",
            "         072_102_002_05_06.txt\n",
            "         073_055_001_03_14.txt\n",
            "         073_050_001_01_01.txt\n",
            "         072_054_003_04_04.txt\n",
            "         072_104_002_04_05.txt\n",
            "         115_082_002_02_08.txt\n",
            "         116_627_001_03_26.txt\n",
            "         116_287_001_03_07.txt\n",
            "         073_002_002_01_08.txt\n",
            "         115_110_001_02_05.txt\n",
            "         115_088_001_02_09.txt\n",
            "         071_181_003_04_17.txt\n",
            "         072_072_001_04_05.txt\n",
            "         115_085_004_02_16.txt\n",
            "         116_400_001_03_36.txt\n",
            "         072_066_001_04_14.txt\n",
            "         071_053_003_03_08.txt\n",
            "         116_631_002_02_18.txt\n",
            "         071_185_002_04_04.txt\n",
            "         115_101_002_01_30.txt\n",
            "         072_036_002_04_15.txt\n",
            "         071_184_004_04_01.txt\n",
            "         035_320_001_02_04.txt\n",
            "         115_007_003_02_09.txt\n",
            "         071_010_003_04_12.txt\n",
            "         072_070_002_02_01.txt\n",
            "         072_050_003_04_02.txt\n",
            "         115_075_001_03_13.txt\n",
            "         116_630_002_02_15.txt\n",
            "         071_101_003_03_01.txt\n",
            "         071_042_002_03_01.txt\n",
            "         071_162_002_04_15.txt\n",
            "         115_011_002_02_37.txt\n",
            "         072_167_003_04_06.txt\n",
            "         116_405_002_01_16.txt\n",
            "         072_051_003_04_04.txt\n",
            "         115_007_001_02_06.txt\n",
            "         096_021_003_02_13.txt\n",
            "         115_084_004_02_11.txt\n",
            "         115_065_001_02_13.txt\n",
            "         072_169_002_04_19.txt\n",
            "         072_210_001_04_02.txt\n",
            "         115_011_002_02_33.txt\n",
            "         116_068_001_02_03.txt\n",
            "         116_393_003_03_01.txt\n",
            "         071_053_004_03_22.txt\n",
            "         116_275_001_03_04.txt\n",
            "         071_181_002_04_20.txt\n",
            "         072_051_003_04_20.txt\n",
            "         115_086_003_01_01.txt\n",
            "         115_112_002_02_09.txt\n",
            "         071_146_002_04_07.txt\n",
            "         073_074_002_03_03.txt\n",
            "         071_102_003_05_09.txt\n",
            "         115_085_003_02_23.txt\n",
            "         035_322_001_02_13.txt\n",
            "         097_186_001_01_23.txt\n",
            "         072_103_004_04_18.txt\n",
            "         072_051_003_04_14.txt\n",
            "         071_042_001_04_10.txt\n",
            "         116_643_001_02_04.txt\n",
            "         072_168_001_04_12.txt\n",
            "         096_052_001_02_06.txt\n",
            "         116_100_001_01_34.txt\n",
            "         071_102_003_05_14.txt\n",
            "         115_080_004_02_21.txt\n",
            "         116_287_001_03_31.txt\n",
            "         116_074_001_02_21.txt\n",
            "         115_080_004_02_09.txt\n",
            "         116_286_002_02_18.txt\n",
            "         071_002_002_01_01.txt\n",
            "         071_111_002_04_12.txt\n",
            "         071_102_002_05_09.txt\n",
            "         116_618_001_03_14.txt\n",
            "         072_101_002_04_19.txt\n",
            "         116_055_001_02_18.txt\n",
            "         073_001_003_01_12.txt\n",
            "         115_076_001_02_32.txt\n",
            "         115_073_001_02_25.txt\n",
            "         096_098_003_01_25.txt\n",
            "         116_294_002_02_02.txt\n",
            "         071_163_004_04_03.txt\n",
            "         072_036_002_04_19.txt\n",
            "         072_066_001_04_15.txt\n",
            "         071_183_004_04_02.txt\n",
            "         115_087_001_02_10.txt\n",
            "         073_069_001_03_23.txt\n",
            "         072_094_004_04_01.txt\n",
            "         116_066_001_02_19.txt\n",
            "         071_146_001_04_01.txt\n",
            "         071_105_003_04_18.txt\n",
            "         115_077_002_02_06.txt\n",
            "         115_086_004_02_18.txt\n",
            "         115_067_003_02_12.txt\n",
            "         096_034_004_01_03.txt\n",
            "         071_101_003_04_12.txt\n",
            "         116_393_003_03_06.txt\n",
            "         072_210_004_04_11.txt\n",
            "         115_008_002_02_06.txt\n",
            "         072_049_001_01_01.txt\n",
            "         116_632_002_02_31.txt\n",
            "         116_100_001_01_21.txt\n",
            "         115_101_004_02_20.txt\n",
            "         072_102_004_04_12.txt\n",
            "         116_606_001_03_06.txt\n",
            "         071_183_004_04_14.txt\n",
            "         116_071_001_03_21.txt\n",
            "         071_180_004_04_15.txt\n",
            "         116_405_001_01_25.txt\n",
            "         116_300_002_02_26.txt\n",
            "         115_082_001_02_21.txt\n",
            "         115_108_001_01_04.txt\n",
            "         071_044_003_04_12.txt\n",
            "         002_080_001_03_14.txt\n",
            "         071_157_001_04_19.txt\n",
            "         115_085_003_01_01.txt\n",
            "         071_111_002_04_02.txt\n",
            "         116_288_001_03_12.txt\n",
            "         071_144_002_04_10.txt\n",
            "         072_100_001_04_05.txt\n",
            "         072_102_003_04_07.txt\n",
            "         115_065_002_02_07.txt\n",
            "         071_101_004_04_06.txt\n",
            "         072_066_001_04_17.txt\n",
            "         072_103_001_05_04.txt\n",
            "         115_108_002_01_12.txt\n",
            "         072_031_001_03_08.txt\n",
            "         096_098_003_01_15.txt\n",
            "         115_007_001_02_21.txt\n",
            "         071_002_003_04_06.txt\n",
            "         115_070_001_02_04.txt\n",
            "         071_163_002_04_11.txt\n",
            "         115_084_004_02_21.txt\n",
            "         071_109_001_04_21.txt\n",
            "         115_076_002_02_12.txt\n",
            "         071_030_001_04_20.txt\n",
            "         071_146_002_04_03.txt\n",
            "         071_133_002_04_05.txt\n",
            "         115_010_002_02_09.txt\n",
            "         035_327_001_02_03.txt\n",
            "         116_135_001_02_25.txt\n",
            "         116_606_001_03_04.txt\n",
            "         116_642_001_02_09.txt\n",
            "         115_080_004_02_28.txt\n",
            "         116_641_001_02_09.txt\n",
            "         116_627_002_03_13.txt\n",
            "         073_070_002_03_16.txt\n",
            "         071_169_004_05_14.txt\n",
            "         115_065_004_02_07.txt\n",
            "         073_071_002_01_17.txt\n",
            "         071_141_003_03_01.txt\n",
            "         072_048_003_04_03.txt\n",
            "         072_054_002_03_01.txt\n",
            "         072_054_001_04_18.txt\n",
            "         071_139_004_04_01.txt\n",
            "         002_112_001_03_11.txt\n",
            "         116_649_001_01_01.txt\n",
            "         116_648_001_03_01.txt\n",
            "         096_098_003_01_12.txt\n",
            "         071_101_003_04_05.txt\n",
            "         071_106_002_04_10.txt\n",
            "         073_068_001_03_20.txt\n",
            "         071_146_001_01_01.txt\n",
            "         071_030_001_04_21.txt\n",
            "         072_167_003_01_01.txt\n",
            "         071_164_002_04_10.txt\n",
            "         116_618_001_03_24.txt\n",
            "         116_290_001_03_04.txt\n",
            "         071_165_003_04_01.txt\n",
            "         096_052_002_03_20.txt\n",
            "         115_101_003_02_16.txt\n",
            "         073_071_003_03_14.txt\n",
            "         071_018_002_04_01.txt\n",
            "         071_163_001_04_07.txt\n",
            "         116_405_003_01_05.txt\n",
            "         035_327_001_02_15.txt\n",
            "         115_080_002_02_15.txt\n",
            "         071_131_004_05_20.txt\n",
            "         115_111_001_02_12.txt\n",
            "         116_631_002_02_11.txt\n",
            "         073_053_001_03_22.txt\n",
            "         071_035_002_06_03.txt\n",
            "         002_579_001_02_01.txt\n",
            "         071_167_001_05_11.txt\n",
            "         072_167_003_04_18.txt\n",
            "         116_076_001_02_02.txt\n",
            "         071_043_003_01_01.txt\n",
            "         096_018_002_01_03.txt\n",
            "         116_643_002_02_06.txt\n",
            "         071_186_002_04_17.txt\n",
            "         071_106_002_04_13.txt\n",
            "         071_146_001_05_09.txt\n",
            "         115_072_003_02_08.txt\n",
            "         096_051_002_03_26.txt\n",
            "         071_151_003_04_10.txt\n",
            "         115_078_001_02_12.txt\n",
            "         071_146_003_05_02.txt\n",
            "         116_068_001_02_24.txt\n",
            "         071_131_004_04_04.txt\n",
            "         071_167_001_04_05.txt\n",
            "         072_099_001_04_15.txt\n",
            "         071_054_001_03_12.txt\n",
            "         116_078_001_02_32.txt\n",
            "         071_018_002_05_13.txt\n",
            "         073_061_001_03_23.txt\n",
            "         116_131_001_01_10.txt\n",
            "         115_085_003_02_11.txt\n",
            "         072_047_002_04_18.txt\n",
            "         071_018_003_04_17.txt\n",
            "         115_084_004_02_30.txt\n",
            "         072_070_002_04_11.txt\n",
            "         071_157_002_04_09.txt\n",
            "         073_050_001_02_18.txt\n",
            "         116_055_001_02_02.txt\n",
            "         116_633_001_02_09.txt\n",
            "         116_648_001_03_49.txt\n",
            "         115_075_001_03_17.txt\n",
            "         115_079_001_02_12.txt\n",
            "         115_007_003_02_23.txt\n",
            "         096_008_004_01_02.txt\n",
            "         071_101_004_04_20.txt\n",
            "         115_009_003_02_22.txt\n",
            "         071_181_003_04_21.txt\n",
            "         115_087_003_02_22.txt\n",
            "         071_035_003_02_01.txt\n",
            "         115_081_001_03_17.txt\n",
            "         071_181_004_04_18.txt\n",
            "         071_032_002_04_13.txt\n",
            "         115_011_002_02_14.txt\n",
            "         115_101_002_01_27.txt\n",
            "         071_184_001_04_17.txt\n",
            "         071_146_002_04_15.txt\n",
            "         071_184_003_04_20.txt\n",
            "         116_074_001_02_38.txt\n",
            "         072_102_003_04_12.txt\n",
            "         116_618_001_03_16.txt\n",
            "         116_073_001_02_07.txt\n",
            "         115_108_003_01_16.txt\n",
            "         115_108_001_01_12.txt\n",
            "         116_405_002_01_14.txt\n",
            "         116_616_001_03_16.txt\n",
            "         115_073_001_02_34.txt\n",
            "         002_579_001_02_03.txt\n",
            "         071_169_004_05_17.txt\n",
            "         115_082_004_02_11.txt\n",
            "         115_084_004_02_29.txt\n",
            "         071_168_004_05_02.txt\n",
            "         071_018_002_04_08.txt\n",
            "         072_031_001_03_20.txt\n",
            "         071_168_003_05_02.txt\n",
            "         071_102_003_06_03.txt\n",
            "         116_064_001_02_36.txt\n",
            "         071_018_002_04_02.txt\n",
            "         115_009_002_02_16.txt\n",
            "         071_120_001_04_01.txt\n",
            "         071_182_004_04_07.txt\n",
            "         071_032_002_04_12.txt\n",
            "         115_011_002_02_35.txt\n",
            "         071_186_002_04_15.txt\n",
            "         116_071_001_03_06.txt\n",
            "         071_182_004_04_17.txt\n",
            "         096_052_002_03_07.txt\n",
            "         096_017_003_01_01.txt\n",
            "         027_029_001_02_17.txt\n",
            "         116_136_001_01_09.txt\n",
            "         071_158_002_04_10.txt\n",
            "         116_607_001_03_13.txt\n",
            "         096_052_001_02_09.txt\n",
            "         096_018_002_01_09.txt\n",
            "         115_085_004_02_11.txt\n",
            "         073_002_002_01_06.txt\n",
            "         071_120_001_05_18.txt\n",
            "         071_042_001_04_07.txt\n",
            "         073_074_001_03_07.txt\n",
            "         073_003_001_02_12.txt\n",
            "         116_400_001_03_33.txt\n",
            "         072_103_002_04_06.txt\n",
            "         072_167_002_05_01.txt\n",
            "         071_139_004_04_14.txt\n",
            "         096_015_002_01_07.txt\n",
            "         071_185_001_04_04.txt\n",
            "         115_112_001_02_21.txt\n",
            "         071_018_002_05_09.txt\n",
            "         071_192_004_04_03.txt\n",
            "         116_642_001_02_29.txt\n",
            "         072_210_002_04_09.txt\n",
            "         071_108_002_04_10.txt\n",
            "         073_074_002_03_12.txt\n",
            "         072_167_003_04_08.txt\n",
            "         071_192_002_04_09.txt\n",
            "         116_074_001_02_13.txt\n",
            "         071_167_001_05_06.txt\n",
            "         116_642_002_02_07.txt\n",
            "         072_032_002_04_16.txt\n",
            "         116_643_002_02_22.txt\n",
            "         071_182_001_04_04.txt\n",
            "         115_007_001_02_27.txt\n",
            "         072_167_002_01_01.txt\n",
            "         115_075_003_02_09.txt\n",
            "         072_100_002_04_18.txt\n",
            "         071_103_002_04_03.txt\n",
            "         071_108_001_04_20.txt\n",
            "         071_168_004_05_18.txt\n",
            "         116_290_001_04_13.txt\n",
            "         096_024_001_02_09.txt\n",
            "         116_287_002_02_17.txt\n",
            "         115_087_001_02_02.txt\n",
            "         115_108_002_01_15.txt\n",
            "         115_087_002_02_08.txt\n",
            "         116_643_002_02_19.txt\n",
            "         071_192_002_04_14.txt\n",
            "         115_101_001_02_19.txt\n",
            "         116_064_001_02_02.txt\n",
            "         073_073_003_01_03.txt\n",
            "         071_164_001_04_14.txt\n",
            "         116_068_001_02_12.txt\n",
            "         071_163_004_04_11.txt\n",
            "         071_120_002_02_01.txt\n",
            "         115_107_002_01_25.txt\n",
            "         116_633_002_02_23.txt\n",
            "         115_073_002_02_14.txt\n",
            "         116_286_002_02_24.txt\n",
            "         035_324_001_02_05.txt\n",
            "         097_186_001_01_01.txt\n",
            "         115_086_004_02_25.txt\n",
            "         115_080_004_01_01.txt\n",
            "         071_151_003_04_02.txt\n",
            "         115_077_003_02_18.txt\n",
            "         073_055_001_03_07.txt\n",
            "         115_084_001_02_24.txt\n",
            "         071_141_003_01_01.txt\n",
            "         071_018_003_04_22.txt\n",
            "         115_011_001_01_01.txt\n",
            "         002_080_001_03_03.txt\n",
            "         073_070_001_01_01.txt\n",
            "         072_094_003_04_18.txt\n",
            "         072_102_004_01_01.txt\n",
            "         072_210_004_04_16.txt\n",
            "         116_642_001_02_22.txt\n",
            "         072_100_001_04_14.txt\n",
            "         096_099_003_02_12.txt\n",
            "         073_001_003_01_17.txt\n",
            "         116_071_001_03_19.txt\n",
            "         072_051_003_04_08.txt\n",
            "         116_303_002_02_25.txt\n",
            "         071_182_004_05_01.txt\n",
            "         071_163_002_04_04.txt\n",
            "         071_131_004_05_07.txt\n",
            "         096_052_003_02_16.txt\n",
            "         071_008_004_03_25.txt\n",
            "         097_186_001_01_02.txt\n",
            "         115_085_003_02_09.txt\n",
            "         072_210_004_01_01.txt\n",
            "         071_139_004_04_20.txt\n",
            "         073_083_001_03_22.txt\n",
            "         116_287_001_03_21.txt\n",
            "         071_163_002_04_20.txt\n",
            "         071_167_002_04_09.txt\n",
            "         073_071_001_03_08.txt\n",
            "         115_084_004_02_03.txt\n",
            "         071_159_002_04_05.txt\n",
            "         116_405_002_01_03.txt\n",
            "         035_321_001_02_11.txt\n",
            "         071_156_002_04_03.txt\n",
            "         115_067_002_02_07.txt\n",
            "         115_085_004_02_19.txt\n",
            "         072_169_002_04_01.txt\n",
            "         115_070_002_02_14.txt\n",
            "         116_067_001_02_25.txt\n",
            "         072_212_001_04_03.txt\n",
            "         096_051_002_03_23.txt\n",
            "         071_003_003_04_12.txt\n",
            "         116_626_002_02_16.txt\n",
            "         115_080_002_02_23.txt\n",
            "         071_168_004_05_20.txt\n",
            "         115_073_001_02_08.txt\n",
            "         073_073_001_03_02.txt\n",
            "         116_063_001_02_33.txt\n",
            "         116_275_001_03_13.txt\n",
            "         116_631_001_02_24.txt\n",
            "         115_072_001_02_02.txt\n",
            "         072_102_002_01_01.txt\n",
            "         116_607_001_03_10.txt\n",
            "         116_606_001_03_11.txt\n",
            "         097_186_001_01_30.txt\n",
            "         071_158_002_01_01.txt\n",
            "         071_132_001_04_11.txt\n",
            "         073_001_003_01_20.txt\n",
            "         096_039_001_01_16.txt\n",
            "         116_244_001_01_14.txt\n",
            "         071_146_001_05_16.txt\n",
            "         116_071_001_03_27.txt\n",
            "         116_405_001_01_26.txt\n",
            "         071_010_003_04_09.txt\n",
            "         115_065_004_02_10.txt\n",
            "         115_065_003_02_27.txt\n",
            "         115_101_001_02_09.txt\n",
            "         071_103_002_04_02.txt\n",
            "         071_022_003_01_01.txt\n",
            "         096_100_001_02_04.txt\n",
            "         071_180_003_05_09.txt\n",
            "         071_008_004_03_22.txt\n",
            "         115_070_001_02_20.txt\n",
            "         116_300_002_02_21.txt\n",
            "         096_099_003_02_03.txt\n",
            "         115_085_003_02_14.txt\n",
            "         071_022_003_04_14.txt\n",
            "         115_111_001_01_01.txt\n",
            "         096_053_004_03_03.txt\n",
            "         115_007_002_01_16.txt\n",
            "         073_055_001_02_01.txt\n",
            "         072_054_001_04_15.txt\n",
            "         072_049_002_04_03.txt\n",
            "         115_016_001_01_05.txt\n",
            "         116_627_001_03_19.txt\n",
            "         115_083_002_02_18.txt\n",
            "         115_111_004_02_06.txt\n",
            "         072_066_002_04_07.txt\n",
            "         071_002_002_03_01.txt\n",
            "         071_054_002_03_01.txt\n",
            "         116_618_001_03_15.txt\n",
            "         071_169_002_05_19.txt\n",
            "         071_108_001_04_15.txt\n",
            "         071_002_003_04_20.txt\n",
            "         115_073_001_02_35.txt\n",
            "         116_630_002_02_31.txt\n",
            "         116_387_001_01_04.txt\n",
            "         071_163_004_04_02.txt\n",
            "         071_108_001_04_10.txt\n",
            "         115_080_001_02_19.txt\n",
            "         116_405_001_01_27.txt\n",
            "         072_049_004_03_01.txt\n",
            "         002_080_001_03_15.txt\n",
            "         072_050_002_04_13.txt\n",
            "         072_105_001_04_18.txt\n",
            "         071_181_001_04_09.txt\n",
            "         071_103_002_03_01.txt\n",
            "         072_066_003_04_10.txt\n",
            "         115_007_004_02_24.txt\n",
            "         073_072_001_03_03.txt\n",
            "         115_080_003_02_08.txt\n",
            "         071_101_004_04_14.txt\n",
            "         073_003_002_01_02.txt\n",
            "         115_069_001_02_03.txt\n",
            "         096_098_002_01_04.txt\n",
            "         071_103_002_04_04.txt\n",
            "         115_088_001_02_07.txt\n",
            "         072_050_002_04_03.txt\n",
            "         115_076_001_02_17.txt\n",
            "         115_075_004_02_01.txt\n",
            "         073_003_002_01_03.txt\n",
            "         071_201_003_04_02.txt\n",
            "         115_084_004_02_20.txt\n",
            "         071_167_001_04_10.txt\n",
            "         115_065_003_02_02.txt\n",
            "         115_080_003_02_05.txt\n",
            "         116_290_001_04_02.txt\n",
            "         071_044_003_04_01.txt\n",
            "         116_073_001_02_18.txt\n",
            "         116_631_002_02_26.txt\n",
            "         073_068_001_03_05.txt\n",
            "         071_183_001_04_04.txt\n",
            "         116_642_001_02_24.txt\n",
            "         116_275_001_03_08.txt\n",
            "         097_186_001_01_17.txt\n",
            "         071_186_002_04_19.txt\n",
            "         115_007_003_02_01.txt\n",
            "         116_244_001_01_16.txt\n",
            "         071_032_002_04_02.txt\n",
            "         115_075_004_02_16.txt\n",
            "         115_086_003_02_01.txt\n",
            "         116_627_001_03_25.txt\n",
            "         072_101_003_04_07.txt\n",
            "         115_083_002_02_03.txt\n",
            "         116_648_001_03_32.txt\n",
            "         116_607_001_03_23.txt\n",
            "         115_007_001_02_15.txt\n",
            "         071_202_001_04_24.txt\n",
            "         072_070_002_06_13.txt\n",
            "         073_057_002_01_13.txt\n",
            "         071_157_001_02_01.txt\n",
            "         115_085_004_02_26.txt\n",
            "         071_103_002_04_06.txt\n",
            "         115_072_001_02_11.txt\n",
            "         115_112_001_02_25.txt\n",
            "         116_649_001_03_18.txt\n",
            "         071_002_003_04_03.txt\n",
            "         116_392_001_07_01.txt\n",
            "         116_607_001_03_02.txt\n",
            "         071_151_003_04_16.txt\n",
            "         115_080_001_02_20.txt\n",
            "         073_055_001_03_02.txt\n",
            "         115_065_002_02_11.txt\n",
            "         072_095_001_04_12.txt\n",
            "         072_050_002_01_01.txt\n",
            "         002_121_001_02_04.txt\n",
            "         071_003_004_04_14.txt\n",
            "         071_131_002_04_08.txt\n",
            "         115_008_002_02_08.txt\n",
            "         071_106_002_04_11.txt\n",
            "         071_167_001_05_04.txt\n",
            "         116_074_001_02_05.txt\n",
            "         116_076_001_02_28.txt\n",
            "         071_030_001_04_01.txt\n",
            "         071_085_004_04_05.txt\n",
            "         116_648_001_03_53.txt\n",
            "         071_186_004_04_11.txt\n",
            "         073_054_001_03_02.txt\n",
            "         115_108_002_01_28.txt\n",
            "         115_072_001_02_16.txt\n",
            "         116_636_002_02_09.txt\n",
            "         071_163_001_04_01.txt\n",
            "         071_043_004_04_04.txt\n",
            "         071_165_003_04_10.txt\n",
            "         096_099_004_01_07.txt\n",
            "         115_101_003_02_20.txt\n",
            "         071_157_001_04_09.txt\n",
            "         071_131_002_04_14.txt\n",
            "         071_109_001_04_20.txt\n",
            "         071_141_003_04_06.txt\n",
            "         116_133_001_02_24.txt\n",
            "         115_007_003_02_25.txt\n",
            "         071_105_003_04_03.txt\n",
            "         116_632_002_02_29.txt\n",
            "         116_648_001_03_33.txt\n",
            "         116_639_002_02_09.txt\n",
            "         096_052_002_03_25.txt\n",
            "         116_067_001_02_37.txt\n",
            "         096_098_003_01_24.txt\n",
            "         071_130_003_04_11.txt\n",
            "         072_066_003_04_03.txt\n",
            "         096_100_002_01_15.txt\n",
            "         097_186_001_01_04.txt\n",
            "         115_075_003_02_17.txt\n",
            "         115_087_003_02_03.txt\n",
            "         116_280_001_02_01.txt\n",
            "         116_275_001_02_17.txt\n",
            "         035_322_001_02_18.txt\n",
            "         072_102_004_04_04.txt\n",
            "         116_063_001_02_32.txt\n",
            "         072_054_003_03_12.txt\n",
            "         035_325_001_02_17.txt\n",
            "         115_079_001_02_01.txt\n",
            "         115_067_003_02_10.txt\n",
            "         071_042_001_04_11.txt\n",
            "         073_069_001_03_15.txt\n",
            "         072_101_002_04_01.txt\n",
            "         115_065_004_02_15.txt\n",
            "         071_120_001_05_02.txt\n",
            "         115_009_003_02_14.txt\n",
            "         096_024_001_02_10.txt\n",
            "         073_071_002_01_07.txt\n",
            "         115_078_002_02_33.txt\n",
            "         071_130_003_04_08.txt\n",
            "         071_132_001_04_16.txt\n",
            "         072_049_001_04_09.txt\n",
            "         072_047_002_04_14.txt\n",
            "         073_071_003_03_10.txt\n",
            "         096_100_001_01_01.txt\n",
            "         071_184_004_04_02.txt\n",
            "         096_052_003_02_18.txt\n",
            "         115_009_004_02_07.txt\n",
            "         072_047_002_04_09.txt\n",
            "         116_642_002_02_10.txt\n",
            "         071_181_002_02_01.txt\n",
            "         072_049_002_04_17.txt\n",
            "         096_118_001_01_26.txt\n",
            "         071_201_003_04_14.txt\n",
            "         071_059_003_01_01.txt\n",
            "         116_639_001_02_22.txt\n",
            "         115_007_004_02_13.txt\n",
            "         071_146_003_05_03.txt\n",
            "         115_077_003_01_01.txt\n",
            "         115_087_001_02_24.txt\n",
            "         115_011_001_02_16.txt\n",
            "         116_643_002_02_21.txt\n",
            "         115_110_004_03_25.txt\n",
            "         116_100_002_01_01.txt\n",
            "         073_068_001_03_02.txt\n",
            "         072_066_002_04_16.txt\n",
            "         071_043_004_04_17.txt\n",
            "         096_118_001_01_16.txt\n",
            "         116_631_002_02_28.txt\n",
            "         116_294_002_02_26.txt\n",
            "         035_321_001_02_12.txt\n",
            "         071_111_002_04_09.txt\n",
            "         115_082_002_02_20.txt\n",
            "         116_290_001_04_16.txt\n",
            "         115_082_001_02_17.txt\n",
            "         071_003_003_04_15.txt\n",
            "         115_077_002_02_22.txt\n",
            "         115_108_002_01_21.txt\n",
            "         035_321_001_02_10.txt\n",
            "         116_648_001_03_27.txt\n",
            "         115_075_001_02_04.txt\n",
            "         116_286_002_02_20.txt\n",
            "         115_107_001_01_10.txt\n",
            "         115_086_004_02_22.txt\n",
            "         071_192_002_04_02.txt\n",
            "         071_120_002_04_02.txt\n",
            "         072_071_004_04_15.txt\n",
            "         096_052_001_02_25.txt\n",
            "         116_280_001_03_05.txt\n",
            "         116_055_001_02_04.txt\n",
            "         072_049_004_04_19.txt\n",
            "         072_032_002_04_15.txt\n",
            "         116_633_002_02_11.txt\n",
            "         071_184_002_04_12.txt\n",
            "         116_071_001_03_10.txt\n",
            "         071_101_003_04_06.txt\n",
            "         116_067_001_02_07.txt\n",
            "         071_163_001_04_17.txt\n",
            "         071_117_002_05_15.txt\n",
            "         115_010_001_02_13.txt\n",
            "         071_181_004_01_01.txt\n",
            "         116_068_001_01_02.txt\n",
            "         096_053_004_03_11.txt\n",
            "         071_169_002_05_07.txt\n",
            "         116_135_001_02_28.txt\n",
            "         115_072_001_02_27.txt\n",
            "         071_131_004_05_06.txt\n",
            "         035_324_001_02_10.txt\n",
            "         073_001_003_01_23.txt\n",
            "         116_643_002_01_01.txt\n",
            "         071_101_004_04_19.txt\n",
            "         071_117_002_05_01.txt\n",
            "         096_098_003_01_21.txt\n",
            "         071_111_002_04_01.txt\n",
            "         115_111_004_02_04.txt\n",
            "         071_108_002_04_13.txt\n",
            "         116_617_001_03_03.txt\n",
            "         116_288_001_03_04.txt\n",
            "         115_107_001_01_11.txt\n",
            "         116_617_001_02_01.txt\n",
            "         073_070_002_03_15.txt\n",
            "         071_112_003_04_05.txt\n",
            "         073_073_001_03_16.txt\n",
            "         072_051_003_04_28.txt\n",
            "         115_067_003_02_30.txt\n",
            "         073_053_001_03_11.txt\n",
            "         071_130_003_04_23.txt\n",
            "         116_279_001_03_22.txt\n",
            "         096_100_001_02_18.txt\n",
            "         115_108_003_01_17.txt\n",
            "         072_070_002_05_02.txt\n",
            "         115_102_001_02_20.txt\n",
            "         071_167_002_04_06.txt\n",
            "         071_190_002_04_05.txt\n",
            "         116_078_001_02_19.txt\n",
            "         071_167_002_01_01.txt\n",
            "         071_044_003_04_06.txt\n",
            "         072_036_002_04_04.txt\n",
            "         115_112_003_02_23.txt\n",
            "         027_029_001_02_31.txt\n",
            "         071_151_003_04_03.txt\n",
            "         071_053_004_01_01.txt\n",
            "         115_101_001_02_05.txt\n",
            "         072_102_003_04_11.txt\n",
            "         072_101_004_03_01.txt\n",
            "         115_083_001_02_14.txt\n",
            "         071_018_002_05_06.txt\n",
            "         116_288_001_03_03.txt\n",
            "         071_186_004_01_01.txt\n",
            "         115_111_004_01_01.txt\n",
            "         116_641_001_02_01.txt\n",
            "         116_055_001_02_35.txt\n",
            "         071_169_002_05_12.txt\n",
            "         073_050_001_02_08.txt\n",
            "         071_101_002_04_08.txt\n",
            "         115_102_001_02_11.txt\n",
            "         071_002_003_04_10.txt\n",
            "         115_112_001_02_11.txt\n",
            "         073_072_002_03_10.txt\n",
            "         115_077_001_02_06.txt\n",
            "         071_022_003_04_01.txt\n",
            "         072_054_001_04_07.txt\n",
            "         116_287_001_03_16.txt\n",
            "         071_128_001_05_08.txt\n",
            "         072_102_004_02_01.txt\n",
            "         035_323_001_03_02.txt\n",
            "         073_054_001_03_26.txt\n",
            "         071_190_002_04_11.txt\n",
            "         115_007_004_02_07.txt\n",
            "         116_135_001_02_16.txt\n",
            "         073_055_001_03_09.txt\n",
            "         116_287_002_02_02.txt\n",
            "         116_064_001_02_21.txt\n",
            "         116_400_001_03_12.txt\n",
            "         096_098_003_01_09.txt\n",
            "         073_060_001_03_02.txt\n",
            "         116_648_001_03_42.txt\n",
            "         071_185_002_01_01.txt\n",
            "         073_052_001_03_01.txt\n",
            "         071_159_003_04_14.txt\n",
            "         073_067_001_03_08.txt\n",
            "         115_065_001_02_24.txt\n",
            "         096_032_003_01_05.txt\n",
            "         071_043_003_04_05.txt\n",
            "         072_103_004_04_21.txt\n",
            "         116_136_001_01_22.txt\n",
            "         071_159_003_04_01.txt\n",
            "         071_169_001_05_10.txt\n",
            "         116_632_002_02_18.txt\n",
            "         072_066_003_04_24.txt\n",
            "         096_052_001_02_19.txt\n",
            "         071_032_001_04_17.txt\n",
            "         115_010_001_02_29.txt\n",
            "         071_130_003_04_14.txt\n",
            "         115_009_004_01_01.txt\n",
            "         071_032_001_04_19.txt\n",
            "         116_625_001_02_08.txt\n",
            "         072_051_002_04_05.txt\n",
            "         071_117_002_05_03.txt\n",
            "         071_102_003_05_11.txt\n",
            "         115_009_003_02_27.txt\n",
            "         072_032_002_04_18.txt\n",
            "         096_032_003_01_10.txt\n",
            "         115_082_003_02_08.txt\n",
            "         073_072_003_01_11.txt\n",
            "         115_009_004_02_19.txt\n",
            "         115_073_001_02_09.txt\n",
            "         071_117_002_05_09.txt\n",
            "         116_046_001_02_07.txt\n",
            "         072_071_004_04_12.txt\n",
            "         071_002_003_04_19.txt\n",
            "         115_107_001_01_17.txt\n",
            "         071_163_003_04_05.txt\n",
            "         071_102_003_04_01.txt\n",
            "         115_065_002_02_19.txt\n",
            "         073_002_001_02_17.txt\n",
            "         072_105_001_04_10.txt\n",
            "         071_043_004_04_27.txt\n",
            "         072_051_003_04_05.txt\n",
            "         071_146_001_05_01.txt\n",
            "         116_639_001_02_08.txt\n",
            "         072_047_002_04_24.txt\n",
            "         096_051_004_04_01.txt\n",
            "         071_117_002_03_01.txt\n",
            "         115_084_002_02_12.txt\n",
            "         071_112_003_04_04.txt\n",
            "         116_303_002_02_04.txt\n",
            "         073_061_001_03_10.txt\n",
            "         115_086_003_02_09.txt\n",
            "         116_405_001_01_16.txt\n",
            "         073_071_001_03_20.txt\n",
            "         071_185_004_04_14.txt\n",
            "         073_003_002_01_04.txt\n",
            "         116_405_001_01_23.txt\n",
            "         071_102_001_04_14.txt\n",
            "         071_002_002_04_01.txt\n",
            "         115_076_002_02_08.txt\n",
            "         071_169_001_05_07.txt\n",
            "         073_070_001_03_14.txt\n",
            "         116_616_001_03_08.txt\n",
            "         115_110_003_02_03.txt\n",
            "         116_133_001_02_07.txt\n",
            "         073_058_001_03_15.txt\n",
            "         115_075_003_02_21.txt\n",
            "         116_633_002_02_22.txt\n",
            "         072_105_002_04_22.txt\n",
            "         073_063_001_03_11.txt\n",
            "         116_400_001_03_23.txt\n",
            "         115_073_001_02_17.txt\n",
            "         116_620_001_03_28.txt\n",
            "         073_071_003_03_03.txt\n",
            "         115_012_001_01_26.txt\n",
            "         072_066_003_04_12.txt\n",
            "         116_642_001_02_10.txt\n",
            "         115_077_003_02_10.txt\n",
            "         096_008_004_01_03.txt\n",
            "         072_100_002_04_10.txt\n",
            "         071_003_004_04_13.txt\n",
            "         071_018_003_04_23.txt\n",
            "         115_008_001_02_25.txt\n",
            "         072_054_003_03_06.txt\n",
            "         071_003_004_02_01.txt\n",
            "         072_210_002_04_13.txt\n",
            "         071_112_003_03_01.txt\n",
            "         071_003_003_04_11.txt\n",
            "         096_024_001_02_01.txt\n",
            "         072_210_002_04_19.txt\n",
            "         115_086_003_02_20.txt\n",
            "         116_636_002_02_04.txt\n",
            "         116_074_001_02_17.txt\n",
            "         115_065_004_02_29.txt\n",
            "         071_043_003_04_11.txt\n",
            "         115_065_004_02_25.txt\n",
            "         116_291_001_03_12.txt\n",
            "         115_077_001_02_12.txt\n",
            "         115_077_003_02_08.txt\n",
            "         073_050_001_02_19.txt\n",
            "         115_011_002_02_27.txt\n",
            "         115_080_001_02_11.txt\n",
            "         097_172_002_01_09.txt\n",
            "         071_184_001_04_07.txt\n",
            "         096_099_004_01_05.txt\n",
            "         115_101_002_01_14.txt\n",
            "         115_007_003_02_07.txt\n",
            "         115_009_004_02_02.txt\n",
            "         115_101_004_02_13.txt\n",
            "         072_054_003_03_01.txt\n",
            "         072_050_001_03_01.txt\n",
            "         116_627_002_03_21.txt\n",
            "         115_107_002_01_10.txt\n",
            "         096_052_002_03_21.txt\n",
            "         072_094_004_04_08.txt\n",
            "         115_086_003_02_29.txt\n",
            "         072_105_003_04_07.txt\n",
            "         072_066_001_04_21.txt\n",
            "         071_128_003_04_15.txt\n",
            "         071_182_002_05_02.txt\n",
            "         071_111_001_04_20.txt\n",
            "         115_085_003_02_13.txt\n",
            "         115_076_001_02_26.txt\n",
            "         115_072_001_02_18.txt\n",
            "         116_291_001_03_10.txt\n",
            "         071_139_004_04_08.txt\n",
            "         115_076_002_02_04.txt\n",
            "         071_102_002_05_12.txt\n",
            "         035_328_001_02_04.txt\n",
            "         116_066_001_02_11.txt\n",
            "         035_324_001_02_17.txt\n",
            "         116_606_001_03_02.txt\n",
            "         072_210_002_04_01.txt\n",
            "         116_619_001_03_08.txt\n",
            "         096_098_003_01_03.txt\n",
            "         116_393_003_01_06.txt\n",
            "         072_069_002_04_12.txt\n",
            "         071_163_001_04_05.txt\n",
            "         072_210_002_04_17.txt\n",
            "         096_018_002_01_06.txt\n",
            "         072_212_001_04_12.txt\n",
            "         115_009_001_03_18.txt\n",
            "         072_210_001_04_16.txt\n",
            "         071_018_003_04_06.txt\n",
            "         115_007_002_01_17.txt\n",
            "         116_607_001_03_24.txt\n",
            "         071_184_002_02_01.txt\n",
            "         116_074_001_02_14.txt\n",
            "         115_102_001_02_23.txt\n",
            "         071_182_001_05_10.txt\n",
            "         072_052_002_04_16.txt\n",
            "         115_081_001_03_21.txt\n",
            "         116_643_001_02_11.txt\n",
            "         035_320_001_02_18.txt\n",
            "         073_056_001_01_01.txt\n",
            "         116_641_001_02_18.txt\n",
            "         115_101_002_01_08.txt\n",
            "         116_648_001_03_12.txt\n",
            "         072_050_002_02_01.txt\n",
            "         071_010_002_04_10.txt\n",
            "         071_130_003_04_09.txt\n",
            "         071_107_001_01_01.txt\n",
            "         096_034_004_01_06.txt\n",
            "         071_185_002_04_08.txt\n",
            "         071_182_004_04_11.txt\n",
            "         115_101_004_02_18.txt\n",
            "         115_087_001_02_05.txt\n",
            "         073_055_001_03_17.txt\n",
            "         072_071_004_04_02.txt\n",
            "         071_043_003_04_06.txt\n",
            "         115_101_003_02_04.txt\n",
            "         116_066_001_02_21.txt\n",
            "         071_117_002_05_11.txt\n",
            "         071_169_001_05_05.txt\n",
            "         072_054_003_03_19.txt\n",
            "         116_642_002_02_04.txt\n",
            "         072_103_002_04_09.txt\n",
            "         115_067_003_02_27.txt\n",
            "         073_003_002_01_14.txt\n",
            "         116_639_001_02_28.txt\n",
            "         115_107_001_01_29.txt\n",
            "         115_080_002_02_17.txt\n",
            "         116_620_001_03_29.txt\n",
            "         116_067_001_01_01.txt\n",
            "         115_101_001_02_16.txt\n",
            "         071_120_002_02_02.txt\n",
            "         071_184_004_04_18.txt\n",
            "         116_405_003_01_14.txt\n",
            "         071_130_003_04_03.txt\n",
            "         115_011_001_02_13.txt\n",
            "         071_182_002_04_08.txt\n",
            "         116_639_002_02_19.txt\n",
            "         071_186_003_04_11.txt\n",
            "         116_291_002_02_08.txt\n",
            "         116_063_001_02_08.txt\n",
            "         115_077_001_02_17.txt\n",
            "         116_070_001_02_09.txt\n",
            "         073_063_001_03_06.txt\n",
            "         115_084_003_02_08.txt\n",
            "         072_049_002_04_20.txt\n",
            "         096_100_003_01_20.txt\n",
            "         116_630_002_02_14.txt\n",
            "         071_130_003_04_25.txt\n",
            "         027_029_001_02_27.txt\n",
            "         096_002_003_02_16.txt\n",
            "         116_643_001_02_17.txt\n",
            "         071_085_004_04_09.txt\n",
            "         097_186_001_01_05.txt\n",
            "         071_018_003_04_03.txt\n",
            "         096_024_001_02_13.txt\n",
            "         115_101_001_02_32.txt\n",
            "         072_213_001_04_16.txt\n",
            "         116_606_001_03_07.txt\n",
            "         071_185_004_04_03.txt\n",
            "         115_065_003_02_18.txt\n",
            "         115_088_001_02_01.txt\n",
            "         073_031_001_04_14.txt\n",
            "         071_182_001_04_05.txt\n",
            "         096_098_003_01_26.txt\n",
            "         115_101_003_02_10.txt\n",
            "         115_080_002_01_01.txt\n",
            "         071_085_004_04_03.txt\n",
            "         072_100_002_04_11.txt\n",
            "         072_031_001_03_13.txt\n",
            "         071_181_003_04_03.txt\n",
            "         115_076_002_02_02.txt\n",
            "         072_094_004_02_01.txt\n",
            "         071_042_002_04_03.txt\n",
            "         073_002_002_01_12.txt\n",
            "         072_048_003_04_08.txt\n",
            "         115_102_001_02_08.txt\n",
            "         072_071_004_04_26.txt\n",
            "         116_633_001_02_01.txt\n",
            "         073_074_001_03_05.txt\n",
            "         035_324_001_02_20.txt\n",
            "         071_131_002_02_01.txt\n",
            "         115_111_002_02_22.txt\n",
            "         115_009_004_02_05.txt\n",
            "         116_076_001_02_34.txt\n",
            "         073_031_001_04_17.txt\n",
            "         073_053_001_03_16.txt\n",
            "         116_405_003_01_23.txt\n",
            "         071_184_002_04_18.txt\n",
            "         072_072_001_02_01.txt\n",
            "         072_103_001_04_06.txt\n",
            "         096_053_004_03_26.txt\n",
            "         073_054_001_03_11.txt\n",
            "         115_007_001_02_09.txt\n",
            "         073_056_001_03_03.txt\n",
            "         116_275_001_02_02.txt\n",
            "         072_212_001_04_06.txt\n",
            "         115_077_001_02_14.txt\n",
            "         115_009_003_02_19.txt\n",
            "         096_098_003_01_27.txt\n",
            "         116_076_001_02_13.txt\n",
            "         072_103_004_04_02.txt\n",
            "         115_101_001_02_22.txt\n",
            "         072_047_002_04_21.txt\n",
            "         071_131_004_02_01.txt\n",
            "         116_071_001_03_13.txt\n",
            "         071_142_001_04_11.txt\n",
            "         115_016_003_01_08.txt\n",
            "         115_085_003_02_19.txt\n",
            "         115_007_004_02_06.txt\n",
            "         115_112_003_02_18.txt\n",
            "         071_128_001_05_10.txt\n",
            "         073_073_001_03_14.txt\n",
            "         071_036_001_02_01.txt\n",
            "         115_080_004_02_13.txt\n",
            "         115_009_002_02_28.txt\n",
            "         035_321_001_02_05.txt\n",
            "         071_163_004_04_10.txt\n",
            "         115_112_003_02_17.txt\n",
            "         115_007_003_02_06.txt\n",
            "         096_038_003_01_03.txt\n",
            "         116_064_001_02_29.txt\n",
            "         071_163_001_02_01.txt\n",
            "         071_163_002_04_13.txt\n",
            "         073_001_003_01_01.txt\n",
            "         071_182_002_04_02.txt\n",
            "         115_009_003_02_28.txt\n",
            "         115_080_004_02_29.txt\n",
            "         073_050_001_02_03.txt\n",
            "         072_047_002_04_23.txt\n",
            "         116_639_001_02_20.txt\n",
            "         071_106_002_04_09.txt\n",
            "         071_192_002_03_01.txt\n",
            "         073_069_001_03_09.txt\n",
            "         072_050_003_04_16.txt\n",
            "         115_110_004_03_08.txt\n",
            "         116_643_002_02_08.txt\n",
            "         115_077_002_02_11.txt\n",
            "         096_101_001_02_08.txt\n",
            "         072_168_001_03_01.txt\n",
            "         073_074_001_03_09.txt\n",
            "         072_167_003_04_17.txt\n",
            "         115_012_001_01_25.txt\n",
            "         116_295_001_03_02.txt\n",
            "         096_003_002_01_01.txt\n",
            "         071_157_002_04_08.txt\n",
            "         071_108_001_03_01.txt\n",
            "         115_065_001_02_07.txt\n",
            "         115_087_002_02_19.txt\n",
            "         116_620_001_03_08.txt\n",
            "         071_102_001_04_21.txt\n",
            "         071_142_001_04_03.txt\n",
            "         115_069_001_02_27.txt\n",
            "         096_051_001_02_15.txt\n",
            "         073_003_002_01_19.txt\n",
            "         096_003_002_01_15.txt\n",
            "         115_075_004_02_22.txt\n",
            "         072_069_002_05_08.txt\n",
            "         072_048_003_04_07.txt\n",
            "         072_102_004_03_01.txt\n",
            "         073_063_001_03_23.txt\n",
            "         115_009_002_02_01.txt\n",
            "         115_012_001_01_37.txt\n",
            "         071_169_004_01_01.txt\n",
            "         073_072_002_03_09.txt\n",
            "         116_607_001_03_11.txt\n",
            "         116_288_001_03_07.txt\n",
            "         115_107_003_01_17.txt\n",
            "         115_080_002_02_26.txt\n",
            "         116_066_001_02_10.txt\n",
            "         115_108_001_01_01.txt\n",
            "         116_625_001_02_03.txt\n",
            "         071_181_003_01_01.txt\n",
            "         115_075_001_03_04.txt\n",
            "         116_642_001_02_19.txt\n",
            "         072_051_003_04_01.txt\n",
            "         116_636_002_02_29.txt\n",
            "         073_001_003_01_16.txt\n",
            "         116_068_001_02_30.txt\n",
            "         071_180_003_05_11.txt\n",
            "         072_169_003_04_03.txt\n",
            "         072_051_003_04_18.txt\n",
            "         115_108_003_01_22.txt\n",
            "         116_286_002_02_08.txt\n",
            "         072_167_004_04_02.txt\n",
            "         116_633_002_02_31.txt\n",
            "         072_102_002_04_03.txt\n",
            "         072_054_003_03_21.txt\n",
            "         116_303_002_01_01.txt\n",
            "         116_072_001_02_20.txt\n",
            "         071_164_001_04_15.txt\n",
            "         071_186_004_04_07.txt\n",
            "         115_107_002_01_27.txt\n",
            "         116_288_001_03_17.txt\n",
            "         116_279_002_03_07.txt\n",
            "         115_072_003_01_01.txt\n",
            "         115_065_003_02_13.txt\n",
            "         116_620_001_03_25.txt\n",
            "         071_003_004_04_11.txt\n",
            "         116_100_001_01_39.txt\n",
            "         071_043_004_04_26.txt\n",
            "         072_051_002_04_25.txt\n",
            "         115_110_004_03_02.txt\n",
            "         116_648_001_03_13.txt\n",
            "         096_038_003_01_15.txt\n",
            "         096_100_001_02_25.txt\n",
            "         071_181_004_04_11.txt\n",
            "         072_072_001_04_23.txt\n",
            "         071_184_002_01_01.txt\n",
            "         115_016_001_01_11.txt\n",
            "         115_108_001_01_16.txt\n",
            "         071_102_001_04_22.txt\n",
            "         072_099_001_04_18.txt\n",
            "         071_111_001_04_17.txt\n",
            "         071_032_002_04_08.txt\n",
            "         115_069_001_02_24.txt\n",
            "         096_032_004_02_07.txt\n",
            "         116_643_002_02_15.txt\n",
            "         096_118_001_01_18.txt\n",
            "         116_400_001_03_34.txt\n",
            "         071_043_004_04_09.txt\n",
            "         115_101_003_02_08.txt\n",
            "         073_001_003_01_04.txt\n",
            "         071_128_003_04_20.txt\n",
            "         115_087_001_02_15.txt\n",
            "         116_406_001_01_12.txt\n",
            "         071_018_003_04_11.txt\n",
            "         071_132_001_04_05.txt\n",
            "         116_631_002_02_36.txt\n",
            "         072_104_002_04_02.txt\n",
            "         115_073_001_02_36.txt\n",
            "         071_085_004_04_17.txt\n",
            "         116_617_001_03_04.txt\n",
            "         071_168_003_05_07.txt\n",
            "         071_182_001_05_13.txt\n",
            "         071_163_003_04_10.txt\n",
            "         072_102_004_04_13.txt\n",
            "         072_213_001_04_13.txt\n",
            "         096_008_002_02_07.txt\n",
            "         115_073_001_02_21.txt\n",
            "         116_287_002_02_20.txt\n",
            "         115_111_001_02_24.txt\n",
            "         071_182_004_04_04.txt\n",
            "         115_067_002_02_08.txt\n",
            "         116_620_001_03_19.txt\n",
            "         116_392_001_03_01.txt\n",
            "         071_053_004_03_21.txt\n",
            "         116_619_001_03_15.txt\n",
            "         071_165_003_05_04.txt\n",
            "         115_101_002_01_07.txt\n",
            "         071_168_004_04_03.txt\n",
            "         071_192_004_04_07.txt\n",
            "         071_131_002_04_09.txt\n",
            "         115_077_001_02_04.txt\n",
            "         115_076_001_02_15.txt\n",
            "         116_070_001_02_16.txt\n",
            "         073_063_001_03_14.txt\n",
            "         072_103_001_04_12.txt\n",
            "         071_184_001_04_15.txt\n",
            "         073_071_001_03_05.txt\n",
            "         071_059_003_04_10.txt\n",
            "         116_275_001_02_20.txt\n",
            "         071_032_001_04_20.txt\n",
            "         115_011_002_02_13.txt\n",
            "         116_627_001_03_31.txt\n",
            "         071_002_003_04_14.txt\n",
            "         096_003_002_01_25.txt\n",
            "         073_069_001_03_11.txt\n",
            "         116_288_001_03_19.txt\n",
            "         116_642_001_01_01.txt\n",
            "         116_288_001_03_01.txt\n",
            "         116_303_002_02_21.txt\n",
            "         071_032_002_04_06.txt\n",
            "         071_192_004_02_01.txt\n",
            "         071_201_001_04_14.txt\n",
            "         115_111_003_02_21.txt\n",
            "         116_633_001_02_15.txt\n",
            "         116_626_002_02_04.txt\n",
            "         073_070_001_03_19.txt\n",
            "         116_133_001_02_23.txt\n",
            "         072_070_002_06_05.txt\n",
            "         115_082_002_02_19.txt\n",
            "         115_107_002_01_08.txt\n",
            "         115_073_002_02_27.txt\n",
            "         073_060_001_02_01.txt\n",
            "         071_032_001_04_18.txt\n",
            "         116_100_001_01_27.txt\n",
            "         115_112_002_02_27.txt\n",
            "         071_156_002_04_05.txt\n",
            "         071_010_002_04_13.txt\n",
            "         116_627_001_03_10.txt\n",
            "         072_066_001_04_20.txt\n",
            "         072_094_003_04_19.txt\n",
            "         115_080_003_02_21.txt\n",
            "         096_051_004_03_10.txt\n",
            "         071_180_003_05_19.txt\n",
            "         071_139_004_04_18.txt\n",
            "         071_157_001_04_03.txt\n",
            "         073_071_003_03_11.txt\n",
            "         071_151_003_04_14.txt\n",
            "         071_106_002_04_19.txt\n",
            "         116_078_001_02_21.txt\n",
            "         116_642_001_02_11.txt\n",
            "         116_639_001_02_24.txt\n",
            "         071_054_001_03_19.txt\n",
            "         115_112_003_02_15.txt\n",
            "         115_009_002_02_23.txt\n",
            "         071_182_002_02_01.txt\n",
            "         096_015_002_01_04.txt\n",
            "         115_078_002_02_35.txt\n",
            "         071_053_004_03_23.txt\n",
            "         116_286_002_02_29.txt\n",
            "         073_063_001_03_24.txt\n",
            "         072_105_001_04_13.txt\n",
            "         115_010_002_01_01.txt\n",
            "         116_633_002_01_01.txt\n",
            "         115_084_001_02_15.txt\n",
            "         116_639_002_02_23.txt\n",
            "         116_291_001_03_09.txt\n",
            "         071_131_004_05_04.txt\n",
            "         071_164_002_02_01.txt\n",
            "         116_063_001_02_31.txt\n",
            "         071_108_001_04_04.txt\n",
            "         071_021_002_04_22.txt\n",
            "         115_065_003_02_10.txt\n",
            "         116_400_001_03_18.txt\n",
            "         072_066_002_04_09.txt\n",
            "         115_084_002_02_10.txt\n",
            "         115_010_001_02_17.txt\n",
            "         072_100_001_04_07.txt\n",
            "         115_007_002_01_15.txt\n",
            "         115_076_001_02_16.txt\n",
            "         115_079_001_02_11.txt\n",
            "         071_157_002_03_01.txt\n",
            "         116_625_001_02_07.txt\n",
            "         115_078_002_02_05.txt\n",
            "         072_054_003_03_10.txt\n",
            "         115_065_002_02_12.txt\n",
            "         115_112_003_01_01.txt\n",
            "         072_169_003_04_07.txt\n",
            "         116_620_001_03_20.txt\n",
            "         116_294_001_03_03.txt\n",
            "         071_141_001_04_10.txt\n",
            "         116_131_001_01_04.txt\n",
            "         071_032_002_02_01.txt\n",
            "         071_131_002_03_01.txt\n",
            "         115_076_001_02_23.txt\n",
            "         072_099_001_04_05.txt\n",
            "         096_051_004_03_04.txt\n",
            "         072_212_001_04_15.txt\n",
            "         115_077_002_02_04.txt\n",
            "         071_120_002_05_03.txt\n",
            "         071_181_004_04_12.txt\n",
            "         097_172_002_01_11.txt\n",
            "         035_328_001_01_01.txt\n",
            "         071_107_002_04_11.txt\n",
            "         071_108_001_04_13.txt\n",
            "         071_106_001_04_06.txt\n",
            "         115_110_004_03_11.txt\n",
            "         071_169_001_05_18.txt\n",
            "         116_300_002_02_29.txt\n",
            "         115_110_003_02_17.txt\n",
            "         116_064_001_02_20.txt\n",
            "         071_146_001_05_12.txt\n",
            "         072_100_003_04_07.txt\n",
            "         116_619_001_03_27.txt\n",
            "         115_111_002_02_27.txt\n",
            "         073_072_001_03_10.txt\n",
            "         115_111_004_02_07.txt\n",
            "         116_287_002_02_24.txt\n",
            "         071_188_002_03_18.txt\n",
            "         071_036_001_04_10.txt\n",
            "         116_287_001_03_27.txt\n",
            "         073_068_001_03_06.txt\n",
            "         071_053_004_03_20.txt\n",
            "         116_071_001_03_07.txt\n",
            "         116_303_002_02_28.txt\n",
            "         035_320_001_02_05.txt\n",
            "         071_108_002_04_09.txt\n",
            "         116_618_001_03_04.txt\n",
            "         072_102_003_03_01.txt\n",
            "         115_083_001_02_15.txt\n",
            "         115_082_001_02_24.txt\n",
            "         072_100_002_04_13.txt\n",
            "         071_183_001_04_05.txt\n",
            "         073_063_001_03_20.txt\n",
            "         115_111_003_02_23.txt\n",
            "         071_120_002_04_04.txt\n",
            "         115_069_001_02_28.txt\n",
            "         115_067_003_02_29.txt\n",
            "         115_081_001_03_19.txt\n",
            "         115_065_002_02_30.txt\n",
            "         072_100_002_04_03.txt\n",
            "         116_133_001_02_08.txt\n",
            "         116_387_001_01_09.txt\n",
            "         071_146_002_05_04.txt\n",
            "         096_052_001_02_24.txt\n",
            "         116_616_001_03_20.txt\n",
            "         096_039_001_01_05.txt\n",
            "         116_648_001_03_18.txt\n",
            "         115_080_002_02_08.txt\n",
            "         116_642_002_02_29.txt\n",
            "         071_042_001_04_03.txt\n",
            "         071_133_003_02_01.txt\n",
            "         073_063_001_03_15.txt\n",
            "         115_065_002_01_01.txt\n",
            "         116_070_001_02_11.txt\n",
            "         072_100_002_04_17.txt\n",
            "         115_108_002_01_25.txt\n",
            "         115_073_001_02_33.txt\n",
            "         115_065_004_02_16.txt\n",
            "         072_100_001_03_01.txt\n",
            "         096_051_001_02_22.txt\n",
            "         096_100_003_01_10.txt\n",
            "         002_080_001_03_11.txt\n",
            "         116_280_001_03_07.txt\n",
            "         115_087_003_02_17.txt\n",
            "         071_164_002_04_15.txt\n",
            "         071_165_003_04_13.txt\n",
            "         072_102_004_04_05.txt\n",
            "         096_032_004_02_14.txt\n",
            "         071_120_001_05_04.txt\n",
            "         072_049_004_04_14.txt\n",
            "         115_111_003_02_14.txt\n",
            "         072_070_002_06_11.txt\n",
            "         116_291_001_03_06.txt\n",
            "         072_101_004_04_14.txt\n",
            "         116_643_002_02_20.txt\n",
            "         115_110_003_02_21.txt\n",
            "         116_067_001_02_19.txt\n",
            "         116_063_001_02_14.txt\n",
            "         073_063_001_03_13.txt\n",
            "         115_084_004_02_15.txt\n",
            "         096_101_001_02_11.txt\n",
            "         115_087_004_02_14.txt\n",
            "         115_067_004_02_18.txt\n",
            "         116_068_001_02_13.txt\n",
            "         116_405_003_01_20.txt\n",
            "         115_082_001_02_09.txt\n",
            "         072_048_003_03_01.txt\n",
            "         116_400_001_03_27.txt\n",
            "         071_107_001_04_03.txt\n",
            "         116_280_001_03_01.txt\n",
            "         071_188_002_03_16.txt\n",
            "         073_069_001_03_10.txt\n",
            "         116_300_002_02_30.txt\n",
            "         116_291_001_04_08.txt\n",
            "         116_072_001_02_19.txt\n",
            "         116_244_001_01_07.txt\n",
            "         096_018_002_01_15.txt\n",
            "         072_054_001_04_10.txt\n",
            "         035_320_001_02_23.txt\n",
            "         115_086_001_02_21.txt\n",
            "         071_181_002_04_05.txt\n",
            "         116_649_001_03_22.txt\n",
            "         116_100_001_01_16.txt\n",
            "         116_300_002_02_22.txt\n",
            "         073_061_001_03_09.txt\n",
            "         115_065_001_02_25.txt\n",
            "         072_071_004_04_06.txt\n",
            "         072_054_003_03_17.txt\n",
            "         096_053_004_03_23.txt\n",
            "         002_541_001_02_12.txt\n",
            "         071_183_004_04_15.txt\n",
            "         073_072_002_03_20.txt\n",
            "         115_110_003_02_01.txt\n",
            "         116_064_001_02_15.txt\n",
            "         071_032_002_04_20.txt\n",
            "         115_101_002_01_18.txt\n",
            "         071_181_002_04_16.txt\n",
            "         116_406_001_01_11.txt\n",
            "         116_405_004_01_01.txt\n",
            "         071_201_001_04_20.txt\n",
            "         116_286_002_02_03.txt\n",
            "         115_087_003_02_09.txt\n",
            "         071_107_001_04_16.txt\n",
            "         071_144_002_04_01.txt\n",
            "         116_244_001_01_11.txt\n",
            "         073_073_001_03_20.txt\n",
            "         115_084_002_02_29.txt\n",
            "         115_083_001_02_23.txt\n",
            "         071_141_001_04_07.txt\n",
            "         115_072_001_02_17.txt\n",
            "         116_631_002_02_14.txt\n",
            "         115_086_004_02_09.txt\n",
            "         072_167_003_04_19.txt\n",
            "         115_007_004_02_27.txt\n",
            "         071_141_001_03_01.txt\n",
            "         072_210_004_04_20.txt\n",
            "         071_101_003_04_04.txt\n",
            "         115_110_004_03_20.txt\n",
            "         071_168_004_05_19.txt\n",
            "         116_633_001_02_03.txt\n",
            "         116_631_002_02_23.txt\n",
            "         071_168_003_05_10.txt\n",
            "         115_082_002_02_11.txt\n",
            "         071_202_001_04_11.txt\n",
            "         116_625_001_02_33.txt\n",
            "         116_620_001_03_12.txt\n",
            "         115_111_004_02_08.txt\n",
            "         115_080_003_02_12.txt\n",
            "         071_192_004_03_01.txt\n",
            "         035_322_001_02_05.txt\n",
            "         116_643_001_02_20.txt\n",
            "         115_081_001_03_12.txt\n",
            "         115_101_004_02_03.txt\n",
            "         096_098_002_01_02.txt\n",
            "         115_080_002_02_10.txt\n",
            "         115_084_002_02_14.txt\n",
            "         071_054_002_03_04.txt\n",
            "         071_185_003_04_03.txt\n",
            "         072_169_002_04_07.txt\n",
            "         115_084_003_02_02.txt\n",
            "         096_098_003_01_13.txt\n",
            "         073_071_001_03_17.txt\n",
            "         071_105_003_04_20.txt\n",
            "         097_186_001_01_19.txt\n",
            "         116_279_001_03_03.txt\n",
            "         072_066_002_02_01.txt\n",
            "         002_080_001_03_13.txt\n",
            "         115_080_001_02_18.txt\n",
            "         071_103_002_04_11.txt\n",
            "         073_071_001_03_10.txt\n",
            "         115_078_002_02_03.txt\n",
            "         072_050_002_04_05.txt\n",
            "         115_111_002_01_01.txt\n",
            "         116_286_002_02_17.txt\n",
            "         115_078_002_02_06.txt\n",
            "         115_110_001_03_17.txt\n",
            "         071_181_004_04_02.txt\n",
            "         116_068_001_02_06.txt\n",
            "         073_069_001_03_14.txt\n",
            "         072_049_004_04_09.txt\n",
            "         116_279_002_03_26.txt\n",
            "         027_029_001_02_19.txt\n",
            "         096_118_001_01_02.txt\n",
            "         071_182_001_05_05.txt\n",
            "         072_167_002_05_15.txt\n",
            "         115_081_001_03_24.txt\n",
            "         071_183_001_05_09.txt\n",
            "         035_328_001_02_21.txt\n",
            "         116_244_001_01_06.txt\n",
            "         072_050_002_04_01.txt\n",
            "         115_107_002_01_19.txt\n",
            "         072_105_002_04_20.txt\n",
            "         115_112_001_02_01.txt\n",
            "         071_010_002_04_05.txt\n",
            "         096_052_003_02_27.txt\n",
            "         096_008_002_02_01.txt\n",
            "         096_098_002_01_03.txt\n",
            "         071_133_003_04_04.txt\n",
            "         116_619_001_03_25.txt\n",
            "         072_049_001_04_17.txt\n",
            "         115_112_003_02_12.txt\n",
            "         116_136_001_01_17.txt\n",
            "         115_087_003_02_31.txt\n",
            "         115_065_004_02_12.txt\n",
            "         002_112_001_03_12.txt\n",
            "         115_072_001_02_03.txt\n",
            "         071_164_002_04_20.txt\n",
            "         116_643_001_02_15.txt\n",
            "         071_184_004_04_14.txt\n",
            "         115_108_003_01_12.txt\n",
            "         115_082_004_02_28.txt\n",
            "         071_107_002_04_10.txt\n",
            "         116_626_002_02_27.txt\n",
            "         116_300_002_02_27.txt\n",
            "         116_287_002_02_25.txt\n",
            "         071_163_004_04_04.txt\n",
            "         071_102_002_04_01.txt\n",
            "         115_077_004_02_24.txt\n",
            "         116_078_001_02_02.txt\n",
            "         071_184_004_04_10.txt\n",
            "         116_275_001_03_07.txt\n",
            "         115_087_004_02_21.txt\n",
            "         071_132_001_04_03.txt\n",
            "         071_164_002_04_05.txt\n",
            "         096_018_002_01_02.txt\n",
            "         073_001_001_02_10.txt\n",
            "         116_073_001_02_25.txt\n",
            "         072_052_002_04_08.txt\n",
            "         071_186_002_02_01.txt\n",
            "         071_120_002_04_08.txt\n",
            "         115_065_001_02_14.txt\n",
            "         071_156_002_04_17.txt\n",
            "         115_108_001_01_21.txt\n",
            "         115_084_003_01_01.txt\n",
            "         115_080_002_02_24.txt\n",
            "         071_035_002_05_06.txt\n",
            "         116_616_001_04_02.txt\n",
            "         115_065_003_02_21.txt\n",
            "         096_100_001_02_11.txt\n",
            "         072_054_001_04_11.txt\n",
            "         116_618_001_03_25.txt\n",
            "         115_087_003_02_12.txt\n",
            "         115_077_004_02_26.txt\n",
            "         116_639_001_02_15.txt\n",
            "         115_077_001_02_22.txt\n",
            "         116_627_001_03_02.txt\n",
            "         116_068_001_02_02.txt\n",
            "         071_132_001_04_08.txt\n",
            "         115_072_001_02_19.txt\n",
            "         115_012_001_01_11.txt\n",
            "         115_085_003_02_18.txt\n",
            "         072_094_004_04_14.txt\n",
            "         071_133_002_05_06.txt\n",
            "         071_163_004_04_13.txt\n",
            "         115_082_003_02_16.txt\n",
            "         035_320_001_02_08.txt\n",
            "         071_140_001_04_13.txt\n",
            "         072_051_002_04_02.txt\n",
            "         073_001_001_02_18.txt\n",
            "         115_087_001_02_22.txt\n",
            "         115_075_003_02_15.txt\n",
            "         071_107_001_04_18.txt\n",
            "         115_076_001_02_08.txt\n",
            "         071_182_001_02_01.txt\n",
            "         115_075_004_02_23.txt\n",
            "         115_084_004_02_07.txt\n",
            "         115_087_003_02_02.txt\n",
            "         071_131_004_05_16.txt\n",
            "         072_101_003_04_13.txt\n",
            "         116_642_002_02_01.txt\n",
            "         115_070_002_02_10.txt\n",
            "         115_082_004_02_17.txt\n",
            "         002_080_001_03_06.txt\n",
            "         115_012_001_01_12.txt\n",
            "         115_075_001_03_12.txt\n",
            "         072_210_001_04_19.txt\n",
            "         071_186_004_04_17.txt\n",
            "         116_066_001_02_08.txt\n",
            "         116_063_001_02_07.txt\n",
            "         116_244_001_01_03.txt\n",
            "         115_110_003_02_09.txt\n",
            "         071_133_002_05_13.txt\n",
            "         072_051_002_04_12.txt\n",
            "         115_087_002_02_07.txt\n",
            "         115_010_001_02_24.txt\n",
            "         071_107_002_04_15.txt\n",
            "         115_065_003_02_07.txt\n",
            "         115_080_002_02_13.txt\n",
            "         115_076_001_02_04.txt\n",
            "         071_164_001_04_06.txt\n",
            "         072_036_002_04_02.txt\n",
            "         116_078_001_02_31.txt\n",
            "         072_103_002_04_05.txt\n",
            "         116_633_002_02_25.txt\n",
            "         115_070_002_02_11.txt\n",
            "         115_070_001_02_16.txt\n",
            "         071_201_001_04_05.txt\n",
            "         115_084_003_02_17.txt\n",
            "         072_094_004_04_09.txt\n",
            "         071_010_003_04_21.txt\n",
            "         071_163_003_04_01.txt\n",
            "         115_110_001_03_05.txt\n",
            "         115_007_003_02_24.txt\n",
            "         116_626_002_02_28.txt\n",
            "         116_642_002_02_25.txt\n",
            "         071_146_002_04_10.txt\n",
            "         115_072_003_02_09.txt\n",
            "         071_018_003_04_18.txt\n",
            "         116_631_001_02_16.txt\n",
            "         115_080_002_02_28.txt\n",
            "         116_290_001_03_08.txt\n",
            "         071_167_002_04_10.txt\n",
            "         116_291_001_04_16.txt\n",
            "         072_049_002_04_19.txt\n",
            "         116_642_001_02_04.txt\n",
            "         071_140_001_04_02.txt\n",
            "         116_625_001_02_24.txt\n",
            "         116_607_001_03_06.txt\n",
            "         071_021_002_04_11.txt\n",
            "         096_051_004_03_12.txt\n",
            "         072_213_001_03_01.txt\n",
            "         071_182_001_03_01.txt\n",
            "         071_131_004_05_14.txt\n",
            "         116_636_002_02_36.txt\n",
            "         096_024_001_02_22.txt\n",
            "         116_287_002_02_22.txt\n",
            "         116_131_001_01_01.txt\n",
            "         115_080_001_02_16.txt\n",
            "         035_327_001_02_14.txt\n",
            "         071_163_003_04_03.txt\n",
            "         116_405_003_01_16.txt\n",
            "         071_032_002_04_26.txt\n",
            "         071_133_002_05_02.txt\n",
            "         116_063_001_02_24.txt\n",
            "         071_181_003_04_04.txt\n",
            "         115_108_002_01_04.txt\n",
            "         116_287_001_03_19.txt\n",
            "         115_083_001_02_20.txt\n",
            "         115_009_003_02_26.txt\n",
            "         096_052_002_03_26.txt\n",
            "         115_082_004_02_05.txt\n",
            "         116_291_002_02_18.txt\n",
            "         073_073_001_03_17.txt\n",
            "         071_042_001_04_18.txt\n",
            "         115_011_001_02_24.txt\n",
            "         116_630_002_02_07.txt\n",
            "         115_085_003_02_30.txt\n",
            "         073_056_001_03_02.txt\n",
            "         096_053_004_03_27.txt\n",
            "         072_169_003_04_04.txt\n",
            "         073_058_001_03_07.txt\n",
            "         071_156_002_04_08.txt\n",
            "         071_163_001_03_01.txt\n",
            "         072_050_001_04_04.txt\n",
            "         071_180_003_05_21.txt\n",
            "         096_100_002_01_13.txt\n",
            "         116_643_002_02_02.txt\n",
            "         116_286_002_02_02.txt\n",
            "         071_184_004_04_07.txt\n",
            "         115_067_002_02_28.txt\n",
            "         073_067_001_03_19.txt\n",
            "         115_080_004_02_08.txt\n",
            "         115_073_001_02_30.txt\n",
            "         115_083_002_02_25.txt\n",
            "         071_008_004_03_20.txt\n",
            "         115_012_001_01_36.txt\n",
            "         071_141_003_04_09.txt\n",
            "         115_086_001_02_26.txt\n",
            "         072_071_004_04_24.txt\n",
            "         115_069_001_02_12.txt\n",
            "         072_052_002_04_22.txt\n",
            "         073_059_001_01_04.txt\n",
            "         116_300_002_02_10.txt\n",
            "         002_121_001_02_09.txt\n",
            "         071_128_003_04_11.txt\n",
            "         071_180_003_05_07.txt\n",
            "         115_087_003_02_06.txt\n",
            "         096_100_002_01_11.txt\n",
            "         115_076_001_02_05.txt\n",
            "         071_181_004_04_03.txt\n",
            "         071_003_004_04_24.txt\n",
            "         096_118_001_01_23.txt\n",
            "         071_157_002_04_04.txt\n",
            "         073_001_001_02_09.txt\n",
            "         073_073_001_03_24.txt\n",
            "         073_067_001_03_22.txt\n",
            "         116_627_002_03_26.txt\n",
            "         072_103_002_04_10.txt\n",
            "         072_051_002_04_04.txt\n",
            "         116_064_001_02_03.txt\n",
            "         071_106_002_04_05.txt\n",
            "         035_320_001_02_09.txt\n",
            "         097_186_001_01_14.txt\n",
            "         116_078_001_02_30.txt\n",
            "         071_156_002_04_15.txt\n",
            "         071_184_003_04_12.txt\n",
            "         115_101_003_02_29.txt\n",
            "         072_103_001_05_02.txt\n",
            "         116_405_002_01_20.txt\n",
            "         116_290_001_04_24.txt\n",
            "         071_202_001_04_07.txt\n",
            "         071_043_004_04_25.txt\n",
            "         116_100_002_01_11.txt\n",
            "         115_080_004_02_27.txt\n",
            "         115_009_003_02_17.txt\n",
            "         115_011_002_02_01.txt\n",
            "         071_159_002_04_03.txt\n",
            "         116_068_001_02_17.txt\n",
            "         035_321_001_02_06.txt\n",
            "         071_139_003_04_04.txt\n",
            "         115_007_003_02_05.txt\n",
            "         096_051_004_03_11.txt\n",
            "         116_064_001_02_07.txt\n",
            "         072_070_002_06_08.txt\n",
            "         096_099_003_02_16.txt\n",
            "         115_082_003_02_01.txt\n",
            "         072_051_003_01_01.txt\n",
            "         116_291_002_02_04.txt\n",
            "         071_133_002_04_10.txt\n",
            "         116_620_001_03_16.txt\n",
            "         116_627_002_03_30.txt\n",
            "         071_018_003_04_19.txt\n",
            "         115_009_003_02_06.txt\n",
            "         116_625_001_02_01.txt\n",
            "         115_110_004_03_04.txt\n",
            "         071_142_001_02_01.txt\n",
            "         115_070_001_02_28.txt\n",
            "         071_105_003_03_01.txt\n",
            "         072_050_001_04_05.txt\n",
            "         072_105_001_04_01.txt\n",
            "         072_050_002_04_24.txt\n",
            "         071_184_002_04_11.txt\n",
            "         071_132_001_04_07.txt\n",
            "         071_183_004_04_01.txt\n",
            "         115_087_003_02_18.txt\n",
            "         116_619_001_03_20.txt\n",
            "         115_067_003_02_25.txt\n",
            "         116_627_001_03_22.txt\n",
            "         116_387_001_01_14.txt\n",
            "         116_055_001_02_06.txt\n",
            "         035_324_001_02_02.txt\n",
            "         115_008_001_02_15.txt\n",
            "         071_201_003_04_04.txt\n",
            "         115_080_004_02_02.txt\n",
            "         071_102_003_05_05.txt\n",
            "         116_631_002_02_02.txt\n",
            "         071_169_004_05_05.txt\n",
            "         071_183_004_04_06.txt\n",
            "         073_003_001_01_01.txt\n",
            "         116_286_002_02_26.txt\n",
            "         116_627_001_03_03.txt\n",
            "         073_073_001_02_01.txt\n",
            "         072_054_001_04_20.txt\n",
            "         115_111_004_02_26.txt\n",
            "         072_168_003_04_14.txt\n",
            "         072_072_001_01_01.txt\n",
            "         115_085_004_02_17.txt\n",
            "         115_077_003_02_12.txt\n",
            "         116_275_001_02_10.txt\n",
            "         116_064_001_02_33.txt\n",
            "         072_100_002_03_01.txt\n",
            "         115_108_003_01_04.txt\n",
            "         072_051_003_04_10.txt\n",
            "         071_035_003_04_06.txt\n",
            "         115_110_003_02_12.txt\n",
            "         073_063_001_03_05.txt\n",
            "         035_327_001_02_06.txt\n",
            "         072_168_003_04_07.txt\n",
            "         115_070_002_02_03.txt\n",
            "         115_078_002_02_16.txt\n",
            "         115_086_001_02_25.txt\n",
            "         116_616_001_03_19.txt\n",
            "         115_101_001_02_04.txt\n",
            "         072_047_002_04_06.txt\n",
            "         116_642_001_02_25.txt\n",
            "         096_039_001_01_02.txt\n",
            "         115_087_001_02_11.txt\n",
            "         115_087_002_02_12.txt\n",
            "         115_111_004_02_23.txt\n",
            "         071_054_001_03_01.txt\n",
            "         116_648_001_01_01.txt\n",
            "         002_112_001_03_06.txt\n",
            "         071_184_004_04_15.txt\n",
            "         071_146_003_03_01.txt\n",
            "         035_324_001_02_03.txt\n",
            "         116_633_002_02_16.txt\n",
            "         035_321_001_02_13.txt\n",
            "         096_098_003_01_19.txt\n",
            "         115_111_004_02_17.txt\n",
            "         073_083_001_03_03.txt\n",
            "         116_100_001_01_38.txt\n",
            "         073_053_001_02_01.txt\n",
            "         072_167_004_04_10.txt\n",
            "         072_047_002_04_16.txt\n",
            "         072_072_001_04_17.txt\n",
            "         071_162_001_04_19.txt\n",
            "         073_031_001_04_05.txt\n",
            "         073_002_002_01_15.txt\n",
            "         096_099_003_02_19.txt\n",
            "         071_164_001_04_09.txt\n",
            "         115_084_001_02_27.txt\n",
            "         002_080_001_03_04.txt\n",
            "         116_287_001_03_02.txt\n",
            "         116_392_001_04_04.txt\n",
            "         071_163_003_04_04.txt\n",
            "         115_083_002_02_16.txt\n",
            "         072_070_002_04_09.txt\n",
            "         072_069_002_05_05.txt\n",
            "         116_046_001_03_02.txt\n",
            "         002_112_001_03_21.txt\n",
            "         071_107_002_04_07.txt\n",
            "         115_070_001_02_08.txt\n",
            "         071_002_003_04_21.txt\n",
            "         072_054_003_04_06.txt\n",
            "         115_073_002_02_24.txt\n",
            "         071_101_004_04_17.txt\n",
            "         096_051_001_02_17.txt\n",
            "         116_074_001_02_10.txt\n",
            "         073_003_001_02_19.txt\n",
            "         116_627_001_03_27.txt\n",
            "         096_008_004_01_01.txt\n",
            "         071_181_004_04_04.txt\n",
            "         116_294_002_02_11.txt\n",
            "         072_036_002_04_03.txt\n",
            "         071_146_001_04_04.txt\n",
            "         072_100_003_04_11.txt\n",
            "         072_169_003_04_12.txt\n",
            "         035_327_001_02_21.txt\n",
            "         071_043_003_04_15.txt\n",
            "         073_072_002_03_07.txt\n",
            "         115_011_002_02_08.txt\n",
            "         116_275_001_02_12.txt\n",
            "         072_100_001_04_04.txt\n",
            "         116_244_001_01_08.txt\n",
            "         115_009_003_02_24.txt\n",
            "         073_060_001_03_21.txt\n",
            "         115_108_003_01_21.txt\n",
            "         115_009_002_02_03.txt\n",
            "         071_133_002_05_09.txt\n",
            "         115_010_002_02_04.txt\n",
            "         115_082_004_02_20.txt\n",
            "         116_392_001_08_01.txt\n",
            "         115_108_002_01_18.txt\n",
            "         071_030_001_04_12.txt\n",
            "         115_010_002_02_05.txt\n",
            "         116_393_003_03_12.txt\n",
            "         115_007_001_02_20.txt\n",
            "         071_043_003_04_18.txt\n",
            "         073_072_002_03_22.txt\n",
            "         115_087_001_02_25.txt\n",
            "         115_108_001_01_24.txt\n",
            "         071_168_004_05_08.txt\n",
            "         071_181_001_04_12.txt\n",
            "         071_042_001_04_19.txt\n",
            "         096_024_001_02_14.txt\n",
            "         115_101_002_01_09.txt\n",
            "         116_046_001_02_02.txt\n",
            "         071_159_003_04_10.txt\n",
            "         096_024_001_02_11.txt\n",
            "         115_101_001_02_21.txt\n",
            "         071_184_002_04_08.txt\n",
            "         071_010_003_04_23.txt\n",
            "         071_131_002_04_07.txt\n",
            "         115_078_002_02_18.txt\n",
            "         035_320_001_02_01.txt\n",
            "         071_129_002_04_13.txt\n",
            "         096_100_003_01_11.txt\n",
            "         115_010_001_02_28.txt\n",
            "         115_102_001_02_15.txt\n",
            "         071_112_003_04_08.txt\n",
            "         071_166_001_04_18.txt\n",
            "         115_085_004_02_03.txt\n",
            "         116_626_002_02_06.txt\n",
            "         116_078_001_02_34.txt\n",
            "         115_108_001_01_03.txt\n",
            "         115_067_003_02_02.txt\n",
            "         072_169_003_04_10.txt\n",
            "         115_083_002_02_02.txt\n",
            "         035_321_001_02_18.txt\n",
            "         116_405_004_01_08.txt\n",
            "         115_108_002_01_02.txt\n",
            "         096_002_002_01_01.txt\n",
            "         071_035_003_05_05.txt\n",
            "         073_050_001_02_15.txt\n",
            "         073_003_001_02_08.txt\n",
            "         071_141_001_04_01.txt\n",
            "         096_015_002_02_08.txt\n",
            "         072_050_003_04_11.txt\n",
            "         071_164_002_03_01.txt\n",
            "         071_184_001_04_11.txt\n",
            "         071_165_003_04_02.txt\n",
            "         071_120_002_05_08.txt\n",
            "         116_295_001_02_01.txt\n",
            "         071_185_002_02_01.txt\n",
            "         115_065_002_02_04.txt\n",
            "         115_082_002_02_28.txt\n",
            "         071_180_003_05_08.txt\n",
            "         072_100_001_01_01.txt\n",
            "         071_002_003_04_02.txt\n",
            "         116_074_001_02_36.txt\n",
            "         116_291_002_02_02.txt\n",
            "         071_184_004_04_09.txt\n",
            "         115_076_002_02_19.txt\n",
            "         116_074_001_02_44.txt\n",
            "         116_405_002_01_13.txt\n",
            "         096_002_002_01_04.txt\n",
            "         115_085_004_02_01.txt\n",
            "         071_181_003_04_18.txt\n",
            "         071_112_001_04_05.txt\n",
            "         072_105_001_04_05.txt\n",
            "         115_102_001_02_28.txt\n",
            "         071_182_002_04_06.txt\n",
            "         115_078_001_02_13.txt\n",
            "         116_291_002_02_27.txt\n",
            "         071_107_002_01_01.txt\n",
            "         096_051_004_03_17.txt\n",
            "         072_031_001_03_05.txt\n",
            "         116_286_002_02_25.txt\n",
            "         096_003_002_01_18.txt\n",
            "         115_101_002_01_12.txt\n",
            "         072_100_001_04_03.txt\n",
            "         072_100_002_04_01.txt\n",
            "         116_649_001_03_19.txt\n",
            "         096_052_002_03_12.txt\n",
            "         071_192_004_04_21.txt\n",
            "         115_070_001_02_02.txt\n",
            "         071_109_001_04_12.txt\n",
            "         096_118_001_01_19.txt\n",
            "         072_070_002_06_18.txt\n",
            "         116_067_001_02_18.txt\n",
            "         096_051_001_02_05.txt\n",
            "         071_003_003_04_09.txt\n",
            "         116_617_001_03_13.txt\n",
            "         072_066_001_04_22.txt\n",
            "         071_108_002_04_12.txt\n",
            "         071_021_002_04_08.txt\n",
            "         071_168_003_05_13.txt\n",
            "         071_139_003_04_10.txt\n",
            "         071_036_001_04_01.txt\n",
            "         071_151_003_04_05.txt\n",
            "         071_133_003_04_11.txt\n",
            "         116_616_001_04_01.txt\n",
            "         073_070_001_03_21.txt\n",
            "         115_087_003_02_01.txt\n",
            "         115_070_001_02_13.txt\n",
            "         116_294_001_03_05.txt\n",
            "         115_101_003_02_09.txt\n",
            "         115_086_003_02_16.txt\n",
            "         115_007_002_01_08.txt\n",
            "         116_076_001_02_06.txt\n",
            "         115_076_001_02_27.txt\n",
            "         116_620_001_03_01.txt\n",
            "         115_087_004_02_26.txt\n",
            "         115_087_003_02_16.txt\n",
            "         071_044_003_04_11.txt\n",
            "         115_111_001_02_20.txt\n",
            "         115_111_002_02_10.txt\n",
            "         116_275_001_03_01.txt\n",
            "         116_649_001_03_01.txt\n",
            "         071_101_002_04_06.txt\n",
            "         115_087_004_02_24.txt\n",
            "         073_074_001_03_10.txt\n",
            "         115_084_003_02_32.txt\n",
            "         096_015_002_01_06.txt\n",
            "         115_111_003_02_11.txt\n",
            "         071_141_003_04_18.txt\n",
            "         071_163_003_04_08.txt\n",
            "         116_627_001_03_18.txt\n",
            "         116_063_001_02_29.txt\n",
            "         115_107_003_01_16.txt\n",
            "         115_107_002_01_03.txt\n",
            "         071_185_001_04_16.txt\n",
            "         071_169_004_05_10.txt\n",
            "         116_641_001_02_13.txt\n",
            "         073_069_001_03_17.txt\n",
            "         071_181_001_04_06.txt\n",
            "         072_052_002_04_07.txt\n",
            "         116_074_001_02_24.txt\n",
            "         096_038_003_01_02.txt\n",
            "         071_188_002_03_12.txt\n",
            "         096_018_002_01_14.txt\n",
            "         115_082_001_02_20.txt\n",
            "         071_181_003_03_01.txt\n",
            "         115_107_003_01_13.txt\n",
            "         073_056_001_03_06.txt\n",
            "         071_180_004_04_03.txt\n",
            "         071_018_002_05_04.txt\n",
            "         096_052_002_03_08.txt\n",
            "         072_094_004_04_02.txt\n",
            "         071_146_002_03_01.txt\n",
            "         071_035_002_06_02.txt\n",
            "         115_011_001_02_03.txt\n",
            "         071_202_001_04_02.txt\n",
            "         035_321_001_02_19.txt\n",
            "         115_110_001_02_07.txt\n",
            "         115_009_001_03_17.txt\n",
            "         115_007_004_02_19.txt\n",
            "         115_076_001_02_24.txt\n",
            "         116_641_001_02_08.txt\n",
            "         072_103_004_04_14.txt\n",
            "         116_076_001_02_15.txt\n",
            "         073_002_002_01_17.txt\n",
            "         071_131_004_04_01.txt\n",
            "         071_053_004_03_06.txt\n",
            "         115_069_001_02_31.txt\n",
            "         116_275_001_01_06.txt\n",
            "         071_184_003_04_14.txt\n",
            "         072_066_003_04_08.txt\n",
            "         073_055_001_03_16.txt\n",
            "         096_100_001_02_13.txt\n",
            "         116_627_001_03_14.txt\n",
            "         116_393_003_03_11.txt\n",
            "         071_166_001_04_17.txt\n",
            "         072_054_003_03_13.txt\n",
            "         035_328_001_02_02.txt\n",
            "         115_112_002_02_21.txt\n",
            "         116_405_001_01_01.txt\n",
            "         072_052_002_04_14.txt\n",
            "         115_011_001_02_29.txt\n",
            "         116_641_001_02_28.txt\n",
            "         072_168_003_04_13.txt\n",
            "         116_071_001_03_17.txt\n",
            "         115_075_001_03_06.txt\n",
            "         071_166_001_02_01.txt\n",
            "         073_001_001_02_05.txt\n",
            "         072_094_004_04_15.txt\n",
            "         071_146_003_05_12.txt\n",
            "         002_080_001_03_07.txt\n",
            "         115_108_003_01_15.txt\n",
            "         071_141_001_04_12.txt\n",
            "         071_165_003_05_06.txt\n",
            "         115_070_002_02_22.txt\n",
            "         116_606_001_03_17.txt\n",
            "         071_130_003_03_01.txt\n",
            "         115_107_001_01_20.txt\n",
            "         096_003_002_01_14.txt\n",
            "         116_405_004_01_17.txt\n",
            "         072_049_001_04_05.txt\n",
            "         116_636_002_02_34.txt\n",
            "         116_648_001_03_52.txt\n",
            "         071_186_004_04_12.txt\n",
            "         096_052_002_03_09.txt\n",
            "         073_074_002_03_04.txt\n",
            "         116_275_001_03_12.txt\n",
            "         073_051_001_03_05.txt\n",
            "         115_086_004_02_28.txt\n",
            "         115_007_003_02_10.txt\n",
            "         071_010_002_03_01.txt\n",
            "         071_141_001_04_08.txt\n",
            "         115_087_002_02_05.txt\n",
            "         071_030_001_04_06.txt\n",
            "         115_067_003_02_20.txt\n",
            "         071_105_003_04_08.txt\n",
            "         071_053_004_03_08.txt\n",
            "         116_627_002_03_25.txt\n",
            "         073_056_001_03_15.txt\n",
            "         115_083_002_02_24.txt\n",
            "         116_387_001_01_16.txt\n",
            "         116_639_002_02_11.txt\n",
            "         115_101_001_02_08.txt\n",
            "         071_132_001_04_09.txt\n",
            "         073_002_001_02_19.txt\n",
            "         116_627_001_03_05.txt\n",
            "         115_084_002_02_15.txt\n",
            "         096_008_002_02_11.txt\n",
            "         115_107_001_01_03.txt\n",
            "         116_301_002_02_01.txt\n",
            "         115_086_004_02_03.txt\n",
            "         116_630_002_02_03.txt\n",
            "         115_087_002_02_25.txt\n",
            "         115_009_002_02_19.txt\n",
            "         072_071_004_04_23.txt\n",
            "         096_002_002_01_14.txt\n",
            "         072_051_002_04_03.txt\n",
            "         073_060_001_03_07.txt\n",
            "         116_279_002_03_19.txt\n",
            "         115_073_001_02_19.txt\n",
            "         071_053_003_03_18.txt\n",
            "         071_131_002_04_21.txt\n",
            "         115_110_003_02_10.txt\n",
            "         115_078_002_02_39.txt\n",
            "         072_210_002_04_18.txt\n",
            "         115_067_004_02_03.txt\n",
            "         116_280_001_03_11.txt\n",
            "         115_082_002_02_04.txt\n",
            "         072_103_001_05_11.txt\n",
            "         071_163_003_04_06.txt\n",
            "         116_631_001_02_11.txt\n",
            "         071_010_003_04_11.txt\n",
            "         071_002_002_04_10.txt\n",
            "         115_111_003_02_04.txt\n",
            "         072_103_004_01_01.txt\n",
            "         116_287_002_02_30.txt\n",
            "         072_102_003_04_05.txt\n",
            "         072_100_001_04_17.txt\n",
            "         096_008_004_01_18.txt\n",
            "         071_163_001_01_01.txt\n",
            "         072_168_003_01_01.txt\n",
            "         096_038_003_01_14.txt\n",
            "         115_079_001_02_18.txt\n",
            "         115_107_001_01_12.txt\n",
            "         116_393_003_03_04.txt\n",
            "         116_626_002_02_15.txt\n",
            "         071_168_004_05_03.txt\n",
            "         002_541_001_02_18.txt\n",
            "         116_642_002_01_01.txt\n",
            "         096_024_001_02_04.txt\n",
            "         115_080_001_02_02.txt\n",
            "         096_002_003_02_11.txt\n",
            "         071_105_003_04_09.txt\n",
            "         073_072_002_03_18.txt\n",
            "         096_100_002_01_09.txt\n",
            "         115_007_004_02_03.txt\n",
            "         115_111_004_02_18.txt\n",
            "         116_074_001_02_06.txt\n",
            "         073_070_001_03_04.txt\n",
            "         115_077_001_02_11.txt\n",
            "         072_101_003_02_01.txt\n",
            "         072_094_004_04_20.txt\n",
            "         071_185_004_04_12.txt\n",
            "         096_032_004_01_01.txt\n",
            "         071_053_003_03_02.txt\n",
            "         115_108_002_01_05.txt\n",
            "         115_073_002_02_07.txt\n",
            "         096_051_002_03_07.txt\n",
            "         071_111_002_04_18.txt\n",
            "         115_077_001_02_18.txt\n",
            "         035_328_001_02_22.txt\n",
            "         116_405_002_01_08.txt\n",
            "         115_010_001_02_19.txt\n",
            "         115_007_003_02_18.txt\n",
            "         116_303_002_02_22.txt\n",
            "         096_098_004_01_05.txt\n",
            "         115_084_004_02_04.txt\n",
            "         115_016_001_01_02.txt\n",
            "         115_065_004_02_08.txt\n",
            "         115_076_002_02_13.txt\n",
            "         115_007_001_02_19.txt\n",
            "         115_009_002_02_06.txt\n",
            "         073_072_002_01_01.txt\n",
            "         071_164_002_04_13.txt\n",
            "         071_139_004_04_10.txt\n",
            "         071_010_003_04_02.txt\n",
            "         072_048_003_02_01.txt\n",
            "         071_102_001_04_20.txt\n",
            "         073_067_001_03_09.txt\n",
            "         071_102_001_05_03.txt\n",
            "         116_406_001_01_23.txt\n",
            "         071_112_003_04_09.txt\n",
            "         115_102_001_02_05.txt\n",
            "         072_103_001_04_01.txt\n",
            "         116_074_001_02_22.txt\n",
            "         116_648_001_03_36.txt\n",
            "         115_073_002_01_01.txt\n",
            "         071_157_001_04_01.txt\n",
            "         116_279_001_03_16.txt\n",
            "         071_139_003_04_16.txt\n",
            "         116_295_001_03_09.txt\n",
            "         096_032_004_02_06.txt\n",
            "         116_133_001_02_31.txt\n",
            "         071_201_003_04_01.txt\n",
            "         115_112_003_02_19.txt\n",
            "         071_168_004_05_13.txt\n",
            "         116_300_002_02_12.txt\n",
            "         071_030_001_04_04.txt\n",
            "         071_129_002_04_05.txt\n",
            "         071_163_002_04_08.txt\n",
            "         071_035_002_06_12.txt\n",
            "         073_003_001_02_13.txt\n",
            "         116_074_001_02_03.txt\n",
            "         116_303_002_02_12.txt\n",
            "         071_162_001_04_10.txt\n",
            "         071_186_002_04_20.txt\n",
            "         071_053_003_03_21.txt\n",
            "         073_003_001_02_14.txt\n",
            "         072_105_002_04_07.txt\n",
            "         115_107_003_01_19.txt\n",
            "         096_003_002_01_09.txt\n",
            "         116_405_002_01_23.txt\n",
            "         072_054_001_04_21.txt\n",
            "         073_072_003_01_18.txt\n",
            "         073_070_002_03_09.txt\n",
            "         115_111_001_02_27.txt\n",
            "         071_108_001_04_03.txt\n",
            "         073_070_001_03_06.txt\n",
            "         116_076_001_02_11.txt\n",
            "         027_029_001_02_03.txt\n",
            "         116_073_001_02_11.txt\n",
            "         071_169_001_01_01.txt\n",
            "         115_081_001_02_02.txt\n",
            "         073_068_001_01_01.txt\n",
            "         115_077_002_02_16.txt\n",
            "         116_295_001_03_24.txt\n",
            "         071_129_002_04_07.txt\n",
            "         072_069_002_05_09.txt\n",
            "         071_010_002_04_21.txt\n",
            "         071_101_004_02_01.txt\n",
            "         115_010_001_02_06.txt\n",
            "         116_068_001_02_15.txt\n",
            "         072_168_003_04_19.txt\n",
            "         115_083_001_02_10.txt\n",
            "         115_081_001_03_23.txt\n",
            "         071_054_001_03_20.txt\n",
            "         116_286_002_02_15.txt\n",
            "         115_065_002_02_09.txt\n",
            "         115_084_002_02_23.txt\n",
            "         071_129_002_04_09.txt\n",
            "         071_103_002_04_01.txt\n",
            "         115_077_001_02_16.txt\n",
            "         116_301_002_02_05.txt\n",
            "         071_035_002_02_01.txt\n",
            "         072_100_001_04_15.txt\n",
            "         071_021_002_04_05.txt\n",
            "         071_184_004_04_17.txt\n",
            "         071_201_001_04_13.txt\n",
            "         072_048_003_04_01.txt\n",
            "         115_078_001_02_06.txt\n",
            "         115_078_002_02_20.txt\n",
            "         071_169_004_05_01.txt\n",
            "         071_106_001_04_19.txt\n",
            "         071_053_004_03_07.txt\n",
            "         115_107_002_01_23.txt\n",
            "         116_648_001_03_11.txt\n",
            "         115_086_004_02_19.txt\n",
            "         072_066_001_04_09.txt\n",
            "         115_082_004_02_10.txt\n",
            "         072_210_004_04_06.txt\n",
            "         115_011_001_02_36.txt\n",
            "         115_108_001_01_15.txt\n",
            "         073_070_002_03_21.txt\n",
            "         116_639_002_02_03.txt\n",
            "         073_071_003_03_20.txt\n",
            "         116_063_001_02_23.txt\n",
            "         116_633_002_02_13.txt\n",
            "         072_210_001_04_07.txt\n",
            "         116_064_001_02_23.txt\n",
            "         115_086_001_02_05.txt\n",
            "         115_076_002_02_10.txt\n",
            "         071_185_002_04_02.txt\n",
            "         115_007_004_02_26.txt\n",
            "         097_186_001_01_22.txt\n",
            "         096_052_002_03_04.txt\n",
            "         072_094_003_03_02.txt\n",
            "         096_015_002_01_09.txt\n",
            "         115_077_004_02_03.txt\n",
            "         116_063_001_02_34.txt\n",
            "         115_076_001_02_02.txt\n",
            "         115_112_001_02_24.txt\n",
            "         073_070_002_03_06.txt\n",
            "         096_052_002_03_22.txt\n",
            "         116_405_003_01_15.txt\n",
            "         071_130_003_04_15.txt\n",
            "         116_133_001_02_33.txt\n",
            "         072_101_004_04_03.txt\n",
            "         071_129_002_05_04.txt\n",
            "         115_110_004_03_03.txt\n",
            "         116_626_002_02_25.txt\n",
            "         115_075_004_02_28.txt\n",
            "         115_080_001_02_22.txt\n",
            "         072_105_002_04_15.txt\n",
            "         071_141_001_04_24.txt\n",
            "         116_393_003_03_02.txt\n",
            "         071_043_004_04_18.txt\n",
            "         115_101_002_01_02.txt\n",
            "         071_101_004_04_07.txt\n",
            "         071_164_001_04_18.txt\n",
            "         116_649_001_03_21.txt\n",
            "         073_058_001_03_05.txt\n",
            "         071_168_004_05_09.txt\n",
            "         096_051_002_03_01.txt\n",
            "         116_643_001_02_02.txt\n",
            "         096_034_004_01_17.txt\n",
            "         072_051_002_04_10.txt\n",
            "         115_009_003_02_03.txt\n",
            "         116_405_003_01_22.txt\n",
            "         072_049_004_04_07.txt\n",
            "         115_016_001_01_25.txt\n",
            "         071_085_004_04_11.txt\n",
            "         035_320_001_02_20.txt\n",
            "         116_071_001_03_09.txt\n",
            "         116_073_001_02_02.txt\n",
            "         116_275_001_01_01.txt\n",
            "         071_168_004_05_12.txt\n",
            "         116_294_002_02_31.txt\n",
            "         071_144_002_04_20.txt\n",
            "         071_184_004_04_13.txt\n",
            "         072_047_002_04_11.txt\n",
            "         071_186_002_04_18.txt\n",
            "         073_053_001_03_18.txt\n",
            "         116_280_001_03_04.txt\n",
            "         073_072_001_01_01.txt\n",
            "         071_182_004_05_06.txt\n",
            "         072_054_001_04_16.txt\n",
            "         071_182_004_05_05.txt\n",
            "         071_164_001_04_17.txt\n",
            "         071_184_004_01_01.txt\n",
            "         071_188_002_03_07.txt\n",
            "         073_068_001_03_19.txt\n",
            "         071_108_001_04_17.txt\n",
            "         115_084_001_02_04.txt\n",
            "         071_053_003_03_11.txt\n",
            "         116_625_001_02_38.txt\n",
            "         072_049_004_04_12.txt\n",
            "         071_141_001_04_18.txt\n",
            "         115_076_001_02_34.txt\n",
            "         071_182_001_04_01.txt\n",
            "         116_633_001_02_27.txt\n",
            "         072_094_003_04_17.txt\n",
            "         115_012_001_01_04.txt\n",
            "         071_133_002_05_04.txt\n",
            "         071_186_003_04_20.txt\n",
            "         116_287_001_03_23.txt\n",
            "         116_291_002_02_15.txt\n",
            "         116_071_001_03_25.txt\n",
            "         116_290_001_04_20.txt\n",
            "         096_038_003_01_09.txt\n",
            "         115_111_003_02_03.txt\n",
            "         115_082_001_02_06.txt\n",
            "         073_031_001_04_09.txt\n",
            "         072_101_002_04_04.txt\n",
            "         072_054_003_02_01.txt\n",
            "         072_102_002_05_02.txt\n",
            "         072_210_002_04_22.txt\n",
            "         115_086_001_02_23.txt\n",
            "         072_069_002_04_09.txt\n",
            "         071_107_002_03_01.txt\n",
            "         071_151_003_04_07.txt\n",
            "         073_071_003_03_09.txt\n",
            "         116_286_002_02_23.txt\n",
            "         116_387_001_01_01.txt\n",
            "         115_082_004_02_31.txt\n",
            "         071_128_001_05_03.txt\n",
            "         072_167_004_02_01.txt\n",
            "         071_131_004_05_21.txt\n",
            "         096_099_003_02_04.txt\n",
            "         073_070_001_03_22.txt\n",
            "         116_648_001_03_48.txt\n",
            "         072_101_004_02_01.txt\n",
            "         072_100_003_02_01.txt\n",
            "         116_400_001_03_01.txt\n",
            "         071_101_002_04_16.txt\n",
            "         071_201_003_04_11.txt\n",
            "         116_633_002_02_29.txt\n",
            "         071_163_002_04_18.txt\n",
            "         071_184_002_04_02.txt\n",
            "         072_102_003_04_18.txt\n",
            "         116_279_002_03_28.txt\n",
            "         115_112_001_02_13.txt\n",
            "         071_146_001_04_10.txt\n",
            "         071_186_004_04_09.txt\n",
            "         072_102_002_03_01.txt\n",
            "         072_051_003_04_03.txt\n",
            "         071_108_002_04_20.txt\n",
            "         072_210_001_04_14.txt\n",
            "         115_080_003_02_26.txt\n",
            "         071_146_001_03_01.txt\n",
            "         116_627_001_01_01.txt\n",
            "         115_081_001_03_16.txt\n",
            "         072_054_003_03_03.txt\n",
            "         115_007_001_02_05.txt\n",
            "         116_055_001_01_01.txt\n",
            "         115_075_001_02_05.txt\n",
            "         071_129_002_04_21.txt\n",
            "         115_082_004_02_33.txt\n",
            "         072_094_003_04_02.txt\n",
            "         116_626_002_02_30.txt\n",
            "         002_541_001_02_16.txt\n",
            "         071_181_003_04_13.txt\n",
            "         072_210_001_04_03.txt\n",
            "         035_323_001_03_05.txt\n",
            "         071_184_001_04_09.txt\n",
            "         027_029_001_02_12.txt\n",
            "         071_003_004_01_01.txt\n",
            "         072_210_004_04_03.txt\n",
            "         002_121_001_02_08.txt\n",
            "         096_028_001_02_01.txt\n",
            "         115_070_001_02_17.txt\n",
            "         115_107_001_01_28.txt\n",
            "         072_169_002_03_01.txt\n",
            "         071_159_001_02_01.txt\n",
            "         115_111_004_02_25.txt\n",
            "         073_069_001_03_01.txt\n",
            "         073_003_001_02_20.txt\n",
            "         071_165_003_04_15.txt\n",
            "         096_101_001_02_12.txt\n",
            "         072_066_002_04_01.txt\n",
            "         073_051_001_03_18.txt\n",
            "         115_087_002_02_29.txt\n",
            "         072_094_003_04_23.txt\n",
            "         096_032_003_01_08.txt\n",
            "         096_008_002_02_03.txt\n",
            "         072_103_001_05_08.txt\n",
            "         071_103_002_04_08.txt\n",
            "         072_066_003_04_07.txt\n",
            "         071_101_002_04_05.txt\n",
            "         071_042_001_04_05.txt\n",
            "         116_288_001_03_23.txt\n",
            "         072_103_004_04_19.txt\n",
            "         116_648_001_03_16.txt\n",
            "         071_008_004_03_17.txt\n",
            "         072_213_001_04_06.txt\n",
            "         096_002_003_02_07.txt\n",
            "         073_063_001_03_18.txt\n",
            "         096_038_003_01_07.txt\n",
            "         116_133_001_02_27.txt\n",
            "         096_052_002_03_01.txt\n",
            "         115_087_004_02_22.txt\n",
            "         071_159_001_05_01.txt\n",
            "         072_069_002_04_08.txt\n",
            "         071_159_001_05_02.txt\n",
            "         035_325_001_02_13.txt\n",
            "         115_007_002_01_11.txt\n",
            "         071_185_001_04_02.txt\n",
            "         071_162_001_03_01.txt\n",
            "         072_051_002_04_06.txt\n",
            "         071_030_001_04_29.txt\n",
            "         073_069_001_03_07.txt\n",
            "         072_054_002_02_01.txt\n",
            "         115_007_002_01_26.txt\n",
            "         073_074_001_03_17.txt\n",
            "         096_100_002_01_07.txt\n",
            "         116_639_002_02_07.txt\n",
            "         096_118_001_01_13.txt\n",
            "         071_003_004_04_05.txt\n",
            "         071_159_003_04_04.txt\n",
            "         116_639_001_02_26.txt\n",
            "         002_112_001_03_15.txt\n",
            "         116_046_001_03_12.txt\n",
            "         071_168_004_05_04.txt\n",
            "         115_077_001_02_03.txt\n",
            "         072_066_002_04_20.txt\n",
            "         071_181_003_04_06.txt\n",
            "         072_049_004_04_02.txt\n",
            "         116_400_001_03_21.txt\n",
            "         071_010_003_04_18.txt\n",
            "         115_083_002_02_23.txt\n",
            "         115_079_001_02_02.txt\n",
            "         096_099_003_02_05.txt\n",
            "         072_049_002_04_14.txt\n",
            "         072_210_004_04_01.txt\n",
            "         115_073_002_02_15.txt\n",
            "         071_201_001_04_06.txt\n",
            "         116_067_001_02_01.txt\n",
            "         116_633_001_02_22.txt\n",
            "         116_616_001_04_05.txt\n",
            "         073_001_001_02_04.txt\n",
            "         072_101_002_03_01.txt\n",
            "         115_112_002_02_26.txt\n",
            "         116_405_002_01_01.txt\n",
            "         073_050_001_02_02.txt\n",
            "         096_032_004_02_10.txt\n",
            "         115_088_001_02_08.txt\n",
            "         071_112_001_04_16.txt\n",
            "         115_011_002_02_28.txt\n",
            "         115_008_002_02_19.txt\n",
            "         116_290_001_04_10.txt\n",
            "         116_294_002_02_18.txt\n",
            "         096_018_002_01_10.txt\n",
            "         116_393_003_03_13.txt\n",
            "         073_002_002_01_22.txt\n",
            "         096_100_001_02_03.txt\n",
            "         116_290_001_04_01.txt\n",
            "         027_029_001_02_14.txt\n",
            "         072_169_003_02_01.txt\n",
            "         115_107_003_01_09.txt\n",
            "         072_167_003_04_12.txt\n",
            "         071_163_002_04_21.txt\n",
            "         115_110_004_03_06.txt\n",
            "         096_118_001_01_25.txt\n",
            "         073_056_001_03_22.txt\n",
            "         072_105_001_03_01.txt\n",
            "         116_648_001_03_35.txt\n",
            "         071_112_001_04_11.txt\n",
            "         116_136_001_01_06.txt\n",
            "         116_100_001_01_37.txt\n",
            "         073_061_001_03_19.txt\n",
            "         073_070_001_03_02.txt\n",
            "         115_072_003_02_13.txt\n",
            "         116_301_002_02_13.txt\n",
            "         115_067_004_02_31.txt\n",
            "         116_072_001_02_25.txt\n",
            "         115_082_004_02_21.txt\n",
            "         072_048_003_04_18.txt\n",
            "         116_067_001_02_29.txt\n",
            "         072_049_001_02_01.txt\n",
            "         115_087_002_02_15.txt\n",
            "         115_008_002_02_20.txt\n",
            "         115_065_004_02_22.txt\n",
            "         116_400_001_03_24.txt\n",
            "         115_108_002_01_20.txt\n",
            "         115_011_002_02_20.txt\n",
            "         027_029_001_02_10.txt\n",
            "         072_102_004_05_10.txt\n",
            "         072_051_003_04_07.txt\n",
            "         115_077_003_02_21.txt\n",
            "         116_633_002_02_08.txt\n",
            "         071_059_003_04_02.txt\n",
            "         072_031_001_03_18.txt\n",
            "         116_294_002_02_28.txt\n",
            "         072_169_002_04_09.txt\n",
            "         116_100_001_01_28.txt\n",
            "         072_036_002_04_18.txt\n",
            "         072_050_002_04_09.txt\n",
            "         115_076_002_02_15.txt\n",
            "         071_163_003_02_01.txt\n",
            "         116_643_002_02_11.txt\n",
            "         071_101_004_04_05.txt\n",
            "         071_182_001_05_06.txt\n",
            "         116_631_001_02_09.txt\n",
            "         116_619_001_03_16.txt\n",
            "         115_075_003_02_24.txt\n",
            "         115_009_002_02_26.txt\n",
            "         072_210_002_01_01.txt\n",
            "         072_094_003_01_01.txt\n",
            "         116_135_001_02_20.txt\n",
            "         115_065_002_02_17.txt\n",
            "         116_131_001_01_20.txt\n",
            "         071_185_004_04_02.txt\n",
            "         073_003_001_02_11.txt\n",
            "         072_100_001_04_08.txt\n",
            "         071_120_002_05_07.txt\n",
            "         116_133_001_02_26.txt\n",
            "         071_163_004_04_07.txt\n",
            "         071_101_004_04_24.txt\n",
            "         072_105_002_04_11.txt\n",
            "         115_079_001_02_13.txt\n",
            "         073_057_002_01_07.txt\n",
            "         071_109_001_04_08.txt\n",
            "         071_184_001_04_04.txt\n",
            "         116_055_001_02_08.txt\n",
            "         071_146_003_05_08.txt\n",
            "         071_140_001_04_10.txt\n",
            "         071_102_002_04_02.txt\n",
            "         071_128_001_05_04.txt\n",
            "         116_405_004_01_06.txt\n",
            "         116_387_001_01_06.txt\n",
            "         071_003_004_04_17.txt\n",
            "         116_400_001_03_30.txt\n",
            "         115_077_004_01_01.txt\n",
            "         071_159_002_04_08.txt\n",
            "         116_136_001_01_05.txt\n",
            "         073_071_002_01_11.txt\n",
            "         071_128_003_04_09.txt\n",
            "         071_141_003_04_08.txt\n",
            "         072_102_003_04_15.txt\n",
            "         071_044_003_04_09.txt\n",
            "         115_108_002_01_08.txt\n",
            "         116_100_001_01_04.txt\n",
            "         071_185_003_05_05.txt\n",
            "         071_163_001_04_13.txt\n",
            "         115_069_001_02_10.txt\n",
            "         115_086_001_02_12.txt\n",
            "         071_144_002_04_02.txt\n",
            "         072_049_002_04_18.txt\n",
            "         115_080_002_02_06.txt\n",
            "         116_641_001_02_26.txt\n",
            "         071_163_002_04_14.txt\n",
            "         073_063_001_03_22.txt\n",
            "         073_061_001_03_01.txt\n",
            "         071_128_001_04_03.txt\n",
            "         116_643_002_02_25.txt\n",
            "         071_184_002_03_01.txt\n",
            "         071_032_001_04_11.txt\n",
            "         072_031_001_03_11.txt\n",
            "         116_136_001_01_12.txt\n",
            "         115_080_004_02_07.txt\n",
            "         072_066_002_04_11.txt\n",
            "         097_186_001_01_08.txt\n",
            "         116_135_001_01_01.txt\n",
            "         071_184_002_04_16.txt\n",
            "         072_169_002_04_21.txt\n",
            "         096_039_001_01_01.txt\n",
            "         035_320_001_02_07.txt\n",
            "         072_210_004_04_14.txt\n",
            "         115_111_004_02_19.txt\n",
            "         116_618_001_03_02.txt\n",
            "         115_112_003_02_05.txt\n",
            "         115_110_003_02_18.txt\n",
            "         116_294_001_03_18.txt\n",
            "         116_405_002_01_11.txt\n",
            "         072_049_004_04_15.txt\n",
            "         071_186_002_03_01.txt\n",
            "         096_052_003_02_17.txt\n",
            "         115_082_001_02_29.txt\n",
            "         071_142_001_04_13.txt\n",
            "         071_002_002_04_09.txt\n",
            "         073_031_001_04_13.txt\n",
            "         035_328_001_02_09.txt\n",
            "         116_619_001_03_18.txt\n",
            "         096_034_004_01_15.txt\n",
            "         116_643_001_02_08.txt\n",
            "         115_110_001_01_01.txt\n",
            "         116_639_001_02_31.txt\n",
            "         071_185_003_04_12.txt\n",
            "         115_112_001_02_05.txt\n",
            "         071_184_003_04_15.txt\n",
            "         116_648_001_03_08.txt\n",
            "         115_075_003_02_23.txt\n",
            "         115_007_001_01_01.txt\n",
            "         116_131_001_01_17.txt\n",
            "         071_139_004_04_07.txt\n",
            "         116_400_001_03_03.txt\n",
            "         071_008_004_03_18.txt\n",
            "         071_184_001_02_01.txt\n",
            "         071_185_004_04_18.txt\n",
            "         115_072_001_02_07.txt\n",
            "         116_620_001_03_14.txt\n",
            "         072_049_004_04_01.txt\n",
            "         096_051_002_03_17.txt\n",
            "         115_087_003_02_11.txt\n",
            "         071_165_001_05_06.txt\n",
            "         116_625_001_02_18.txt\n",
            "         071_108_001_04_09.txt\n",
            "         071_140_001_04_15.txt\n",
            "         072_210_004_04_07.txt\n",
            "         096_051_001_02_08.txt\n",
            "         071_030_001_04_15.txt\n",
            "         073_053_001_03_24.txt\n",
            "         096_099_003_02_21.txt\n",
            "         072_099_001_04_17.txt\n",
            "         071_131_002_04_15.txt\n",
            "         072_099_001_04_07.txt\n",
            "         071_159_003_01_01.txt\n",
            "         071_159_003_04_03.txt\n",
            "         116_619_001_03_26.txt\n",
            "         115_111_001_02_08.txt\n",
            "         116_643_002_02_17.txt\n",
            "         116_064_001_02_39.txt\n",
            "         073_071_001_03_06.txt\n",
            "         071_183_004_04_18.txt\n",
            "         116_648_001_03_20.txt\n",
            "         115_065_003_02_09.txt\n",
            "         073_057_002_01_14.txt\n",
            "         116_294_001_03_22.txt\n",
            "         027_029_001_02_24.txt\n",
            "         115_077_003_02_05.txt\n",
            "         071_054_001_02_01.txt\n",
            "         115_111_004_02_16.txt\n",
            "         071_107_002_04_16.txt\n",
            "         115_079_001_02_07.txt\n",
            "         072_054_001_04_04.txt\n",
            "         115_112_003_02_24.txt\n",
            "         116_631_001_02_25.txt\n",
            "         071_182_004_04_12.txt\n",
            "         096_032_004_02_03.txt\n",
            "         115_085_004_02_13.txt\n",
            "         115_075_003_02_32.txt\n",
            "         116_290_001_04_09.txt\n",
            "         115_087_003_02_24.txt\n",
            "         073_072_001_03_12.txt\n",
            "         115_007_004_02_16.txt\n",
            "         116_631_002_02_03.txt\n",
            "         072_169_003_03_01.txt\n",
            "         071_010_003_02_01.txt\n",
            "         115_101_001_02_25.txt\n",
            "         096_051_004_03_20.txt\n",
            "         035_325_001_02_04.txt\n",
            "         116_133_001_02_25.txt\n",
            "         071_182_002_04_10.txt\n",
            "         071_035_002_05_05.txt\n",
            "         116_633_001_02_26.txt\n",
            "         072_099_001_02_01.txt\n",
            "         071_133_002_01_01.txt\n",
            "         035_328_001_02_05.txt\n",
            "         116_294_002_02_09.txt\n",
            "         115_087_002_02_28.txt\n",
            "         071_164_001_04_10.txt\n",
            "         116_387_001_01_13.txt\n",
            "         116_632_002_02_25.txt\n",
            "         071_053_003_03_03.txt\n",
            "         071_131_002_04_03.txt\n",
            "         116_626_002_02_12.txt\n",
            "         115_107_001_01_01.txt\n",
            "         071_043_004_04_15.txt\n",
            "         071_159_002_01_01.txt\n",
            "         115_016_003_01_13.txt\n",
            "         071_167_002_04_04.txt\n",
            "         096_099_003_01_01.txt\n",
            "         071_043_004_04_22.txt\n",
            "         115_080_001_02_03.txt\n",
            "         116_641_001_02_29.txt\n",
            "         071_002_002_04_17.txt\n",
            "         116_633_001_02_12.txt\n",
            "         071_165_003_05_05.txt\n",
            "         116_070_001_02_06.txt\n",
            "         071_010_002_04_15.txt\n",
            "         072_066_003_04_04.txt\n",
            "         115_112_002_02_23.txt\n",
            "         035_324_001_02_18.txt\n",
            "         002_121_001_02_16.txt\n",
            "         071_106_001_04_14.txt\n",
            "         071_130_003_04_20.txt\n",
            "         073_061_001_03_07.txt\n",
            "         116_641_001_02_21.txt\n",
            "         071_053_003_03_05.txt\n",
            "         072_212_001_04_13.txt\n",
            "         072_069_002_04_15.txt\n",
            "         071_162_001_04_03.txt\n",
            "         071_167_001_05_05.txt\n",
            "         072_054_002_04_09.txt\n",
            "         072_213_001_04_01.txt\n",
            "         071_106_002_04_08.txt\n",
            "         116_133_001_02_37.txt\n",
            "         116_618_001_03_23.txt\n",
            "         115_112_001_02_20.txt\n",
            "         072_049_004_02_01.txt\n",
            "         073_072_003_01_02.txt\n",
            "         115_083_001_02_12.txt\n",
            "         115_108_002_01_10.txt\n",
            "         073_071_001_03_15.txt\n",
            "         071_162_001_04_07.txt\n",
            "         072_054_002_04_04.txt\n",
            "         071_180_004_04_18.txt\n",
            "         116_627_002_03_23.txt\n",
            "         115_084_001_02_08.txt\n",
            "         072_104_002_04_12.txt\n",
            "         072_168_003_04_09.txt\n",
            "         071_010_002_02_01.txt\n",
            "         071_059_003_04_04.txt\n",
            "         071_035_003_05_02.txt\n",
            "         073_063_001_03_01.txt\n",
            "         116_636_002_02_32.txt\n",
            "         096_100_001_02_28.txt\n",
            "         071_181_002_04_03.txt\n",
            "         116_136_001_01_11.txt\n",
            "         073_001_001_02_06.txt\n",
            "         071_183_004_04_05.txt\n",
            "         115_111_003_02_16.txt\n",
            "         096_100_003_01_16.txt\n",
            "         115_102_001_01_01.txt\n",
            "         073_054_001_03_21.txt\n",
            "         116_275_001_02_14.txt\n",
            "         071_003_004_04_16.txt\n",
            "         071_102_001_04_06.txt\n",
            "         116_063_001_02_13.txt\n",
            "         116_068_001_02_09.txt\n",
            "         115_101_004_02_26.txt\n",
            "         072_051_002_03_01.txt\n",
            "         116_641_001_02_04.txt\n",
            "         096_099_004_01_03.txt\n",
            "         071_002_003_04_09.txt\n",
            "         116_287_002_02_27.txt\n",
            "         116_286_002_02_27.txt\n",
            "         115_083_001_02_04.txt\n",
            "         096_100_001_02_26.txt\n",
            "         071_181_003_04_12.txt\n",
            "         071_107_001_04_10.txt\n",
            "         071_054_001_03_06.txt\n",
            "         072_050_002_04_11.txt\n",
            "         072_049_004_04_03.txt\n",
            "         072_054_001_04_01.txt\n",
            "         115_087_001_02_20.txt\n",
            "         115_087_003_02_26.txt\n",
            "         115_067_002_02_23.txt\n",
            "         115_087_002_02_20.txt\n",
            "         115_086_004_02_16.txt\n",
            "         073_072_001_03_13.txt\n",
            "         073_071_001_03_01.txt\n",
            "         073_056_001_03_16.txt\n",
            "         072_070_002_05_03.txt\n",
            "         116_400_001_03_32.txt\n",
            "         096_052_003_02_07.txt\n",
            "         072_032_002_04_19.txt\n",
            "         115_078_001_02_02.txt\n",
            "         071_053_003_03_24.txt\n",
            "         072_213_001_02_01.txt\n",
            "         116_294_001_03_21.txt\n",
            "         115_102_001_02_22.txt\n",
            "         035_323_001_03_01.txt\n",
            "         115_085_003_02_07.txt\n",
            "         096_008_002_02_05.txt\n",
            "         072_105_001_04_04.txt\n",
            "         115_067_003_02_23.txt\n",
            "         096_100_001_02_22.txt\n",
            "         115_070_002_02_05.txt\n",
            "         115_086_004_02_23.txt\n",
            "         072_100_002_01_01.txt\n",
            "         071_030_001_04_27.txt\n",
            "         072_051_002_04_13.txt\n",
            "         115_111_004_02_03.txt\n",
            "         071_003_003_05_03.txt\n",
            "         072_168_001_04_15.txt\n",
            "         072_168_003_04_04.txt\n",
            "         071_144_002_04_03.txt\n",
            "         115_084_004_02_32.txt\n",
            "         115_080_003_02_03.txt\n",
            "         115_080_004_02_01.txt\n",
            "         071_140_001_03_02.txt\n",
            "         115_065_004_02_11.txt\n",
            "         115_111_002_02_09.txt\n",
            "         072_070_002_06_12.txt\n",
            "         071_106_001_04_15.txt\n",
            "         115_079_001_02_09.txt\n",
            "         115_078_001_02_03.txt\n",
            "         071_036_001_04_03.txt\n",
            "         071_030_001_04_17.txt\n",
            "         116_393_003_01_08.txt\n",
            "         072_101_003_04_05.txt\n",
            "         116_303_002_02_01.txt\n",
            "         115_067_004_02_04.txt\n",
            "         072_100_003_04_19.txt\n",
            "         116_642_002_02_05.txt\n",
            "         116_300_002_02_25.txt\n",
            "         073_071_003_03_08.txt\n",
            "         115_082_004_02_32.txt\n",
            "         115_112_001_02_18.txt\n",
            "         115_079_001_02_22.txt\n",
            "         071_146_002_06_01.txt\n",
            "         071_108_001_04_11.txt\n",
            "         096_017_003_02_13.txt\n",
            "         072_167_002_03_01.txt\n",
            "         096_034_004_01_10.txt\n",
            "         072_052_002_04_12.txt\n",
            "         072_049_004_04_22.txt\n",
            "         116_633_001_02_17.txt\n",
            "         071_181_001_04_03.txt\n",
            "         071_035_003_04_05.txt\n",
            "         096_099_004_01_04.txt\n",
            "         072_048_003_04_17.txt\n",
            "         115_065_003_01_01.txt\n",
            "         115_076_002_02_17.txt\n",
            "         072_105_001_04_19.txt\n",
            "         115_111_001_02_10.txt\n",
            "         072_070_002_04_08.txt\n",
            "         115_077_002_02_02.txt\n",
            "         116_617_001_03_19.txt\n",
            "         073_002_002_01_23.txt\n",
            "         096_053_004_02_01.txt\n",
            "         116_046_001_03_01.txt\n",
            "         115_078_001_02_23.txt\n",
            "         115_086_003_02_25.txt\n",
            "         115_073_002_02_21.txt\n",
            "         073_054_001_03_22.txt\n",
            "         071_144_002_02_01.txt\n",
            "         116_287_001_03_03.txt\n",
            "         115_011_002_02_29.txt\n",
            "         116_078_001_02_07.txt\n",
            "         116_627_002_03_05.txt\n",
            "         073_058_001_02_01.txt\n",
            "         116_619_001_03_19.txt\n",
            "         115_012_001_01_07.txt\n",
            "         071_162_001_04_16.txt\n",
            "         072_210_001_04_12.txt\n",
            "         071_156_002_04_11.txt\n",
            "         073_072_002_03_19.txt\n",
            "         115_083_002_02_08.txt\n",
            "         115_007_004_02_14.txt\n",
            "         073_067_001_03_03.txt\n",
            "         072_051_002_04_07.txt\n",
            "         072_101_003_04_15.txt\n",
            "         071_184_002_04_15.txt\n",
            "         096_017_003_02_03.txt\n",
            "         115_086_003_02_08.txt\n",
            "         116_046_001_02_06.txt\n",
            "         072_094_003_03_01.txt\n",
            "         116_633_001_02_29.txt\n",
            "         116_300_002_02_17.txt\n",
            "         115_069_001_02_09.txt\n",
            "         071_167_001_05_10.txt\n",
            "         071_181_004_02_01.txt\n",
            "         071_112_001_05_02.txt\n",
            "         096_051_002_03_14.txt\n",
            "         116_067_001_02_24.txt\n",
            "         072_049_001_04_06.txt\n",
            "         116_405_003_01_26.txt\n",
            "         116_063_001_02_15.txt\n",
            "         116_076_001_02_04.txt\n",
            "         115_083_001_01_01.txt\n",
            "         072_049_001_04_08.txt\n",
            "         116_136_001_01_24.txt\n",
            "         115_086_001_02_02.txt\n",
            "         072_101_003_04_20.txt\n",
            "         115_088_001_02_03.txt\n",
            "         096_003_002_01_19.txt\n",
            "         071_141_003_04_04.txt\n",
            "         115_070_002_02_12.txt\n",
            "         071_008_004_03_11.txt\n",
            "         115_107_001_01_04.txt\n",
            "         116_625_001_02_04.txt\n",
            "         071_108_002_04_03.txt\n",
            "         072_054_002_01_01.txt\n",
            "         096_051_004_03_02.txt\n",
            "         072_052_002_04_11.txt\n",
            "         072_105_001_04_02.txt\n",
            "         116_618_001_03_27.txt\n",
            "         115_087_001_02_27.txt\n",
            "         115_087_003_02_28.txt\n",
            "         073_051_001_03_15.txt\n",
            "         116_067_001_02_26.txt\n",
            "         071_181_001_04_01.txt\n",
            "         072_101_004_04_04.txt\n",
            "         115_075_001_02_07.txt\n",
            "         116_280_001_03_08.txt\n",
            "         115_087_001_02_17.txt\n",
            "         071_003_004_04_09.txt\n",
            "         116_607_001_03_12.txt\n",
            "         096_052_002_03_03.txt\n",
            "         073_072_001_03_20.txt\n",
            "         071_163_001_04_03.txt\n",
            "         073_001_003_01_27.txt\n",
            "         071_162_001_04_02.txt\n",
            "         073_053_001_03_10.txt\n",
            "         072_071_004_04_17.txt\n",
            "         115_067_003_02_14.txt\n",
            "         071_043_004_04_10.txt\n",
            "         115_008_001_02_11.txt\n",
            "         116_607_001_03_18.txt\n",
            "         116_287_002_02_29.txt\n",
            "         116_133_001_02_36.txt\n",
            "         002_121_001_02_05.txt\n",
            "         116_072_001_02_12.txt\n",
            "         116_406_001_01_29.txt\n",
            "         116_303_002_02_20.txt\n",
            "         072_105_002_04_12.txt\n",
            "         072_094_003_04_05.txt\n",
            "         071_010_003_04_03.txt\n",
            "         072_095_001_04_18.txt\n",
            "         116_625_001_02_34.txt\n",
            "         071_192_002_04_19.txt\n",
            "         071_032_002_04_04.txt\n",
            "         116_618_001_03_01.txt\n",
            "         115_083_001_02_13.txt\n",
            "         071_120_002_04_01.txt\n",
            "         002_541_001_02_15.txt\n",
            "         073_072_001_03_18.txt\n",
            "         072_210_004_04_21.txt\n",
            "         116_286_002_02_06.txt\n",
            "         073_001_001_02_07.txt\n",
            "         072_036_002_04_01.txt\n",
            "         071_164_002_04_09.txt\n",
            "         116_648_001_03_04.txt\n",
            "         115_101_003_02_27.txt\n",
            "         115_102_001_02_01.txt\n",
            "         116_648_001_03_38.txt\n",
            "         072_167_003_03_01.txt\n",
            "         115_101_001_02_31.txt\n",
            "         115_007_002_01_25.txt\n",
            "         071_202_001_04_17.txt\n",
            "         071_120_002_04_10.txt\n",
            "         116_619_001_03_10.txt\n",
            "         116_063_001_02_21.txt\n",
            "         115_067_002_02_19.txt\n",
            "         115_082_004_02_18.txt\n",
            "         071_186_002_04_08.txt\n",
            "         071_165_003_04_12.txt\n",
            "         115_072_003_02_18.txt\n",
            "         071_035_003_07_03.txt\n",
            "         071_139_003_04_14.txt\n",
            "         096_100_003_01_13.txt\n",
            "         035_323_001_03_16.txt\n",
            "         116_291_001_04_11.txt\n",
            "         115_080_003_02_15.txt\n",
            "         115_075_004_02_09.txt\n",
            "         115_081_001_03_18.txt\n",
            "         116_136_001_01_10.txt\n",
            "         096_052_003_02_24.txt\n",
            "         072_101_004_04_01.txt\n",
            "         073_071_002_01_09.txt\n",
            "         071_130_003_04_17.txt\n",
            "         115_067_004_02_13.txt\n",
            "         116_405_004_01_23.txt\n",
            "         072_103_001_03_01.txt\n",
            "         116_076_001_02_16.txt\n",
            "         071_044_003_02_01.txt\n",
            "         071_131_002_04_11.txt\n",
            "         072_071_004_04_18.txt\n",
            "         115_007_004_02_17.txt\n",
            "         071_159_003_04_06.txt\n",
            "         096_100_003_01_02.txt\n",
            "         072_069_002_04_02.txt\n",
            "         116_405_002_01_17.txt\n",
            "         071_182_004_04_03.txt\n",
            "         115_007_001_02_14.txt\n",
            "         071_201_003_04_13.txt\n",
            "         096_052_003_02_26.txt\n",
            "         115_080_001_02_01.txt\n",
            "         072_031_001_03_12.txt\n",
            "         116_294_001_03_29.txt\n",
            "         073_070_001_03_15.txt\n",
            "         072_213_001_03_02.txt\n",
            "         115_108_002_01_16.txt\n",
            "         116_055_001_02_31.txt\n",
            "         071_108_002_04_16.txt\n",
            "         071_010_003_04_04.txt\n",
            "         116_606_001_03_08.txt\n",
            "         115_108_001_01_20.txt\n",
            "         097_186_001_01_26.txt\n",
            "         073_054_001_03_17.txt\n",
            "         115_110_004_03_09.txt\n",
            "         115_111_003_02_13.txt\n",
            "         115_111_004_02_20.txt\n",
            "         096_021_003_02_07.txt\n",
            "         071_185_003_05_01.txt\n",
            "         072_210_002_04_06.txt\n",
            "         071_142_001_04_10.txt\n",
            "         116_078_001_02_29.txt\n",
            "         072_102_003_04_04.txt\n",
            "         072_103_002_04_03.txt\n",
            "         115_101_003_02_23.txt\n",
            "         116_295_001_03_01.txt\n",
            "         116_287_001_03_05.txt\n",
            "         096_100_003_01_14.txt\n",
            "         071_190_002_04_07.txt\n",
            "         115_084_001_02_23.txt\n",
            "         072_051_003_04_21.txt\n",
            "         071_163_002_04_12.txt\n",
            "         072_071_004_04_20.txt\n",
            "         071_192_004_04_12.txt\n",
            "         071_139_003_04_11.txt\n",
            "         073_002_002_01_20.txt\n",
            "         096_003_002_01_05.txt\n",
            "         116_633_001_02_02.txt\n",
            "         116_279_001_03_04.txt\n",
            "         097_172_002_01_15.txt\n",
            "         115_012_001_01_21.txt\n",
            "         115_077_004_02_08.txt\n",
            "         073_031_001_04_02.txt\n",
            "         071_169_001_05_11.txt\n",
            "         071_108_001_04_06.txt\n",
            "         072_066_004_03_01.txt\n",
            "         115_007_002_01_18.txt\n",
            "         115_077_004_02_06.txt\n",
            "         115_084_003_02_10.txt\n",
            "         072_050_003_04_20.txt\n",
            "         115_078_002_02_30.txt\n",
            "         071_185_004_04_09.txt\n",
            "         071_128_003_04_16.txt\n",
            "         115_065_001_02_22.txt\n",
            "         116_076_001_02_33.txt\n",
            "         071_035_002_04_01.txt\n",
            "         115_016_001_01_07.txt\n",
            "         116_631_001_02_34.txt\n",
            "         116_301_002_02_23.txt\n",
            "         116_280_001_03_02.txt\n",
            "         116_290_001_02_01.txt\n",
            "         116_279_002_03_06.txt\n",
            "         073_001_001_02_20.txt\n",
            "         073_071_002_01_10.txt\n",
            "         073_060_001_03_04.txt\n",
            "         072_210_001_01_01.txt\n",
            "         002_080_001_03_19.txt\n",
            "         115_009_004_02_29.txt\n",
            "         116_633_002_02_10.txt\n",
            "         115_077_003_02_25.txt\n",
            "         071_186_003_04_03.txt\n",
            "         071_131_002_04_25.txt\n",
            "         116_633_001_02_08.txt\n",
            "         071_035_002_06_07.txt\n",
            "         071_201_003_04_06.txt\n",
            "         072_169_003_04_01.txt\n",
            "         116_406_001_01_08.txt\n",
            "         116_393_003_03_07.txt\n",
            "         071_102_002_05_04.txt\n",
            "         116_626_002_02_11.txt\n",
            "         073_002_001_02_13.txt\n",
            "         072_049_002_04_15.txt\n",
            "         116_405_001_01_21.txt\n",
            "         072_051_002_04_20.txt\n",
            "         116_064_001_02_34.txt\n",
            "         116_063_001_02_03.txt\n",
            "         096_039_001_01_14.txt\n",
            "         115_112_003_02_22.txt\n",
            "         072_167_004_01_01.txt\n",
            "         116_626_002_02_19.txt\n",
            "         116_280_001_03_03.txt\n",
            "         002_080_001_03_02.txt\n",
            "         115_101_003_02_17.txt\n",
            "         071_018_003_01_01.txt\n",
            "         115_101_002_01_21.txt\n",
            "         115_007_003_02_20.txt\n",
            "         115_075_004_02_17.txt\n",
            "         071_018_002_05_18.txt\n",
            "         073_070_002_03_24.txt\n",
            "         002_121_001_02_10.txt\n",
            "         115_081_001_03_08.txt\n",
            "         073_074_001_02_01.txt\n",
            "         116_287_002_02_13.txt\n",
            "         115_075_003_02_18.txt\n",
            "         116_627_002_03_12.txt\n",
            "         071_181_002_04_02.txt\n",
            "         116_400_001_03_10.txt\n",
            "         071_128_001_05_06.txt\n",
            "         116_074_001_02_16.txt\n",
            "         071_141_001_01_01.txt\n",
            "         072_054_001_04_03.txt\n",
            "         071_164_001_04_01.txt\n",
            "         116_295_001_03_20.txt\n",
            "         116_078_001_02_20.txt\n",
            "         115_111_003_02_22.txt\n",
            "         002_112_001_03_14.txt\n",
            "         116_606_001_02_01.txt\n",
            "         115_111_001_02_02.txt\n",
            "         115_073_002_02_28.txt\n",
            "         071_164_001_04_08.txt\n",
            "         097_172_002_01_12.txt\n",
            "         073_002_001_02_24.txt\n",
            "         096_052_003_02_08.txt\n",
            "         116_100_002_01_04.txt\n",
            "         072_212_001_04_20.txt\n",
            "         073_068_001_03_18.txt\n",
            "         072_210_002_04_10.txt\n",
            "         071_107_002_04_02.txt\n",
            "         096_017_003_02_10.txt\n",
            "         002_121_001_02_07.txt\n",
            "         096_003_002_01_07.txt\n",
            "         116_632_002_02_22.txt\n",
            "         071_159_003_04_16.txt\n",
            "         073_059_001_01_08.txt\n",
            "         072_213_001_04_15.txt\n",
            "         071_111_001_03_01.txt\n",
            "         073_054_001_03_07.txt\n",
            "         072_101_002_04_16.txt\n",
            "         115_085_003_02_27.txt\n",
            "         071_168_003_05_16.txt\n",
            "         035_323_001_03_08.txt\n",
            "         115_080_004_02_04.txt\n",
            "         071_010_002_01_01.txt\n",
            "         072_169_003_04_09.txt\n",
            "         071_163_001_04_18.txt\n",
            "         115_083_002_02_22.txt\n",
            "         071_184_001_04_14.txt\n",
            "         116_405_003_01_25.txt\n",
            "         116_627_002_03_01.txt\n",
            "         071_141_001_04_11.txt\n",
            "         115_009_004_02_12.txt\n",
            "         115_087_001_02_07.txt\n",
            "         116_642_002_02_27.txt\n",
            "         071_165_003_04_08.txt\n",
            "         073_071_001_03_22.txt\n",
            "         116_626_002_02_05.txt\n",
            "         096_051_001_02_16.txt\n",
            "         115_101_003_01_01.txt\n",
            "         071_008_004_03_04.txt\n",
            "         073_072_003_01_17.txt\n",
            "         071_035_003_06_04.txt\n",
            "         072_031_001_03_02.txt\n",
            "         035_322_001_02_06.txt\n",
            "         115_107_002_01_05.txt\n",
            "         115_110_002_04_08.txt\n",
            "         072_049_001_04_07.txt\n",
            "         116_642_002_02_13.txt\n",
            "         116_067_001_02_15.txt\n",
            "         115_086_003_02_30.txt\n",
            "         002_541_001_02_17.txt\n",
            "         071_044_003_04_30.txt\n",
            "         071_044_003_04_07.txt\n",
            "         071_190_002_04_21.txt\n",
            "         115_081_001_03_02.txt\n",
            "         071_164_002_04_08.txt\n",
            "         072_212_001_02_01.txt\n",
            "         072_050_002_04_12.txt\n",
            "         115_070_002_02_04.txt\n",
            "         115_067_003_02_05.txt\n",
            "         071_030_001_04_31.txt\n",
            "         072_168_003_04_06.txt\n",
            "         096_021_003_02_04.txt\n",
            "         115_082_002_01_01.txt\n",
            "         073_056_001_03_19.txt\n",
            "         071_002_003_04_17.txt\n",
            "         116_072_001_02_03.txt\n",
            "         115_078_002_02_31.txt\n",
            "         071_131_004_05_19.txt\n",
            "         115_110_003_02_11.txt\n",
            "         035_321_001_02_24.txt\n",
            "         116_291_002_02_17.txt\n",
            "         116_642_002_02_11.txt\n",
            "         072_094_004_04_22.txt\n",
            "         073_031_001_04_15.txt\n",
            "         115_111_001_02_14.txt\n",
            "         115_108_002_01_23.txt\n",
            "         072_105_001_04_12.txt\n",
            "         097_186_001_01_24.txt\n",
            "         071_181_003_04_15.txt\n",
            "         071_181_001_04_17.txt\n",
            "         072_069_002_05_01.txt\n",
            "         115_065_004_02_20.txt\n",
            "         115_101_004_01_01.txt\n",
            "         072_047_002_04_19.txt\n",
            "         073_052_001_03_14.txt\n",
            "         115_110_003_02_02.txt\n",
            "         071_107_002_04_09.txt\n",
            "         072_069_002_03_01.txt\n",
            "         072_168_001_04_01.txt\n",
            "         116_131_001_01_21.txt\n",
            "         116_616_001_04_08.txt\n",
            "         071_168_003_05_11.txt\n",
            "         071_141_001_04_19.txt\n",
            "         071_201_003_04_21.txt\n",
            "         115_080_002_02_18.txt\n",
            "         071_156_002_04_12.txt\n",
            "         071_117_002_05_07.txt\n",
            "         115_067_002_02_20.txt\n",
            "         115_078_002_02_07.txt\n",
            "         116_405_004_01_05.txt\n",
            "         072_094_004_04_04.txt\n",
            "         072_212_001_04_19.txt\n",
            "         116_643_001_02_29.txt\n",
            "         096_098_003_01_10.txt\n",
            "         072_167_004_04_14.txt\n",
            "         071_192_002_04_07.txt\n",
            "         115_073_001_02_28.txt\n",
            "         071_201_001_04_03.txt\n",
            "         035_328_001_02_08.txt\n",
            "         073_049_002_01_01.txt\n",
            "         116_279_001_03_20.txt\n",
            "         116_287_002_02_26.txt\n",
            "         116_288_001_03_28.txt\n",
            "         071_164_001_04_04.txt\n",
            "         115_112_002_02_12.txt\n",
            "         116_632_002_02_02.txt\n",
            "         115_075_004_01_01.txt\n",
            "         115_084_003_02_22.txt\n",
            "         115_078_002_02_32.txt\n",
            "         116_400_001_03_19.txt\n",
            "         096_099_003_02_15.txt\n",
            "         072_047_002_01_01.txt\n",
            "         071_120_001_05_08.txt\n",
            "         116_074_001_02_25.txt\n",
            "         071_032_002_04_03.txt\n",
            "         116_625_001_02_10.txt\n",
            "         071_129_002_04_20.txt\n",
            "         116_066_001_02_22.txt\n",
            "         071_021_002_03_01.txt\n",
            "         115_101_004_02_15.txt\n",
            "         071_159_003_04_12.txt\n",
            "         072_105_002_04_14.txt\n",
            "         115_078_002_02_02.txt\n",
            "         115_111_001_02_03.txt\n",
            "         115_073_002_02_04.txt\n",
            "         072_103_001_04_04.txt\n",
            "         072_051_002_04_01.txt\n",
            "         071_010_002_04_03.txt\n",
            "         072_104_002_01_01.txt\n",
            "         115_101_001_02_11.txt\n",
            "         115_078_001_02_20.txt\n",
            "         115_077_003_02_14.txt\n",
            "         116_625_001_02_25.txt\n",
            "         115_111_001_02_11.txt\n",
            "         035_327_001_02_08.txt\n",
            "         071_185_004_04_05.txt\n",
            "         115_087_001_02_26.txt\n",
            "         071_181_004_04_09.txt\n",
            "         115_084_002_01_01.txt\n",
            "         072_069_002_04_07.txt\n",
            "         115_085_004_02_02.txt\n",
            "         071_146_003_05_04.txt\n",
            "         116_643_002_02_18.txt\n",
            "         071_159_002_04_02.txt\n",
            "         115_070_001_02_11.txt\n",
            "         071_139_004_04_23.txt\n",
            "         115_079_001_02_05.txt\n",
            "         071_044_003_04_26.txt\n",
            "         115_012_001_01_15.txt\n",
            "         073_074_002_03_20.txt\n",
            "         073_083_001_03_06.txt\n",
            "         071_159_001_05_08.txt\n",
            "         071_181_001_04_07.txt\n",
            "         071_168_004_04_04.txt\n",
            "         096_051_004_03_18.txt\n",
            "         071_163_002_04_16.txt\n",
            "         115_111_004_02_21.txt\n",
            "         116_100_002_01_08.txt\n",
            "         115_011_002_02_38.txt\n",
            "         072_213_001_01_01.txt\n",
            "         116_631_001_02_29.txt\n",
            "         073_063_001_03_12.txt\n",
            "         116_636_002_02_22.txt\n",
            "         115_080_002_02_22.txt\n",
            "         116_275_001_02_11.txt\n",
            "         116_286_002_02_19.txt\n",
            "         115_101_001_02_27.txt\n",
            "         096_099_003_02_23.txt\n",
            "         116_626_002_02_20.txt\n",
            "         073_050_001_02_21.txt\n",
            "         116_607_001_03_14.txt\n",
            "         115_077_002_02_27.txt\n",
            "         035_322_001_02_09.txt\n",
            "         115_076_001_02_33.txt\n",
            "         073_053_001_03_08.txt\n",
            "         116_632_002_02_20.txt\n",
            "         115_084_002_02_03.txt\n",
            "         071_164_002_04_16.txt\n",
            "         115_067_002_02_01.txt\n",
            "         071_131_002_04_16.txt\n",
            "         115_082_001_02_03.txt\n",
            "         096_032_004_02_01.txt\n",
            "         115_083_001_02_16.txt\n",
            "         071_144_002_04_17.txt\n",
            "         115_008_001_02_12.txt\n",
            "         071_163_003_04_18.txt\n",
            "         116_392_001_04_01.txt\n",
            "         116_617_001_03_05.txt\n",
            "         116_648_001_03_19.txt\n",
            "         096_099_003_02_02.txt\n",
            "         115_012_001_01_33.txt\n",
            "         072_105_001_04_03.txt\n",
            "         071_144_002_04_19.txt\n",
            "         116_617_001_03_12.txt\n",
            "         096_038_003_01_08.txt\n",
            "         072_168_003_03_01.txt\n",
            "         071_107_001_04_13.txt\n",
            "         115_084_002_02_17.txt\n",
            "         116_287_002_02_16.txt\n",
            "         115_070_001_02_10.txt\n",
            "         072_048_003_04_22.txt\n",
            "         116_618_001_03_19.txt\n",
            "         116_133_001_02_14.txt\n",
            "         115_110_004_03_17.txt\n",
            "         116_100_001_01_09.txt\n",
            "         035_325_001_02_10.txt\n",
            "         115_011_001_02_38.txt\n",
            "         071_169_002_05_18.txt\n",
            "         115_065_001_02_16.txt\n",
            "         115_011_001_02_11.txt\n",
            "         116_100_001_01_32.txt\n",
            "         071_163_002_02_01.txt\n",
            "         115_087_004_02_20.txt\n",
            "         071_108_002_04_04.txt\n",
            "         116_636_002_02_25.txt\n",
            "         071_032_002_04_15.txt\n",
            "         115_070_001_02_30.txt\n",
            "         073_071_003_03_23.txt\n",
            "         116_642_002_02_15.txt\n",
            "         072_066_001_04_16.txt\n",
            "         071_164_001_04_13.txt\n",
            "         073_053_001_03_02.txt\n",
            "         071_163_004_04_06.txt\n",
            "         116_641_001_02_03.txt\n",
            "         072_100_002_04_05.txt\n",
            "         115_080_003_02_11.txt\n",
            "         116_616_001_04_03.txt\n",
            "         072_168_003_04_21.txt\n",
            "         116_617_001_03_15.txt\n",
            "         071_128_003_04_10.txt\n",
            "         116_627_002_03_04.txt\n",
            "         115_076_002_02_05.txt\n",
            "         072_167_004_04_06.txt\n",
            "         071_101_003_04_18.txt\n",
            "         116_290_001_04_15.txt\n",
            "         071_035_002_05_08.txt\n",
            "         115_075_001_03_18.txt\n",
            "         116_068_001_01_03.txt\n",
            "         071_106_001_04_10.txt\n",
            "         073_056_001_03_23.txt\n",
            "         116_291_001_04_12.txt\n",
            "         116_630_002_02_26.txt\n",
            "         116_136_001_01_13.txt\n",
            "         096_101_001_02_13.txt\n",
            "         115_083_002_02_26.txt\n",
            "         115_086_001_02_09.txt\n",
            "         096_052_003_02_13.txt\n",
            "         072_066_004_02_01.txt\n",
            "         071_139_003_04_06.txt\n",
            "         071_032_002_04_27.txt\n",
            "         072_052_002_01_01.txt\n",
            "         115_086_001_02_06.txt\n",
            "         116_063_001_02_18.txt\n",
            "         116_135_001_02_04.txt\n",
            "         116_648_001_03_24.txt\n",
            "         115_067_002_02_30.txt\n",
            "         116_617_001_03_02.txt\n",
            "         116_406_001_01_22.txt\n",
            "         116_617_001_03_07.txt\n",
            "         096_034_004_01_12.txt\n",
            "         115_009_001_03_24.txt\n",
            "         071_112_003_04_10.txt\n",
            "         096_003_002_01_04.txt\n",
            "         071_159_002_03_02.txt\n",
            "         071_184_001_04_03.txt\n",
            "         116_405_004_01_24.txt\n",
            "         072_054_003_03_16.txt\n",
            "         073_001_001_02_11.txt\n",
            "         116_606_001_03_09.txt\n",
            "         073_031_001_04_04.txt\n",
            "         116_279_002_03_12.txt\n",
            "         071_018_002_04_04.txt\n",
            "         071_141_003_04_02.txt\n",
            "         115_016_001_01_19.txt\n",
            "         116_627_001_03_01.txt\n",
            "         115_084_002_02_28.txt\n",
            "         115_016_003_01_15.txt\n",
            "         073_056_001_03_11.txt\n",
            "         071_146_003_04_04.txt\n",
            "         115_111_003_02_25.txt\n",
            "         071_182_002_05_09.txt\n",
            "         115_101_001_02_06.txt\n",
            "         115_082_002_02_13.txt\n",
            "         116_630_002_02_30.txt\n",
            "         072_167_003_04_15.txt\n",
            "         002_579_001_02_02.txt\n",
            "         116_406_001_01_18.txt\n",
            "         071_101_002_01_01.txt\n",
            "         115_101_004_02_08.txt\n",
            "         071_181_003_04_01.txt\n",
            "         116_078_001_02_06.txt\n",
            "         071_102_001_04_12.txt\n",
            "         116_100_001_01_31.txt\n",
            "         116_066_001_02_15.txt\n",
            "         071_146_003_05_06.txt\n",
            "         072_102_004_04_10.txt\n",
            "         115_112_001_02_03.txt\n",
            "         072_103_004_04_01.txt\n",
            "         071_053_003_03_04.txt\n",
            "         115_087_001_02_13.txt\n",
            "         071_107_001_04_02.txt\n",
            "         115_108_001_01_05.txt\n",
            "         071_128_001_05_19.txt\n",
            "         115_009_004_02_27.txt\n",
            "         115_077_001_02_15.txt\n",
            "         115_110_004_03_01.txt\n",
            "         073_069_001_03_05.txt\n",
            "         071_163_003_04_12.txt\n",
            "         115_069_001_02_29.txt\n",
            "         116_068_001_01_01.txt\n",
            "         071_101_004_03_01.txt\n",
            "         096_099_003_02_08.txt\n",
            "         115_080_001_02_15.txt\n",
            "         071_185_001_04_09.txt\n",
            "         116_068_001_02_08.txt\n",
            "         116_649_001_03_07.txt\n",
            "         115_010_001_02_14.txt\n",
            "         072_047_002_04_13.txt\n",
            "         116_642_001_02_01.txt\n",
            "         073_001_003_01_03.txt\n",
            "         071_042_001_04_12.txt\n",
            "         072_102_004_04_09.txt\n",
            "         071_053_003_03_22.txt\n",
            "         115_088_001_01_01.txt\n",
            "         115_008_001_02_18.txt\n",
            "         071_106_001_04_12.txt\n",
            "         072_102_003_04_06.txt\n",
            "         071_146_001_04_11.txt\n",
            "         071_117_002_01_01.txt\n",
            "         116_288_001_03_06.txt\n",
            "         116_405_004_01_15.txt\n",
            "         096_098_003_01_02.txt\n",
            "         071_184_004_04_05.txt\n",
            "         115_072_001_02_28.txt\n",
            "         071_163_002_04_09.txt\n",
            "         072_047_002_04_04.txt\n",
            "         071_169_002_05_10.txt\n",
            "         115_084_003_02_19.txt\n",
            "         071_159_003_04_19.txt\n",
            "         115_087_004_02_11.txt\n",
            "         116_405_003_01_21.txt\n",
            "         096_002_003_02_03.txt\n",
            "         073_068_001_03_12.txt\n",
            "         071_108_002_04_11.txt\n",
            "         073_053_001_03_06.txt\n",
            "         071_129_002_04_01.txt\n",
            "         072_212_001_04_10.txt\n",
            "         071_101_003_04_07.txt\n",
            "         072_031_001_03_04.txt\n",
            "         072_103_002_04_04.txt\n",
            "         071_159_003_04_15.txt\n",
            "         096_003_002_01_20.txt\n",
            "         115_007_003_02_17.txt\n",
            "         073_002_001_01_01.txt\n",
            "         071_157_002_04_11.txt\n",
            "         115_112_001_02_10.txt\n",
            "         072_168_001_04_11.txt\n",
            "         116_055_001_02_39.txt\n",
            "         072_168_003_04_05.txt\n",
            "         071_163_002_04_01.txt\n",
            "         073_063_001_03_08.txt\n",
            "         071_181_003_04_16.txt\n",
            "         071_053_003_03_16.txt\n",
            "         097_186_001_01_31.txt\n",
            "         071_018_002_05_19.txt\n",
            "         116_617_001_03_08.txt\n",
            "         073_068_001_03_09.txt\n",
            "         115_110_004_03_16.txt\n",
            "         071_158_002_04_06.txt\n",
            "         116_400_001_03_14.txt\n",
            "         071_102_002_03_01.txt\n",
            "         096_100_002_01_16.txt\n",
            "         035_320_001_02_10.txt\n",
            "         115_107_002_01_21.txt\n",
            "         116_068_001_02_27.txt\n",
            "         002_121_001_02_14.txt\n",
            "         115_082_003_02_17.txt\n",
            "         115_110_003_02_04.txt\n",
            "         116_620_001_03_23.txt\n",
            "         116_648_001_03_29.txt\n",
            "         116_072_001_02_11.txt\n",
            "         071_129_002_02_01.txt\n",
            "         071_129_002_04_16.txt\n",
            "         115_084_004_02_23.txt\n",
            "         116_288_001_03_22.txt\n",
            "         115_077_003_02_11.txt\n",
            "         096_051_004_01_01.txt\n",
            "         115_107_002_01_16.txt\n",
            "         071_130_003_04_18.txt\n",
            "         116_290_001_04_27.txt\n",
            "         116_631_001_02_26.txt\n",
            "         073_069_001_03_22.txt\n",
            "         116_303_002_02_09.txt\n",
            "         116_072_001_02_21.txt\n",
            "         072_071_004_04_22.txt\n",
            "         071_158_002_04_11.txt\n",
            "         071_107_002_04_03.txt\n",
            "         116_643_001_02_30.txt\n",
            "         115_080_004_02_15.txt\n",
            "         115_075_001_02_01.txt\n",
            "         115_070_002_02_02.txt\n",
            "         096_099_003_02_24.txt\n",
            "         115_008_001_02_19.txt\n",
            "         071_201_001_04_02.txt\n",
            "         115_085_004_02_07.txt\n",
            "         071_003_004_04_22.txt\n",
            "         072_050_003_04_15.txt\n",
            "         115_107_002_01_18.txt\n",
            "         072_036_002_04_17.txt\n",
            "         073_050_001_02_12.txt\n",
            "         073_050_001_02_17.txt\n",
            "         071_101_004_04_09.txt\n",
            "         071_185_002_04_11.txt\n",
            "         072_031_001_03_14.txt\n",
            "         116_406_001_01_17.txt\n",
            "         116_131_001_01_08.txt\n",
            "         071_180_004_04_21.txt\n",
            "         115_087_004_02_15.txt\n",
            "         035_320_001_02_24.txt\n",
            "         071_112_001_04_12.txt\n",
            "         071_117_002_05_14.txt\n",
            "         116_642_001_02_17.txt\n",
            "         072_213_001_04_11.txt\n",
            "         116_630_002_02_05.txt\n",
            "         116_301_002_02_21.txt\n",
            "         115_016_003_01_28.txt\n",
            "         115_087_001_02_16.txt\n",
            "         073_072_001_03_01.txt\n",
            "         115_084_002_02_31.txt\n",
            "         072_036_002_04_13.txt\n",
            "         116_066_001_02_01.txt\n",
            "         027_029_001_02_06.txt\n",
            "         096_118_001_01_01.txt\n",
            "         071_054_001_03_23.txt\n",
            "         071_128_003_03_01.txt\n",
            "         115_007_004_02_22.txt\n",
            "         035_323_001_03_15.txt\n",
            "         072_105_002_04_08.txt\n",
            "         071_169_004_05_12.txt\n",
            "         071_003_004_04_12.txt\n",
            "         116_279_002_03_04.txt\n",
            "         116_287_001_03_20.txt\n",
            "         071_157_001_04_15.txt\n",
            "         116_620_001_03_27.txt\n",
            "         116_392_001_06_05.txt\n",
            "         071_131_002_04_22.txt\n",
            "         115_076_001_02_06.txt\n",
            "         071_166_001_04_20.txt\n",
            "         116_625_001_02_15.txt\n",
            "         072_210_004_04_10.txt\n",
            "         116_632_002_02_11.txt\n",
            "         116_620_001_01_01.txt\n",
            "         116_301_002_02_11.txt\n",
            "         073_072_002_03_08.txt\n",
            "         072_210_001_04_15.txt\n",
            "         096_052_002_03_18.txt\n",
            "         115_110_003_02_25.txt\n",
            "         071_156_002_04_10.txt\n",
            "         096_003_002_01_16.txt\n",
            "         096_051_001_02_10.txt\n",
            "         115_084_004_02_12.txt\n",
            "         116_641_001_02_31.txt\n",
            "         072_050_003_04_22.txt\n",
            "         115_101_003_02_12.txt\n",
            "         116_135_001_02_23.txt\n",
            "         116_643_002_02_09.txt\n",
            "         071_201_001_04_18.txt\n",
            "         115_084_003_02_18.txt\n",
            "         072_094_003_04_07.txt\n",
            "         071_190_002_04_01.txt\n",
            "         071_128_001_05_15.txt\n",
            "         071_192_004_04_04.txt\n",
            "         072_168_003_04_17.txt\n",
            "         035_325_001_01_01.txt\n",
            "         071_105_003_04_04.txt\n",
            "         073_052_001_03_07.txt\n",
            "         072_101_004_04_02.txt\n",
            "         115_070_002_02_17.txt\n",
            "         115_112_001_02_09.txt\n",
            "         071_130_003_01_01.txt\n",
            "         071_164_002_04_01.txt\n",
            "         071_003_004_03_01.txt\n",
            "         071_163_004_04_15.txt\n",
            "         071_002_003_04_15.txt\n",
            "         116_627_001_02_01.txt\n",
            "         116_633_002_02_30.txt\n",
            "         115_007_002_01_09.txt\n",
            "         116_639_002_02_30.txt\n",
            "         096_015_002_02_07.txt\n",
            "         071_018_002_05_15.txt\n",
            "         073_083_001_03_20.txt\n",
            "         071_159_001_05_06.txt\n",
            "         115_107_003_01_12.txt\n",
            "         071_128_001_05_01.txt\n",
            "         071_169_001_05_20.txt\n",
            "         115_065_002_02_29.txt\n",
            "         071_201_001_04_16.txt\n",
            "         115_087_001_02_18.txt\n",
            "         071_182_002_05_01.txt\n",
            "         035_322_001_01_01.txt\n",
            "         115_067_004_02_28.txt\n",
            "         071_018_003_04_12.txt\n",
            "         071_002_002_04_20.txt\n",
            "         071_120_002_05_04.txt\n",
            "         072_210_004_03_01.txt\n",
            "         071_117_002_05_02.txt\n",
            "         115_110_004_03_22.txt\n",
            "         073_049_002_01_05.txt\n",
            "         116_135_001_02_26.txt\n",
            "         072_071_004_04_09.txt\n",
            "         071_158_002_04_14.txt\n",
            "         071_184_001_04_16.txt\n",
            "         072_050_002_04_20.txt\n",
            "         071_151_003_04_20.txt\n",
            "         073_072_002_03_14.txt\n",
            "         073_054_001_03_01.txt\n",
            "         071_164_002_04_04.txt\n",
            "         072_070_002_06_15.txt\n",
            "         116_074_001_02_18.txt\n",
            "         115_077_001_02_25.txt\n",
            "         116_387_001_01_15.txt\n",
            "         071_186_002_04_06.txt\n",
            "         096_100_002_01_10.txt\n",
            "         071_010_003_04_25.txt\n",
            "         115_107_003_01_15.txt\n",
            "         115_084_003_02_29.txt\n",
            "         073_071_001_03_19.txt\n",
            "         097_172_002_01_02.txt\n",
            "         115_007_001_02_13.txt\n",
            "         116_287_002_02_07.txt\n",
            "         115_065_003_02_04.txt\n",
            "         002_112_001_02_01.txt\n",
            "         071_142_001_04_09.txt\n",
            "         071_112_003_04_01.txt\n",
            "         073_001_003_01_07.txt\n",
            "         115_084_003_02_20.txt\n",
            "         072_066_002_04_03.txt\n",
            "         116_625_001_02_11.txt\n",
            "         115_009_003_01_01.txt\n",
            "         116_632_002_02_13.txt\n",
            "         071_181_002_04_18.txt\n",
            "         115_069_001_02_17.txt\n",
            "         072_070_002_04_04.txt\n",
            "         071_131_002_04_20.txt\n",
            "         115_075_003_02_10.txt\n",
            "         115_011_002_02_31.txt\n",
            "         073_071_001_03_09.txt\n",
            "         116_295_001_03_11.txt\n",
            "         071_184_003_04_17.txt\n",
            "         073_060_001_03_13.txt\n",
            "         071_166_001_04_01.txt\n",
            "         035_325_001_02_05.txt\n",
            "         115_080_003_02_10.txt\n",
            "         115_101_001_02_29.txt\n",
            "         071_169_001_05_14.txt\n",
            "         072_169_002_04_15.txt\n",
            "         071_132_001_04_02.txt\n",
            "         072_047_002_04_07.txt\n",
            "         035_321_001_02_15.txt\n",
            "         116_078_001_02_23.txt\n",
            "         116_287_002_02_10.txt\n",
            "         071_003_004_04_21.txt\n",
            "         115_067_004_02_21.txt\n",
            "         097_186_001_01_03.txt\n",
            "         071_101_002_04_18.txt\n",
            "         072_105_002_04_18.txt\n",
            "         116_046_001_01_01.txt\n",
            "         115_069_001_02_25.txt\n",
            "         115_084_001_02_03.txt\n",
            "         115_067_002_02_11.txt\n",
            "         071_131_002_04_17.txt\n",
            "         071_192_004_04_11.txt\n",
            "         071_010_003_04_05.txt\n",
            "         115_073_001_02_29.txt\n",
            "         115_087_003_02_10.txt\n",
            "         035_325_001_02_09.txt\n",
            "         073_072_001_03_04.txt\n",
            "         071_120_001_05_10.txt\n",
            "         073_074_002_03_15.txt\n",
            "         073_068_001_03_16.txt\n",
            "         097_186_001_01_11.txt\n",
            "         115_072_003_02_25.txt\n",
            "         073_001_003_01_06.txt\n",
            "         071_185_001_04_03.txt\n",
            "         073_067_001_03_23.txt\n",
            "         115_087_004_02_18.txt\n",
            "         116_136_001_01_14.txt\n",
            "         115_070_002_02_01.txt\n",
            "         071_192_002_04_05.txt\n",
            "         073_073_001_03_23.txt\n",
            "         073_070_002_03_07.txt\n",
            "         116_074_001_02_19.txt\n",
            "         071_117_002_02_01.txt\n",
            "         072_054_003_03_14.txt\n",
            "         116_055_001_02_12.txt\n",
            "         071_184_004_04_12.txt\n",
            "         073_058_001_01_01.txt\n",
            "         072_070_002_06_19.txt\n",
            "         071_182_004_05_04.txt\n",
            "         116_300_002_02_16.txt\n",
            "         071_106_002_04_20.txt\n",
            "         115_077_002_02_09.txt\n",
            "         115_086_001_02_01.txt\n",
            "         072_167_002_05_08.txt\n",
            "         073_067_001_03_12.txt\n",
            "         072_104_002_04_21.txt\n",
            "         072_051_003_03_01.txt\n",
            "         116_073_001_02_06.txt\n",
            "         116_405_002_01_10.txt\n",
            "         096_039_001_01_15.txt\n",
            "         072_101_004_04_18.txt\n",
            "         096_101_001_02_03.txt\n",
            "         071_101_003_02_01.txt\n",
            "         096_024_001_02_06.txt\n",
            "         116_280_001_01_01.txt\n",
            "         071_111_001_04_10.txt\n",
            "         116_642_002_02_28.txt\n",
            "         116_279_002_03_17.txt\n",
            "         073_083_001_03_15.txt\n",
            "         115_069_001_02_07.txt\n",
            "         115_101_004_02_23.txt\n",
            "         072_105_002_04_04.txt\n",
            "         115_008_001_02_10.txt\n",
            "         116_070_001_02_04.txt\n",
            "         115_012_001_01_16.txt\n",
            "         116_627_002_03_03.txt\n",
            "         071_164_002_04_14.txt\n",
            "         072_105_003_01_01.txt\n",
            "         071_133_003_04_08.txt\n",
            "         072_102_004_05_02.txt\n",
            "         071_106_001_04_21.txt\n",
            "         071_180_003_05_10.txt\n",
            "         096_100_003_01_04.txt\n",
            "         071_107_002_04_14.txt\n",
            "         073_051_001_03_09.txt\n",
            "         115_011_002_02_04.txt\n",
            "         071_133_003_01_01.txt\n",
            "         072_103_002_04_15.txt\n",
            "         096_118_001_01_22.txt\n",
            "         116_291_002_02_29.txt\n",
            "         096_053_004_03_14.txt\n",
            "         071_106_001_04_09.txt\n",
            "         071_185_003_05_08.txt\n",
            "         115_008_001_02_13.txt\n",
            "         115_085_003_02_06.txt\n",
            "         096_118_001_01_21.txt\n",
            "         116_636_002_02_16.txt\n",
            "         116_279_002_03_01.txt\n",
            "         071_107_002_04_06.txt\n",
            "         096_052_001_02_05.txt\n",
            "         115_069_001_02_02.txt\n",
            "         071_054_001_01_01.txt\n",
            "         115_065_002_02_24.txt\n",
            "         071_186_003_04_15.txt\n",
            "         071_053_003_01_01.txt\n",
            "         116_631_002_02_07.txt\n",
            "         116_291_001_04_02.txt\n",
            "         115_008_001_02_24.txt\n",
            "         115_067_002_02_02.txt\n",
            "         071_165_003_04_07.txt\n",
            "         035_328_001_02_20.txt\n",
            "         116_068_001_02_07.txt\n",
            "         115_110_002_04_01.txt\n",
            "         116_074_001_02_20.txt\n",
            "         072_054_003_03_08.txt\n",
            "         072_095_001_03_02.txt\n",
            "         116_607_001_03_28.txt\n",
            "         115_073_002_02_08.txt\n",
            "         116_287_002_02_19.txt\n",
            "         071_146_002_04_04.txt\n",
            "         071_159_001_05_04.txt\n",
            "         071_054_001_03_09.txt\n",
            "         071_133_002_04_02.txt\n",
            "         071_186_002_04_09.txt\n",
            "         116_405_003_01_02.txt\n",
            "         071_163_004_01_01.txt\n",
            "         072_101_004_04_15.txt\n",
            "         115_072_003_02_12.txt\n",
            "         071_159_003_03_02.txt\n",
            "         073_072_001_03_14.txt\n",
            "         097_172_002_01_05.txt\n",
            "         071_188_002_03_02.txt\n",
            "         115_084_001_02_14.txt\n",
            "         116_649_001_03_03.txt\n",
            "         002_112_001_03_17.txt\n",
            "         073_060_001_03_12.txt\n",
            "         071_185_001_04_01.txt\n",
            "         071_157_002_04_13.txt\n",
            "         071_163_003_03_01.txt\n",
            "         115_084_004_02_05.txt\n",
            "         073_070_001_03_13.txt\n",
            "         115_083_001_02_24.txt\n",
            "         115_110_002_03_02.txt\n",
            "         115_007_003_02_19.txt\n",
            "         071_021_002_04_10.txt\n",
            "         115_007_001_02_24.txt\n",
            "         071_133_002_05_11.txt\n",
            "         116_073_001_02_20.txt\n",
            "         072_103_001_05_06.txt\n",
            "         115_080_003_02_19.txt\n",
            "         071_085_004_04_01.txt\n",
            "         072_105_002_04_02.txt\n",
            "         073_058_001_03_09.txt\n",
            "         116_631_002_02_09.txt\n",
            "         072_049_004_04_20.txt\n",
            "         096_002_002_01_16.txt\n",
            "         116_631_001_02_04.txt\n",
            "         073_002_001_02_12.txt\n",
            "         116_067_001_02_31.txt\n",
            "         071_139_004_04_22.txt\n",
            "         116_286_002_02_04.txt\n",
            "         115_078_001_02_24.txt\n",
            "         115_087_002_02_27.txt\n",
            "         071_043_004_04_01.txt\n",
            "         116_405_003_01_19.txt\n",
            "         116_606_001_03_21.txt\n",
            "         071_151_003_04_22.txt\n",
            "         071_185_004_04_19.txt\n",
            "         115_082_004_02_23.txt\n",
            "         115_065_003_02_23.txt\n",
            "         115_108_001_01_09.txt\n",
            "         116_301_002_02_04.txt\n",
            "         115_110_001_03_12.txt\n",
            "         072_102_003_04_02.txt\n",
            "         071_163_003_04_07.txt\n",
            "         116_642_002_02_18.txt\n",
            "         096_021_003_02_15.txt\n",
            "         116_071_001_03_01.txt\n",
            "         115_080_003_02_09.txt\n",
            "         115_111_003_02_26.txt\n",
            "         073_056_001_03_08.txt\n",
            "         072_050_003_04_08.txt\n",
            "         071_146_001_05_15.txt\n",
            "         072_103_004_04_07.txt\n",
            "         072_167_002_04_06.txt\n",
            "         116_616_001_03_09.txt\n",
            "         071_112_001_04_13.txt\n",
            "         096_015_002_01_05.txt\n",
            "         115_087_003_02_14.txt\n",
            "         116_300_002_02_20.txt\n",
            "         071_018_003_04_05.txt\n",
            "         115_067_004_02_29.txt\n",
            "         072_100_001_04_11.txt\n",
            "         071_146_003_01_01.txt\n",
            "         116_290_001_01_01.txt\n",
            "         071_003_003_05_01.txt\n",
            "         096_002_002_01_09.txt\n",
            "         071_146_001_05_03.txt\n",
            "         072_105_001_04_22.txt\n",
            "         071_142_001_04_05.txt\n",
            "         116_074_001_02_09.txt\n",
            "         115_075_004_02_05.txt\n",
            "         073_074_002_03_10.txt\n",
            "         097_186_001_01_21.txt\n",
            "         072_054_003_04_02.txt\n",
            "         116_606_001_03_22.txt\n",
            "         071_165_003_01_01.txt\n",
            "         116_244_001_01_01.txt\n",
            "         071_163_001_04_06.txt\n",
            "         071_163_001_04_10.txt\n",
            "         071_146_003_04_05.txt\n",
            "         071_128_001_05_23.txt\n",
            "         071_192_002_01_01.txt\n",
            "         073_070_002_03_22.txt\n",
            "         071_106_002_02_01.txt\n",
            "         115_079_001_02_08.txt\n",
            "         072_100_002_04_16.txt\n",
            "         073_070_002_03_10.txt\n",
            "         071_133_002_02_01.txt\n",
            "         072_101_002_04_20.txt\n",
            "         116_626_002_02_08.txt\n",
            "         072_071_004_04_13.txt\n",
            "         072_032_002_04_21.txt\n",
            "         072_101_002_04_09.txt\n",
            "         071_168_004_04_01.txt\n",
            "         071_106_002_03_01.txt\n",
            "         073_070_001_03_05.txt\n",
            "         073_069_001_02_01.txt\n",
            "         115_107_002_01_06.txt\n",
            "         116_131_001_01_05.txt\n",
            "         116_136_001_01_02.txt\n",
            "         116_291_001_04_13.txt\n",
            "         116_625_001_02_17.txt\n",
            "         116_135_001_02_17.txt\n",
            "         116_135_001_02_22.txt\n",
            "         115_101_004_02_10.txt\n",
            "         071_120_002_04_09.txt\n",
            "         071_163_003_01_01.txt\n",
            "         116_641_001_02_23.txt\n",
            "         115_084_003_02_27.txt\n",
            "         073_071_003_03_22.txt\n",
            "         115_083_002_02_07.txt\n",
            "         072_048_003_01_01.txt\n",
            "         115_012_001_01_09.txt\n",
            "         071_185_002_04_16.txt\n",
            "         071_184_003_04_09.txt\n",
            "         116_244_001_01_12.txt\n",
            "         115_065_004_02_18.txt\n",
            "         115_080_004_02_24.txt\n",
            "         072_169_002_04_17.txt\n",
            "         115_078_001_02_05.txt\n",
            "         116_648_001_03_43.txt\n",
            "         116_066_001_02_06.txt\n",
            "         115_077_004_02_02.txt\n",
            "         071_158_002_04_12.txt\n",
            "         072_066_001_04_03.txt\n",
            "         096_100_003_01_07.txt\n",
            "         071_182_002_04_04.txt\n",
            "         071_129_002_04_22.txt\n",
            "         115_067_004_02_02.txt\n",
            "         116_406_001_01_06.txt\n",
            "         115_011_001_02_04.txt\n",
            "         115_067_002_02_16.txt\n",
            "         035_327_001_02_01.txt\n",
            "         071_120_002_04_11.txt\n",
            "         073_067_001_03_01.txt\n",
            "         073_073_001_03_15.txt\n",
            "         116_286_002_02_05.txt\n",
            "         072_100_001_04_13.txt\n",
            "         116_290_001_04_18.txt\n",
            "         071_109_001_04_16.txt\n",
            "         071_141_003_04_16.txt\n",
            "         096_053_004_03_08.txt\n",
            "         116_300_002_02_04.txt\n",
            "         115_078_002_02_19.txt\n",
            "         071_201_001_04_15.txt\n",
            "         115_112_001_02_16.txt\n",
            "         115_065_002_02_27.txt\n",
            "         115_065_004_02_26.txt\n",
            "         115_075_003_02_12.txt\n",
            "         071_139_004_04_04.txt\n",
            "         071_085_004_04_12.txt\n",
            "         116_100_002_01_09.txt\n",
            "         116_641_001_02_11.txt\n",
            "         116_100_001_01_20.txt\n",
            "   BenthamDatasetR0-Images/\n",
            "      Images/\n",
            "         Pages/\n",
            "            071_184_003.jpg\n",
            "            071_169_001.jpg\n",
            "            115_010_001.jpg\n",
            "            096_100_003.jpg\n",
            "            073_002_002.jpg\n",
            "            071_101_004.jpg\n",
            "            115_080_004.jpg\n",
            "            115_080_002.jpg\n",
            "            115_111_004.jpg\n",
            "            116_131_001.jpg\n",
            "            071_185_002.jpg\n",
            "            071_185_003.jpg\n",
            "            115_108_002.jpg\n",
            "            071_201_001.jpg\n",
            "            096_098_002.jpg\n",
            "            115_111_003.jpg\n",
            "            116_290_001.jpg\n",
            "            096_032_004.jpg\n",
            "            073_056_001.jpg\n",
            "            116_301_002.jpg\n",
            "            073_072_001.jpg\n",
            "            072_051_003.jpg\n",
            "            116_631_001.jpg\n",
            "            096_052_003.jpg\n",
            "            071_107_001.jpg\n",
            "            115_107_003.jpg\n",
            "            072_105_003.jpg\n",
            "            072_052_002.jpg\n",
            "            071_109_001.jpg\n",
            "            115_101_004.jpg\n",
            "            071_181_003.jpg\n",
            "            072_101_004.jpg\n",
            "            071_131_002.jpg\n",
            "            071_181_001.jpg\n",
            "            116_619_001.jpg\n",
            "            071_180_003.jpg\n",
            "            116_280_001.jpg\n",
            "            071_144_002.jpg\n",
            "            072_032_002.jpg\n",
            "            071_022_003.jpg\n",
            "            073_063_001.jpg\n",
            "            116_642_002.jpg\n",
            "            115_081_001.jpg\n",
            "            073_070_002.jpg\n",
            "            073_055_001.jpg\n",
            "            116_392_001.jpg\n",
            "            115_011_002.jpg\n",
            "            072_210_001.jpg\n",
            "            115_007_002.jpg\n",
            "            116_287_002.jpg\n",
            "            115_078_002.jpg\n",
            "            071_103_002.jpg\n",
            "            073_071_001.jpg\n",
            "            071_139_004.jpg\n",
            "            071_162_001.jpg\n",
            "            035_322_001.jpg\n",
            "            115_085_003.jpg\n",
            "            071_120_001.jpg\n",
            "            072_167_004.jpg\n",
            "            115_111_001.jpg\n",
            "            116_136_001.jpg\n",
            "            072_099_001.jpg\n",
            "            116_100_001.jpg\n",
            "            072_105_001.jpg\n",
            "            073_003_002.jpg\n",
            "            071_183_004.jpg\n",
            "            071_159_001.jpg\n",
            "            071_167_002.jpg\n",
            "            071_059_003.jpg\n",
            "            072_051_002.jpg\n",
            "            116_100_002.jpg\n",
            "            071_186_004.jpg\n",
            "            096_100_002.jpg\n",
            "            072_066_004.jpg\n",
            "            116_631_002.jpg\n",
            "            116_072_001.jpg\n",
            "            073_059_001.jpg\n",
            "            073_071_003.jpg\n",
            "            071_201_003.jpg\n",
            "            096_032_003.jpg\n",
            "            071_188_002.jpg\n",
            "            116_071_001.jpg\n",
            "            115_082_001.jpg\n",
            "            071_102_003.jpg\n",
            "            115_112_001.jpg\n",
            "            116_070_001.jpg\n",
            "            071_054_001.jpg\n",
            "            115_076_003.jpg\n",
            "            116_133_001.jpg\n",
            "            071_181_002.jpg\n",
            "            116_393_003.jpg\n",
            "            096_038_003.jpg\n",
            "            071_185_001.jpg\n",
            "            002_121_001.jpg\n",
            "            071_032_002.jpg\n",
            "            071_032_001.jpg\n",
            "            071_192_002.jpg\n",
            "            072_066_003.jpg\n",
            "            097_172_002.jpg\n",
            "            072_048_003.jpg\n",
            "            115_075_004.jpg\n",
            "            072_213_001.jpg\n",
            "            073_053_001.jpg\n",
            "            071_030_001.jpg\n",
            "            071_102_002.jpg\n",
            "            071_166_001.jpg\n",
            "            115_112_002.jpg\n",
            "            071_010_003.jpg\n",
            "            072_050_001.jpg\n",
            "            072_101_002.jpg\n",
            "            071_146_003.jpg\n",
            "            115_084_002.jpg\n",
            "            073_061_001.jpg\n",
            "            072_094_004.jpg\n",
            "            115_102_001.jpg\n",
            "            071_128_003.jpg\n",
            "            071_169_004.jpg\n",
            "            096_099_004.jpg\n",
            "            115_079_001.jpg\n",
            "            096_098_003.jpg\n",
            "            071_132_001.jpg\n",
            "            072_167_002.jpg\n",
            "            071_042_001.jpg\n",
            "            072_031_001.jpg\n",
            "            071_163_003.jpg\n",
            "            071_182_001.jpg\n",
            "            071_042_002.jpg\n",
            "            071_043_003.jpg\n",
            "            072_103_001.jpg\n",
            "            115_075_001.jpg\n",
            "            116_649_001.jpg\n",
            "            115_108_001.jpg\n",
            "            115_101_002.jpg\n",
            "            072_071_004.jpg\n",
            "            072_095_001.jpg\n",
            "            071_131_004.jpg\n",
            "            071_106_001.jpg\n",
            "            116_063_001.jpg\n",
            "            071_142_001.jpg\n",
            "            096_052_001.jpg\n",
            "            073_072_003.jpg\n",
            "            116_641_001.jpg\n",
            "            002_579_001.jpg\n",
            "            072_101_003.jpg\n",
            "            071_035_002.jpg\n",
            "            072_036_002.jpg\n",
            "            071_003_003.jpg\n",
            "            096_052_002.jpg\n",
            "            071_010_002.jpg\n",
            "            116_064_001.jpg\n",
            "            072_102_004.jpg\n",
            "            115_075_003.jpg\n",
            "            116_300_002.jpg\n",
            "            072_047_002.jpg\n",
            "            072_100_002.jpg\n",
            "            071_151_003.jpg\n",
            "            035_324_001.jpg\n",
            "            096_051_004.jpg\n",
            "            071_141_003.jpg\n",
            "            115_007_004.jpg\n",
            "            073_067_001.jpg\n",
            "            116_287_001.jpg\n",
            "            115_080_001.jpg\n",
            "            116_627_002.jpg\n",
            "            071_163_001.jpg\n",
            "            073_072_002.jpg\n",
            "            116_630_002.jpg\n",
            "            115_083_001.jpg\n",
            "            096_003_002.jpg\n",
            "            072_105_002.jpg\n",
            "            072_103_004.jpg\n",
            "            071_184_002.jpg\n",
            "            115_101_001.jpg\n",
            "            072_167_003.jpg\n",
            "            115_112_003.jpg\n",
            "            071_162_002.jpg\n",
            "            096_118_001.jpg\n",
            "            072_066_002.jpg\n",
            "            071_117_002.jpg\n",
            "            096_098_004.jpg\n",
            "            115_082_004.jpg\n",
            "            115_008_001.jpg\n",
            "            073_069_001.jpg\n",
            "            071_111_002.jpg\n",
            "            116_642_001.jpg\n",
            "            071_168_003.jpg\n",
            "            115_087_003.jpg\n",
            "            116_639_002.jpg\n",
            "            072_066_001.jpg\n",
            "            071_165_001.jpg\n",
            "            073_003_001.jpg\n",
            "            071_163_004.jpg\n",
            "            116_073_001.jpg\n",
            "            071_158_002.jpg\n",
            "            071_165_003.jpg\n",
            "            071_140_001.jpg\n",
            "            096_028_001.jpg\n",
            "            116_405_002.jpg\n",
            "            071_129_002.jpg\n",
            "            071_108_002.jpg\n",
            "            116_620_001.jpg\n",
            "            115_080_003.jpg\n",
            "            072_054_001.jpg\n",
            "            071_130_003.jpg\n",
            "            116_294_001.jpg\n",
            "            073_051_001.jpg\n",
            "            071_157_002.jpg\n",
            "            115_076_002.jpg\n",
            "            002_112_001.jpg\n",
            "            071_168_004.jpg\n",
            "            115_111_002.jpg\n",
            "            115_007_001.jpg\n",
            "            071_159_003.jpg\n",
            "            115_083_002.jpg\n",
            "            116_632_002.jpg\n",
            "            035_328_001.jpg\n",
            "            115_070_001.jpg\n",
            "            071_185_004.jpg\n",
            "            115_107_002.jpg\n",
            "            035_327_001.jpg\n",
            "            071_182_004.jpg\n",
            "            115_088_001.jpg\n",
            "            071_002_002.jpg\n",
            "            115_067_003.jpg\n",
            "            116_405_001.jpg\n",
            "            115_009_003.jpg\n",
            "            096_101_001.jpg\n",
            "            116_067_001.jpg\n",
            "            116_288_001.jpg\n",
            "            073_074_001.jpg\n",
            "            002_541_001.jpg\n",
            "            096_100_001.jpg\n",
            "            071_003_004.jpg\n",
            "            072_102_002.jpg\n",
            "            115_073_001.jpg\n",
            "            115_016_001.jpg\n",
            "            073_001_003.jpg\n",
            "            072_050_003.jpg\n",
            "            115_108_003.jpg\n",
            "            071_035_003.jpg\n",
            "            115_084_004.jpg\n",
            "            116_078_001.jpg\n",
            "            071_101_003.jpg\n",
            "            115_087_002.jpg\n",
            "            115_016_003.jpg\n",
            "            071_018_002.jpg\n",
            "            115_007_003.jpg\n",
            "            096_002_003.jpg\n",
            "            035_320_001.jpg\n",
            "            115_084_003.jpg\n",
            "            115_110_003.jpg\n",
            "            116_648_001.jpg\n",
            "            116_406_001.jpg\n",
            "            071_112_001.jpg\n",
            "            116_626_002.jpg\n",
            "            115_087_004.jpg\n",
            "            115_067_002.jpg\n",
            "            071_184_001.jpg\n",
            "            116_135_001.jpg\n",
            "            115_101_003.jpg\n",
            "            072_212_001.jpg\n",
            "            073_054_001.jpg\n",
            "            071_106_002.jpg\n",
            "            115_086_004.jpg\n",
            "            116_607_001.jpg\n",
            "            116_643_001.jpg\n",
            "            071_008_004.jpg\n",
            "            072_210_004.jpg\n",
            "            071_186_002.jpg\n",
            "            071_183_001.jpg\n",
            "            072_070_002.jpg\n",
            "            071_111_001.jpg\n",
            "            096_051_001.jpg\n",
            "            071_159_002.jpg\n",
            "            071_163_002.jpg\n",
            "            071_139_003.jpg\n",
            "            116_633_002.jpg\n",
            "            071_036_001.jpg\n",
            "            072_094_003.jpg\n",
            "            073_074_002.jpg\n",
            "            073_049_002.jpg\n",
            "            115_009_001.jpg\n",
            "            096_018_002.jpg\n",
            "            096_008_002.jpg\n",
            "            096_008_004.jpg\n",
            "            071_021_002.jpg\n",
            "            072_049_001.jpg\n",
            "            115_010_002.jpg\n",
            "            071_002_003.jpg\n",
            "            116_279_002.jpg\n",
            "            071_054_002.jpg\n",
            "            096_021_003.jpg\n",
            "            115_072_003.jpg\n",
            "            071_141_001.jpg\n",
            "            072_054_002.jpg\n",
            "            116_275_001.jpg\n",
            "            116_066_001.jpg\n",
            "            072_072_001.jpg\n",
            "            116_291_002.jpg\n",
            "            116_244_001.jpg\n",
            "            073_050_001.jpg\n",
            "            096_051_002.jpg\n",
            "            116_627_001.jpg\n",
            "            071_101_002.jpg\n",
            "            116_291_001.jpg\n",
            "            071_184_004.jpg\n",
            "            116_046_001.jpg\n",
            "            071_169_002.jpg\n",
            "            115_084_001.jpg\n",
            "            115_012_001.jpg\n",
            "            115_086_003.jpg\n",
            "            072_168_001.jpg\n",
            "            096_024_001.jpg\n",
            "            116_405_004.jpg\n",
            "            116_639_001.jpg\n",
            "            071_107_002.jpg\n",
            "            027_029_001.jpg\n",
            "            116_286_002.jpg\n",
            "            071_044_003.jpg\n",
            "            073_068_001.jpg\n",
            "            115_065_001.jpg\n",
            "            072_169_002.jpg\n",
            "            071_146_001.jpg\n",
            "            072_100_003.jpg\n",
            "            096_053_004.jpg\n",
            "            071_018_003.jpg\n",
            "            072_210_002.jpg\n",
            "            116_294_002.jpg\n",
            "            096_017_003.jpg\n",
            "            115_011_001.jpg\n",
            "            071_164_002.jpg\n",
            "            116_625_001.jpg\n",
            "            071_156_002.jpg\n",
            "            072_168_003.jpg\n",
            "            116_055_001.jpg\n",
            "            115_110_004.jpg\n",
            "            116_606_001.jpg\n",
            "            073_073_003.jpg\n",
            "            116_643_002.jpg\n",
            "            073_083_001.jpg\n",
            "            115_076_001.jpg\n",
            "            096_039_001.jpg\n",
            "            116_618_001.jpg\n",
            "            072_069_002.jpg\n",
            "            097_186_001.jpg\n",
            "            115_008_002.jpg\n",
            "            115_070_002.jpg\n",
            "            115_065_004.jpg\n",
            "            116_405_003.jpg\n",
            "            071_157_001.jpg\n",
            "            071_102_001.jpg\n",
            "            071_133_003.jpg\n",
            "            073_070_001.jpg\n",
            "            071_164_001.jpg\n",
            "            115_085_004.jpg\n",
            "            071_108_001.jpg\n",
            "            073_001_001.jpg\n",
            "            073_071_002.jpg\n",
            "            071_186_003.jpg\n",
            "            115_077_001.jpg\n",
            "            116_303_002.jpg\n",
            "            096_099_003.jpg\n",
            "            072_049_002.jpg\n",
            "            073_058_001.jpg\n",
            "            072_050_002.jpg\n",
            "            115_009_004.jpg\n",
            "            071_043_004.jpg\n",
            "            072_049_004.jpg\n",
            "            115_087_001.jpg\n",
            "            071_146_002.jpg\n",
            "            116_068_001.jpg\n",
            "            072_102_003.jpg\n",
            "            073_073_001.jpg\n",
            "            072_169_003.jpg\n",
            "            115_078_001.jpg\n",
            "            071_112_003.jpg\n",
            "            071_133_002.jpg\n",
            "            116_076_001.jpg\n",
            "            115_065_003.jpg\n",
            "            072_054_003.jpg\n",
            "            071_053_004.jpg\n",
            "            073_057_002.jpg\n",
            "            071_180_004.jpg\n",
            "            035_325_001.jpg\n",
            "            115_065_002.jpg\n",
            "            116_400_001.jpg\n",
            "            071_190_002.jpg\n",
            "            115_073_002.jpg\n",
            "            115_077_002.jpg\n",
            "            071_167_001.jpg\n",
            "            071_182_002.jpg\n",
            "            115_082_003.jpg\n",
            "            071_085_004.jpg\n",
            "            072_100_001.jpg\n",
            "            115_086_001.jpg\n",
            "            115_077_004.jpg\n",
            "            035_321_001.jpg\n",
            "            073_060_001.jpg\n",
            "            071_181_004.jpg\n",
            "            115_069_001.jpg\n",
            "            071_128_001.jpg\n",
            "            096_002_002.jpg\n",
            "            115_067_004.jpg\n",
            "            071_202_001.jpg\n",
            "            116_617_001.jpg\n",
            "            073_002_001.jpg\n",
            "            073_071_004.jpg\n",
            "            072_104_002.jpg\n",
            "            073_052_001.jpg\n",
            "            002_080_001.jpg\n",
            "            115_110_001.jpg\n",
            "            116_279_001.jpg\n",
            "            115_082_002.jpg\n",
            "            115_009_002.jpg\n",
            "            071_105_003.jpg\n",
            "            116_636_002.jpg\n",
            "            072_103_002.jpg\n",
            "            116_387_001.jpg\n",
            "            073_031_001.jpg\n",
            "            096_015_002.jpg\n",
            "            115_107_001.jpg\n",
            "            115_110_002.jpg\n",
            "            115_072_001.jpg\n",
            "            116_295_001.jpg\n",
            "            116_074_001.jpg\n",
            "            096_034_004.jpg\n",
            "            035_323_001.jpg\n",
            "            115_077_003.jpg\n",
            "            071_120_002.jpg\n",
            "            071_053_003.jpg\n",
            "            071_192_004.jpg\n",
            "            116_633_001.jpg\n",
            "            116_616_001.jpg\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "root = Path(r\"/content/drive/MyDrive/Bentham\")\n",
        "\n",
        "def print_tree(path, prefix=\"\"):\n",
        "    print(prefix + path.name + \"/\")\n",
        "    for p in path.iterdir():\n",
        "        if p.is_dir():\n",
        "            print_tree(p, prefix + \"   \")\n",
        "        else:\n",
        "            print(prefix + \"   \" + p.name)\n",
        "\n",
        "print_tree(root)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "482d2216-bcca-47dd-bf5a-243b3d4389a0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "482d2216-bcca-47dd-bf5a-243b3d4389a0",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "708c209a-5c75-4554-b33a-6eba7dad100c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_181_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/072_066_004.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_107_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/072_031_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/096_015_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_067_004.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_079_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_102_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_066_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_003_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/096_028_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_035_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_287_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_128_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_159_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/072_167_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/072_048_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_087_004.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/072_210_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_183_004.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_009_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/073_074_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_002_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_018_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_180_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_181_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_010_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/072_105_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/073_071_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_163_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_080_004.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_301_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/072_051_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/072_168_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_032_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/097_172_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_158_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_167_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/073_052_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/072_103_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/096_038_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_168_004.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/072_050_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/072_032_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/072_101_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/096_024_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_630_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_084_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_042_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_642_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_165_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_108_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_101_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_631_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_083_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_085_004.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_080_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_087_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/096_032_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_185_004.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/096_003_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_169_004.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_286_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/073_072_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_111_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_073_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/002_579_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/073_051_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/096_017_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_076_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_078_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/073_074_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_107_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_202_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/002_080_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_164_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_101_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/072_167_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_131_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_077_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_392_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_007_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/072_054_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_135_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/096_053_004.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/072_212_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/073_068_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_078_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_077_004.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_133_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_084_004.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_185_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_186_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_105_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_059_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/073_031_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_159_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_291_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_294_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/072_050_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_133_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_082_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/073_049_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_181_004.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/073_055_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_016_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_083_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_141_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/072_104_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/096_008_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/035_328_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_077_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/073_058_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/072_102_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/072_168_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/072_105_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_636_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_279_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_295_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_065_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_616_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_109_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_406_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_074_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_010_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_141_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_012_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/072_054_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/072_169_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_163_004.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_184_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_075_004.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_186_004.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_405_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/073_072_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_290_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/073_003_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/096_100_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_053_004.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_065_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_111_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/072_103_004.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/096_021_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_002_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/073_063_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/072_066_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_081_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_649_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/096_039_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/072_047_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_102_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_139_004.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_626_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/072_102_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_188_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_620_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_184_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_201_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/072_072_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/072_036_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_063_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/096_100_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_007_004.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_132_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_146_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_192_004.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_043_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_157_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_142_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/072_100_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_400_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/072_103_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/072_071_004.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/002_112_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_102_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_071_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_044_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_117_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_101_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_008_004.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/073_054_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_627_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_010_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_070_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_016_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_069_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_617_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_032_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/073_072_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_168_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_011_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_112_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_100_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/096_051_004.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_190_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_185_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/097_186_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_106_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/035_325_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/073_053_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_107_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/096_051_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/073_071_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_166_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_101_004.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_167_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/096_118_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_080_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_648_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_065_004.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_085_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/096_098_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/073_059_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/072_069_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_159_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_065_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_077_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/072_050_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_073_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/035_327_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_300_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_101_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_183_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_087_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_181_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_043_004.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/073_056_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/072_213_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_102_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_082_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_087_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/072_099_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_165_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/072_102_004.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_244_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_086_004.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_086_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_643_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_008_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_073_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_022_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/072_101_004.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_064_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_128_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/002_121_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_169_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/072_100_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/072_051_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/073_061_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/096_098_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/096_100_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_108_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_072_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/072_095_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_633_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_639_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_075_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_009_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_157_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_151_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/073_060_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/073_073_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/073_083_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_164_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_021_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_112_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_144_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_163_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_162_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_070_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_201_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_018_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_084_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_632_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_107_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/096_099_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_146_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/073_002_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_053_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_086_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_192_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/035_322_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_108_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_120_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_084_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_184_004.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_387_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_110_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/096_034_004.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_007_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_110_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_642_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_186_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_146_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_067_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_080_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_393_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/073_002_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_131_004.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/072_049_004.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_103_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_035_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/096_052_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/073_073_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_163_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_185_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_072_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/002_541_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_279_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_136_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_010_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_075_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/035_323_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_046_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/072_105_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/072_066_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_633_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_182_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_294_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_140_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_068_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/073_001_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_111_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_182_004.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_607_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/073_067_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/096_098_004.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/072_049_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_082_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_108_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_627_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/073_071_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/072_094_004.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_631_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_133_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_606_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_288_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_180_004.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/072_054_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_042_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_107_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_625_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_130_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/096_052_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_169_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/096_101_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_111_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/096_002_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_085_004.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/072_210_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_008_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/073_001_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/073_070_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/096_051_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/035_324_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_101_004.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_072_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/072_167_004.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_106_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_643_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/072_052_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_182_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_112_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/072_094_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/027_029_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_275_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/072_066_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_009_004.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_009_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/096_018_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_076_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/096_099_004.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_078_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_639_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/035_321_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_139_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_067_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_055_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_112_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_076_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_108_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/072_100_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_162_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/072_169_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_088_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_100_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_003_004.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/073_057_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/072_101_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_641_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/072_049_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_101_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_619_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_112_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_280_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_303_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_054_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_405_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_030_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_036_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_156_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/096_008_004.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/035_320_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/096_002_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_111_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/073_050_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/073_070_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/072_210_004.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_405_004.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_067_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_007_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_111_004.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_291_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/096_032_004.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_082_004.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_131_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_129_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_110_004.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/096_052_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_405_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_110_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_070_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/073_069_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_618_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_011_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_184_003.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/116_287_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/072_070_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_120_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/115_076_001.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/073_003_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/071_054_002.xml\n",
            "/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/PAGE/073_071_004.xml\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "root = Path(r\"/content/drive/MyDrive/Bentham\")\n",
        "\n",
        "for xml in root.rglob(\"*.xml\"):\n",
        "    print(xml)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51e6e3f6-4cfa-4146-a191-1e233dcdec5f",
      "metadata": {
        "id": "51e6e3f6-4cfa-4146-a191-1e233dcdec5f"
      },
      "source": [
        "### 2.1 Extracting Line Images and Transcriptions\n",
        "\n",
        "In this section we construct a unified Python list called `samples`, where each element contains:\n",
        "\n",
        "- the path to a **line image**, and\n",
        "- the corresponding **ground-truth transcription**.\n",
        "\n",
        "This list becomes the single source of truth for all subsequent experiments.  \n",
        "By centralising the data representation, we guarantee that the PyTorch baseline, TrOCR, and Kraken models all see *exactly the same* underlying line-level samples.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f26f998d-13d8-437b-a145-02cfd4cd85c5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f26f998d-13d8-437b-a145-02cfd4cd85c5",
        "outputId": "0c93635f-0b46-4b45-fdc8-cda0090fd0a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Lines image root: /content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/Images/Lines\n",
            "Transcriptions root: /content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/Transcriptions\n",
            "Number of PNG line images found: 11473\n",
            "Number of candidate transcription files found: 11473\n",
            "Number of matched line samples: 11473\n",
            "Number of line images without transcription: 0\n",
            "Example sample: {'img_path': PosixPath('/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/Images/Lines/115_085_004_02_23.png'), 'bbox': None, 'text': 'taxes , fees , gratuities and other deductions whatsoever and with'}\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "data_root = Path(r\"/content/drive/MyDrive/Bentham\")\n",
        "\n",
        "lines_img_root = data_root / \"BenthamDatasetR0-GT\" / \"Images\" / \"Lines\"\n",
        "lines_txt_root = data_root / \"BenthamDatasetR0-GT\" / \"Transcriptions\"\n",
        "\n",
        "print(\"Lines image root:\", lines_img_root)\n",
        "print(\"Transcriptions root:\", lines_txt_root)\n",
        "\n",
        "# 1) Collect ALL line images (recursively, in case of subfolders)\n",
        "img_files = {}\n",
        "for p in lines_img_root.rglob(\"*.png\"):\n",
        "    img_files[p.stem] = p\n",
        "print(\"Number of PNG line images found:\", len(img_files))\n",
        "\n",
        "# 2) Collect ALL possible transcription files under Transcriptions (any extension)\n",
        "txt_files = {}\n",
        "for p in lines_txt_root.rglob(\"*\"):\n",
        "    if p.is_file() and p.suffix.lower() in {\".txt\", \".xml\"}:\n",
        "        txt_files[p.stem] = p\n",
        "print(\"Number of candidate transcription files found:\", len(txt_files))\n",
        "\n",
        "# 3) Match by stem: same base name -> (image, text)\n",
        "samples = []\n",
        "unmatched_imgs = 0\n",
        "\n",
        "for stem, img_path in img_files.items():\n",
        "    txt_path = txt_files.get(stem)\n",
        "    if txt_path is None:\n",
        "        unmatched_imgs += 1\n",
        "        continue\n",
        "\n",
        "    text = txt_path.read_text(encoding=\"utf-8\", errors=\"ignore\").strip()\n",
        "    if not text:\n",
        "        continue\n",
        "\n",
        "    samples.append({\n",
        "        \"img_path\": img_path,\n",
        "        \"bbox\": None,   # not used in Option B\n",
        "        \"text\": text,\n",
        "    })\n",
        "\n",
        "print(\"Number of matched line samples:\", len(samples))\n",
        "print(\"Number of line images without transcription:\", unmatched_imgs)\n",
        "print(\"Example sample:\", samples[0] if samples else \"NONE\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZMcAJACraQH7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMcAJACraQH7",
        "outputId": "0f42f547-6b8a-4192-cfb1-f9ba301f7f11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of matched line samples: 3000\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "subset_size = 3000\n",
        "samples = random.sample(samples, subset_size)\n",
        "print(\"Number of matched line samples:\", len(samples))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43a09dfe-43cd-4787-b9ac-27d922a815d5",
      "metadata": {
        "id": "43a09dfe-43cd-4787-b9ac-27d922a815d5"
      },
      "source": [
        "### 2.2 Character Set Analysis\n",
        "\n",
        "To better understand the complexity of the transcription task, we compute basic statistics on the ground-truth text:\n",
        "\n",
        "- frequency of characters and symbols,\n",
        "- presence of non-ASCII or rarely used glyphs,\n",
        "- distribution of line lengths.\n",
        "\n",
        "This analysis informs design choices for the baseline model, such as the size of the character vocabulary, and gives context for later error analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "123681e3-e3bf-4020-a771-9c64f8d8c604",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "123681e3-e3bf-4020-a771-9c64f8d8c604",
        "outputId": "92b1a4b0-146b-449f-f404-a14b2e448355"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocab size (chars): 87\n",
            "Some chars: [' ', '!', '\"', '#', '&', \"'\", '(', ')', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U']\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "# 'samples' is the list you just built (length 11473)\n",
        "all_text = [s[\"text\"] for s in samples]\n",
        "char_counts = Counter(\"\".join(all_text))\n",
        "chars = sorted(char_counts.keys())  # for determinism\n",
        "\n",
        "print(\"Vocab size (chars):\", len(chars))\n",
        "print(\"Some chars:\", chars[:50])\n",
        "\n",
        "# CTC blank = index 0\n",
        "idx2char = [\"<BLANK>\"] + chars\n",
        "char2idx = {c: i for i, c in enumerate(idx2char)}\n",
        "\n",
        "def text_to_labels(text: str):\n",
        "    return [char2idx[c] for c in text if c in char2idx]\n",
        "\n",
        "def labels_to_text(labels):\n",
        "    return \"\".join(idx2char[i] for i in labels if i != 0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6dee8c47-dedc-4739-854a-5d86d89a80c8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dee8c47-dedc-4739-854a-5d86d89a80c8",
        "outputId": "200df6d9-a816-402a-a74b-e7ad3087cce0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "After filtering: 2886\n"
          ]
        }
      ],
      "source": [
        "filtered_samples = [s for s in samples if any(ch.isalpha() for ch in s[\"text\"])]\n",
        "samples = filtered_samples\n",
        "print(\"After filtering:\", len(samples))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "560521a6-6ed4-4ae2-8aae-ca2acd146508",
      "metadata": {
        "id": "560521a6-6ed4-4ae2-8aae-ca2acd146508"
      },
      "source": [
        "## 3. PyTorch Baseline: CRNN with CTC Loss\n",
        "\n",
        "Our first model is a **baseline OCR system implemented from scratch in PyTorch**.  \n",
        "The aim is not to compete with state-of-the-art systems, but to:\n",
        "\n",
        "- practice building a full OCR pipeline end to end, and  \n",
        "- obtain a point of comparison for more advanced models (TrOCR and Kraken).\n",
        "\n",
        "The baseline follows the common **CRNN** pattern:\n",
        "\n",
        "- a convolutional front-end to extract visual features from the line image,\n",
        "- a bidirectional recurrent layer to model sequential dependencies, and\n",
        "- a final linear projection trained with **CTC loss** for alignment-free sequence supervision.\n",
        "\n",
        "Training was originally carried out on a local machine and reproduced here as closely as possible within Colab.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8040525-56ee-4591-acf0-aebaa9f1bcae",
      "metadata": {
        "id": "f8040525-56ee-4591-acf0-aebaa9f1bcae"
      },
      "source": [
        "### 3.1 PyTorch Dataset for Line Images\n",
        "\n",
        "We define a custom `Dataset` class that:\n",
        "\n",
        "- loads each line image from disk,\n",
        "- normalises and resizes it to a fixed height,\n",
        "- converts the transcription into a sequence of character indices,\n",
        "- returns both image tensor and label sequence to the training loop.\n",
        "\n",
        "This abstraction isolates all I/O and pre-processing logic and allows us to reuse the same `samples` list defined earlier.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7889b0c8-73d2-4f09-979d-f15d3c5c0f4c",
      "metadata": {
        "id": "7889b0c8-73d2-4f09-979d-f15d3c5c0f4c"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "class BenthamLineDataset(Dataset):\n",
        "    def __init__(self, samples, img_height=64, max_width=512):\n",
        "        self.samples = samples\n",
        "        self.img_height = img_height\n",
        "        self.max_width = max_width\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def _load_and_preprocess(self, s):\n",
        "        img = Image.open(s[\"img_path\"]).convert(\"L\")  # grayscale\n",
        "\n",
        "        # Resize to fixed height, keep aspect ratio\n",
        "        w, h = img.size\n",
        "        new_h = self.img_height\n",
        "        new_w = int(w * (new_h / h))\n",
        "        img = img.resize((new_w, new_h), Image.BILINEAR)\n",
        "\n",
        "        arr = np.array(img, dtype=np.float32) / 255.0\n",
        "        arr = 1.0 - arr   # optional: invert, text white on black\n",
        "        arr = arr[None, :, :]  # (1, H, W)\n",
        "\n",
        "        # Pad / truncate to max_width\n",
        "        if new_w > self.max_width:\n",
        "            arr = arr[:, :, : self.max_width]\n",
        "            new_w = self.max_width\n",
        "        else:\n",
        "            pad_w = self.max_width - new_w\n",
        "            arr = np.pad(arr, ((0,0), (0,0), (0,pad_w)),\n",
        "                         mode=\"constant\", constant_values=0.0)\n",
        "\n",
        "        return torch.from_numpy(arr), new_w\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        s = self.samples[idx]\n",
        "        image_tensor, true_w = self._load_and_preprocess(s)\n",
        "        label = torch.tensor(text_to_labels(s[\"text\"]), dtype=torch.long)\n",
        "        return {\n",
        "            \"image\": image_tensor,   # (1, H, max_width)\n",
        "            \"width\": true_w,\n",
        "            \"label\": label,\n",
        "            \"text\": s[\"text\"],\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9d66b5e-7374-4252-8eb7-86f2340329c7",
      "metadata": {
        "id": "d9d66b5e-7374-4252-8eb7-86f2340329c7"
      },
      "source": [
        "### 3.2 Train/Validation/Test Split and Data Loaders\n",
        "\n",
        "The full set of Bentham line samples is split into **training**, **validation**, and **test** subsets.\n",
        "\n",
        "- The **training set** is used to optimise model parameters.\n",
        "- The **validation set** is used to monitor loss and character error rate during training.\n",
        "- The **test set** is reserved for final evaluation once hyperparameters are fixed.\n",
        "\n",
        "PyTorch `DataLoader` objects handle batching and shuffling, enabling efficient iteration over each subset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a89eaeb3-3fb2-499a-bea1-06a253c0fe68",
      "metadata": {
        "id": "a89eaeb3-3fb2-499a-bea1-06a253c0fe68"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Split samples\n",
        "train_s, temp_s = train_test_split(samples, test_size=0.2, random_state=42)\n",
        "val_s, test_s   = train_test_split(temp_s, test_size=0.5, random_state=42)\n",
        "\n",
        "train_ds = BenthamLineDataset(train_s)\n",
        "val_ds   = BenthamLineDataset(val_s)\n",
        "test_ds  = BenthamLineDataset(test_s)\n",
        "\n",
        "def collate_fn(batch):\n",
        "    images = torch.stack([b[\"image\"] for b in batch])      # (B, 1, H, W)\n",
        "    labels = torch.cat([b[\"label\"] for b in batch])        # concatenated labels\n",
        "    label_lengths = torch.tensor([len(b[\"label\"]) for b in batch],\n",
        "                                 dtype=torch.long)\n",
        "    widths = torch.tensor([b[\"image\"].shape[-1] for b in batch],\n",
        "                          dtype=torch.long)\n",
        "    return images, labels, label_lengths, widths, batch\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=16, shuffle=True,\n",
        "                          collate_fn=collate_fn)\n",
        "val_loader   = DataLoader(val_ds, batch_size=16, shuffle=False,\n",
        "                          collate_fn=collate_fn)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db27245b-4bb0-4a4d-a87c-f7f595666256",
      "metadata": {
        "id": "db27245b-4bb0-4a4d-a87c-f7f595666256"
      },
      "source": [
        "### 3.3 CRNN Architecture\n",
        "\n",
        "The CRNN baseline combines:\n",
        "\n",
        "- several convolutional layers with pooling to reduce the spatial dimension while increasing the number of feature channels,\n",
        "- a bidirectional LSTM layer to capture left-to-right and right-to-left context in the feature sequence,\n",
        "- a linear classification layer over the character inventory, including a blank symbol required by CTC.\n",
        "\n",
        "The network outputs a sequence of frame-wise logits which are interpreted as unaligned character probabilities.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "678a5d42-d2de-4b02-81ff-93bd3f2c5c7f",
      "metadata": {
        "id": "678a5d42-d2de-4b02-81ff-93bd3f2c5c7f"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "class CRNN(nn.Module):\n",
        "    def __init__(self, img_height, num_chars):\n",
        "        super().__init__()\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, 3, padding=1), nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),   # H/2, W/2\n",
        "\n",
        "            nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),   # H/4, W/4\n",
        "\n",
        "            nn.Conv2d(128, 256, 3, padding=1), nn.ReLU(),\n",
        "            nn.BatchNorm2d(256),\n",
        "        )\n",
        "\n",
        "        cnn_out_channels = 256\n",
        "        cnn_out_height = img_height // 4   # due to two pool(2,2)\n",
        "\n",
        "        self.rnn = nn.LSTM(\n",
        "            input_size=cnn_out_channels * cnn_out_height,\n",
        "            hidden_size=128,\n",
        "            num_layers=2,\n",
        "            bidirectional=True,\n",
        "            batch_first=True,\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Linear(128 * 2, num_chars)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (B, 1, H, W)\n",
        "        x = self.cnn(x)          # (B, C, H', W')\n",
        "        B, C, H, W = x.size()\n",
        "        x = x.permute(0, 3, 1, 2)       # (B, W, C, H)\n",
        "        x = x.contiguous().view(B, W, C * H)  # (B, T=W, features)\n",
        "        x, _ = self.rnn(x)       # (B, T, 2*hidden)\n",
        "        x = self.fc(x)           # (B, T, num_chars)\n",
        "        x = x.permute(1, 0, 2)   # (T, B, num_chars) for CTC\n",
        "        return x\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = CRNN(img_height=64, num_chars=len(idx2char)).to(device)\n",
        "\n",
        "ctc_loss = nn.CTCLoss(blank=0, zero_infinity=True)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b28b4ae7-68c7-43a9-9741-1b5c2bde3b27",
      "metadata": {
        "id": "b28b4ae7-68c7-43a9-9741-1b5c2bde3b27"
      },
      "source": [
        "### 3.4 CTC Decoding and CER Metric\n",
        "\n",
        "Once we have frame-wise character probabilities from the CRNN, we apply:\n",
        "\n",
        "- **greedy CTC decoding**, selecting the most probable class at each time step and collapsing repeats and blanks, and\n",
        "- computation of **Character Error Rate (CER)** between decoded predictions and ground truth.\n",
        "\n",
        "CER is defined as the Levenshtein edit distance between prediction and reference, normalised by the reference length.  \n",
        "It is used throughout this notebook as the primary sequence-level evaluation metric.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aca8b3fd-f3c8-405c-aec4-bfff6272c9c7",
      "metadata": {
        "id": "aca8b3fd-f3c8-405c-aec4-bfff6272c9c7"
      },
      "outputs": [],
      "source": [
        "# Greedy decode\n",
        "\n",
        "def greedy_decode(logits):\n",
        "    # logits: (T, B, num_chars)\n",
        "    probs = logits.softmax(2)\n",
        "    max_indices = probs.argmax(2)  # (T, B)\n",
        "\n",
        "    decoded_texts = []\n",
        "    T, B = max_indices.shape\n",
        "    for b in range(B):\n",
        "        prev = None\n",
        "        seq = []\n",
        "        for t in range(T):\n",
        "            idx = max_indices[t, b].item()\n",
        "            if idx != prev and idx != 0:\n",
        "                seq.append(idx)\n",
        "            prev = idx\n",
        "        decoded_texts.append(labels_to_text(seq))\n",
        "    return decoded_texts\n",
        "\n",
        "# Simple CER (character error rate)\n",
        "\n",
        "def edit_distance(a, b):\n",
        "    # classic DP Levenshtein distance\n",
        "    n, m = len(a), len(b)\n",
        "    dp = [[0] * (m+1) for _ in range(n+1)]\n",
        "    for i in range(n+1):\n",
        "        dp[i][0] = i\n",
        "    for j in range(m+1):\n",
        "        dp[0][j] = j\n",
        "    for i in range(1, n+1):\n",
        "        for j in range(1, m+1):\n",
        "            cost = 0 if a[i-1] == b[j-1] else 1\n",
        "            dp[i][j] = min(\n",
        "                dp[i-1][j] + 1,      # delete\n",
        "                dp[i][j-1] + 1,      # insert\n",
        "                dp[i-1][j-1] + cost  # substitute\n",
        "            )\n",
        "    return dp[n][m]\n",
        "\n",
        "def cer(refs, hyps):\n",
        "    # refs, hyps: lists of strings\n",
        "    total_dist = 0\n",
        "    total_chars = 0\n",
        "    for r, h in zip(refs, hyps):\n",
        "        total_dist += edit_distance(r, h)\n",
        "        total_chars += len(r)\n",
        "    return total_dist / max(1, total_chars)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a7c6e6d-5425-4cdf-a1de-1b9f9453d707",
      "metadata": {
        "id": "8a7c6e6d-5425-4cdf-a1de-1b9f9453d707"
      },
      "source": [
        "### 3.5 Training and Validation Loops\n",
        "\n",
        "The training loop for the baseline model:\n",
        "\n",
        "- runs multiple epochs over the training set,\n",
        "- optimises the CTC loss using an appropriate optimiser,\n",
        "- periodically evaluates on the validation set to track both **validation loss** and **CER**.\n",
        "\n",
        "The code is written to be CPU-friendly, reflecting the resource constraints of a typical learner setup.  \n",
        "Although performance is limited compared to modern transformer-based systems, the baseline establishes a clear lower bound for later comparisons.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1acf8880-a6e8-4da1-9e2b-48751a622a16",
      "metadata": {
        "collapsed": true,
        "id": "1acf8880-a6e8-4da1-9e2b-48751a622a16",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "5f66851d-69ad-4e34-9a74-4a1e46ab8e76"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1 [train]: 100%|███████████████████████████████████████████████████████████████| 552/552 [15:09<00:00,  1.65s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: train loss = 3.4387\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1 [val]: 100%|███████████████████████████████████████████████████████████████████| 69/69 [00:48<00:00,  1.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: val loss = 3.1094, CER = 1.0000\n",
            "\n",
            "Sample predictions:\n",
            "GT:    As to the mere Act of Coining considered by itself\n",
            "Pred:  \n",
            "---\n",
            "GT:    is compelled in the first instance to discover and surrender his\n",
            "Pred:  \n",
            "---\n",
            "GT:    : specting the actual past and present matter of fact . 2 . If\n",
            "Pred:  \n",
            "---\n",
            "GT:    first day of every term by themselves respecttively or their\n",
            "Pred:  \n",
            "---\n",
            "GT:    =ry for the purpose of any other Art  , the use and possession\n",
            "Pred:  \n",
            "---\n",
            "Saved new best model.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2 [train]: 100%|███████████████████████████████████████████████████████████████| 552/552 [17:10<00:00,  1.87s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2: train loss = 3.1152\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2 [val]: 100%|███████████████████████████████████████████████████████████████████| 69/69 [00:48<00:00,  1.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2: val loss = 3.0988, CER = 0.9665\n",
            "\n",
            "Sample predictions:\n",
            "GT:    As to the mere Act of Coining considered by itself\n",
            "Pred:  te\n",
            "---\n",
            "GT:    is compelled in the first instance to discover and surrender his\n",
            "Pred:  te\n",
            "---\n",
            "GT:    : specting the actual past and present matter of fact . 2 . If\n",
            "Pred:  te\n",
            "---\n",
            "GT:    first day of every term by themselves respecttively or their\n",
            "Pred:  te\n",
            "---\n",
            "GT:    =ry for the purpose of any other Art  , the use and possession\n",
            "Pred:  te\n",
            "---\n",
            "Saved new best model.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3 [train]: 100%|███████████████████████████████████████████████████████████████| 552/552 [18:34<00:00,  2.02s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3: train loss = 3.0793\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3 [val]: 100%|███████████████████████████████████████████████████████████████████| 69/69 [00:48<00:00,  1.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3: val loss = 3.0684, CER = 0.9655\n",
            "\n",
            "Sample predictions:\n",
            "GT:    As to the mere Act of Coining considered by itself\n",
            "Pred:  te\n",
            "---\n",
            "GT:    is compelled in the first instance to discover and surrender his\n",
            "Pred:  te\n",
            "---\n",
            "GT:    : specting the actual past and present matter of fact . 2 . If\n",
            "Pred:  te\n",
            "---\n",
            "GT:    first day of every term by themselves respecttively or their\n",
            "Pred:  e\n",
            "---\n",
            "GT:    =ry for the purpose of any other Art  , the use and possession\n",
            "Pred:  \"e\n",
            "---\n",
            "Saved new best model.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4 [train]: 100%|███████████████████████████████████████████████████████████████| 552/552 [21:12<00:00,  2.30s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4: train loss = 3.0541\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4 [val]: 100%|███████████████████████████████████████████████████████████████████| 69/69 [00:47<00:00,  1.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4: val loss = 3.1055, CER = 0.9654\n",
            "\n",
            "Sample predictions:\n",
            "GT:    As to the mere Act of Coining considered by itself\n",
            "Pred:  ae\n",
            "---\n",
            "GT:    is compelled in the first instance to discover and surrender his\n",
            "Pred:  ae\n",
            "---\n",
            "GT:    : specting the actual past and present matter of fact . 2 . If\n",
            "Pred:  \"e\n",
            "---\n",
            "GT:    first day of every term by themselves respecttively or their\n",
            "Pred:  oe\n",
            "---\n",
            "GT:    =ry for the purpose of any other Art  , the use and possession\n",
            "Pred:  te\n",
            "---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5 [train]: 100%|███████████████████████████████████████████████████████████████| 552/552 [21:04<00:00,  2.29s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: train loss = 2.9892\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5 [val]: 100%|███████████████████████████████████████████████████████████████████| 69/69 [00:48<00:00,  1.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: val loss = 3.0130, CER = 0.8372\n",
            "\n",
            "Sample predictions:\n",
            "GT:    As to the mere Act of Coining considered by itself\n",
            "Pred:  t       t th  te\n",
            "---\n",
            "GT:    is compelled in the first instance to discover and surrender his\n",
            "Pred:  O         -\n",
            "---\n",
            "GT:    : specting the actual past and present matter of fact . 2 . If\n",
            "Pred:  \"         e\n",
            "---\n",
            "GT:    first day of every term by themselves respecttively or their\n",
            "Pred:  f         e\n",
            "---\n",
            "GT:    =ry for the purpose of any other Art  , the use and possession\n",
            "Pred:  t          e\n",
            "---\n",
            "Saved new best model.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6 [train]: 100%|███████████████████████████████████████████████████████████████| 552/552 [21:51<00:00,  2.38s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6: train loss = 2.8883\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6 [val]: 100%|███████████████████████████████████████████████████████████████████| 69/69 [00:49<00:00,  1.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6: val loss = 2.8753, CER = 0.8161\n",
            "\n",
            "Sample predictions:\n",
            "GT:    As to the mere Act of Coining considered by itself\n",
            "Pred:  :  h     h e h=\n",
            "---\n",
            "GT:    is compelled in the first instance to discover and surrender his\n",
            "Pred:  I         t th e\n",
            "---\n",
            "GT:    : specting the actual past and present matter of fact . 2 . If\n",
            "Pred:  :          o   e\n",
            "---\n",
            "GT:    first day of every term by themselves respecttively or their\n",
            "Pred:  Of h     th   to  e\n",
            "---\n",
            "GT:    =ry for the purpose of any other Art  , the use and possession\n",
            "Pred:  t   th h o  e\n",
            "---\n",
            "Saved new best model.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7 [train]: 100%|███████████████████████████████████████████████████████████████| 552/552 [23:00<00:00,  2.50s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7: train loss = 2.8080\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7 [val]: 100%|███████████████████████████████████████████████████████████████████| 69/69 [00:48<00:00,  1.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7: val loss = 2.8897, CER = 0.7941\n",
            "\n",
            "Sample predictions:\n",
            "GT:    As to the mere Act of Coining considered by itself\n",
            "Pred:  t  th   o ae   o=\n",
            "---\n",
            "GT:    is compelled in the first instance to discover and surrender his\n",
            "Pred:  :      o a e e  e oe\n",
            "---\n",
            "GT:    : specting the actual past and present matter of fact . 2 . If\n",
            "Pred:  : h   o o o ae\n",
            "---\n",
            "GT:    first day of every term by themselves respecttively or their\n",
            "Pred:  Of hy  a a thy th e o oo oe\n",
            "---\n",
            "GT:    =ry for the purpose of any other Art  , the use and possession\n",
            "Pred:  a  th o  e o o o o e\n",
            "---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8 [train]: 100%|███████████████████████████████████████████████████████████████| 552/552 [23:51<00:00,  2.59s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8: train loss = 2.7521\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8 [val]: 100%|███████████████████████████████████████████████████████████████████| 69/69 [00:52<00:00,  1.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8: val loss = 2.7512, CER = 0.7724\n",
            "\n",
            "Sample predictions:\n",
            "GT:    As to the mere Act of Coining considered by itself\n",
            "Pred:  I i th  a o h  e h=\n",
            "---\n",
            "GT:    is compelled in the first instance to discover and surrender his\n",
            "Pred:  [   h fo a e e e  h oe\n",
            "---\n",
            "GT:    : specting the actual past and present matter of fact . 2 . If\n",
            "Pred:  :  th a hee i  e h e\n",
            "---\n",
            "GT:    first day of every term by themselves respecttively or their\n",
            "Pred:  pf hy  y to toy th en h  e\n",
            "---\n",
            "GT:    =ry for the purpose of any other Art  , the use and possession\n",
            "Pred:  :g f th e e ho ae  e\n",
            "---\n",
            "Saved new best model.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9 [train]: 100%|███████████████████████████████████████████████████████████████| 552/552 [24:10<00:00,  2.63s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9: train loss = 2.6779\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9 [val]: 100%|███████████████████████████████████████████████████████████████████| 69/69 [00:52<00:00,  1.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9: val loss = 2.6933, CER = 0.7746\n",
            "\n",
            "Sample predictions:\n",
            "GT:    As to the mere Act of Coining considered by itself\n",
            "Pred:  I th th   o theeeeo o=\n",
            "---\n",
            "GT:    is compelled in the first instance to discover and surrender his\n",
            "Pred:  i ti th fp ie ee e to eee\n",
            "---\n",
            "GT:    : specting the actual past and present matter of fact . 2 . If\n",
            "Pred:  :  th  tee o oe ae\n",
            "---\n",
            "GT:    first day of every term by themselves respecttively or their\n",
            "Pred:  p iy o ay i toy heeeen o\n",
            "---\n",
            "GT:    =ry for the purpose of any other Art  , the use and possession\n",
            "Pred:  -g fo th fp e o o e o\n",
            "---\n",
            "Saved new best model.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10 [train]: 100%|██████████████████████████████████████████████████████████████| 552/552 [24:02<00:00,  2.61s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10: train loss = 2.6283\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10 [val]: 100%|██████████████████████████████████████████████████████████████████| 69/69 [00:50<00:00,  1.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10: val loss = 2.6517, CER = 0.7549\n",
            "\n",
            "Sample predictions:\n",
            "GT:    As to the mere Act of Coining considered by itself\n",
            "Pred:  A o th o of heeen e=\n",
            "---\n",
            "GT:    is compelled in the first instance to discover and surrender his\n",
            "Pred:  i tit  h foi o ee one h ee.\n",
            "---\n",
            "GT:    : specting the actual past and present matter of fact . 2 . If\n",
            "Pred:  :i th e the e te oe ene\n",
            "---\n",
            "GT:    first day of every term by themselves respecttively or their\n",
            "Pred:  p gy of ay ie oy teoeeeneen oeie\n",
            "---\n",
            "GT:    =ry for the purpose of any other Art  , the use and possession\n",
            "Pred:  -g fo th poee ee o oeee ie\n",
            "---\n",
            "Saved new best model.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 11 [train]: 100%|██████████████████████████████████████████████████████████████| 552/552 [24:57<00:00,  2.71s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11: train loss = 2.5770\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 11 [val]: 100%|██████████████████████████████████████████████████████████████████| 69/69 [00:48<00:00,  1.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11: val loss = 2.6864, CER = 0.7287\n",
            "\n",
            "Sample predictions:\n",
            "GT:    As to the mere Act of Coining considered by itself\n",
            "Pred:  I to the a at of herenennee on\n",
            "---\n",
            "GT:    is compelled in the first instance to discover and surrender his\n",
            "Pred:  E pot  th p inaeneniniee\n",
            "---\n",
            "GT:    : specting the actual past and present matter of fact . 2 . If\n",
            "Pred:  : pie to  ee on in h en ee\n",
            "---\n",
            "GT:    first day of every term by themselves respecttively or their\n",
            "Pred:  prt hiy o aiy tie boy th ana\n",
            "---\n",
            "GT:    =ry for the purpose of any other Art  , the use and possession\n",
            "Pred:  :g foe th per eo a oo a en o\n",
            "---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 12 [train]: 100%|██████████████████████████████████████████████████████████████| 552/552 [25:24<00:00,  2.76s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12: train loss = 2.5436\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 12 [val]: 100%|██████████████████████████████████████████████████████████████████| 69/69 [00:47<00:00,  1.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12: val loss = 2.6287, CER = 0.7493\n",
            "\n",
            "Sample predictions:\n",
            "GT:    As to the mere Act of Coining considered by itself\n",
            "Pred:  I to the at of teeni e  o\n",
            "---\n",
            "GT:    is compelled in the first instance to discover and surrender his\n",
            "Pred:  O it i th pt ieee e\n",
            "---\n",
            "GT:    : specting the actual past and present matter of fact . 2 . If\n",
            "Pred:  : p tht oe e ee en en er\n",
            "---\n",
            "GT:    first day of every term by themselves respecttively or their\n",
            "Pred:  pot biy o y hen toy theee ene ee\n",
            "---\n",
            "GT:    =ry for the purpose of any other Art  , the use and possession\n",
            "Pred:  -gy fo the pp  o ae o\n",
            "---\n",
            "Saved new best model.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 13 [train]: 100%|██████████████████████████████████████████████████████████████| 552/552 [25:16<00:00,  2.75s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13: train loss = 2.4941\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 13 [val]: 100%|██████████████████████████████████████████████████████████████████| 69/69 [00:49<00:00,  1.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13: val loss = 2.5654, CER = 0.7343\n",
            "\n",
            "Sample predictions:\n",
            "GT:    As to the mere Act of Coining considered by itself\n",
            "Pred:  I to the   ofe en en e ee o\n",
            "---\n",
            "GT:    is compelled in the first instance to discover and surrender his\n",
            "Pred:  I at i th p iae e ee ho eo\n",
            "---\n",
            "GT:    : specting the actual past and present matter of fact . 2 . If\n",
            "Pred:  :p the a theen ene ie oe\n",
            "---\n",
            "GT:    first day of every term by themselves respecttively or their\n",
            "Pred:  fot bigy of ay he oy theen en on o\n",
            "---\n",
            "GT:    =ry for the purpose of any other Art  , the use and possession\n",
            "Pred:  ag fo the popo oo e oe\n",
            "---\n",
            "Saved new best model.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 14 [train]: 100%|██████████████████████████████████████████████████████████████| 552/552 [24:36<00:00,  2.68s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14: train loss = 2.4505\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 14 [val]: 100%|██████████████████████████████████████████████████████████████████| 69/69 [00:49<00:00,  1.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14: val loss = 2.5291, CER = 0.6982\n",
            "\n",
            "Sample predictions:\n",
            "GT:    As to the mere Act of Coining considered by itself\n",
            "Pred:  I to th moe at o heher enen  ee ee\n",
            "---\n",
            "GT:    is compelled in the first instance to discover and surrender his\n",
            "Pred:  E eaththt i thhee fi inehea en e e ho  e\n",
            "---\n",
            "GT:    : specting the actual past and present matter of fact . 2 . If\n",
            "Pred:  :ptiy th ae areee ine or\n",
            "---\n",
            "GT:    first day of every term by themselves respecttively or their\n",
            "Pred:  prt bhgy of ey he toy theeenenee in o\n",
            "---\n",
            "GT:    =ry for the purpose of any other Art  , the use and possession\n",
            "Pred:  \"g fo the por  ane ea  eneee i\n",
            "---\n",
            "Saved new best model.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 15 [train]: 100%|██████████████████████████████████████████████████████████████| 552/552 [25:09<00:00,  2.74s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15: train loss = 2.4175\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 15 [val]: 100%|██████████████████████████████████████████████████████████████████| 69/69 [00:53<00:00,  1.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15: val loss = 2.5011, CER = 0.6958\n",
            "\n",
            "Sample predictions:\n",
            "GT:    As to the mere Act of Coining considered by itself\n",
            "Pred:  I to th ee at of eer eneee oe=\n",
            "---\n",
            "GT:    is compelled in the first instance to discover and surrender his\n",
            "Pred:  1 o the i the pist inee e en  ho  e \n",
            "---\n",
            "GT:    : specting the actual past and present matter of fact . 2 . If\n",
            "Pred:  : ptoy tha thre e ee e e-\n",
            "---\n",
            "GT:    first day of every term by themselves respecttively or their\n",
            "Pred:  fot hy of ay beone by thee an o-\n",
            "---\n",
            "GT:    =ry for the purpose of any other Art  , the use and possession\n",
            "Pred:  -g fo th pepa o ee o\n",
            "---\n",
            "Saved new best model.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 16 [train]: 100%|██████████████████████████████████████████████████████████████| 552/552 [25:24<00:00,  2.76s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16: train loss = 2.3608\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 16 [val]: 100%|██████████████████████████████████████████████████████████████████| 69/69 [00:48<00:00,  1.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16: val loss = 2.4344, CER = 0.6837\n",
            "\n",
            "Sample predictions:\n",
            "GT:    As to the mere Act of Coining considered by itself\n",
            "Pred:  A to the moe t of beeinenenene e=\n",
            "---\n",
            "GT:    is compelled in the first instance to discover and surrender his\n",
            "Pred:  Eeet i the fi ine e e e e he e ee\n",
            "---\n",
            "GT:    : specting the actual past and present matter of fact . 2 . If\n",
            "Pred:  : pti th ll thee ee ee henee\n",
            "---\n",
            "GT:    first day of every term by themselves respecttively or their\n",
            "Pred:  ft thy of oy tee by theenen  e en ee ee\n",
            "---\n",
            "GT:    =ry for the purpose of any other Art  , the use and possession\n",
            "Pred:  \"y f the ppe eo  ee e ie\n",
            "---\n",
            "Saved new best model.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 17 [train]: 100%|██████████████████████████████████████████████████████████████| 552/552 [25:14<00:00,  2.74s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17: train loss = 2.3218\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 17 [val]: 100%|██████████████████████████████████████████████████████████████████| 69/69 [00:49<00:00,  1.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17: val loss = 2.4117, CER = 0.6744\n",
            "\n",
            "Sample predictions:\n",
            "GT:    As to the mere Act of Coining considered by itself\n",
            "Pred:  I to the e t of enen ene ene en=\n",
            "---\n",
            "GT:    is compelled in the first instance to discover and surrender his\n",
            "Pred:  i etd i th pfit ineee en e a  ee\n",
            "---\n",
            "GT:    : specting the actual past and present matter of fact . 2 . If\n",
            "Pred:  : ptin the al hene en eee o e\n",
            "---\n",
            "GT:    first day of every term by themselves respecttively or their\n",
            "Pred:  ft dy of oy ti boy theennen er a e e oe\n",
            "---\n",
            "GT:    =ry for the purpose of any other Art  , the use and possession\n",
            "Pred:  -g fo the pp o  aeee ee\n",
            "---\n",
            "Saved new best model.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 18 [train]: 100%|██████████████████████████████████████████████████████████████| 552/552 [24:29<00:00,  2.66s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18: train loss = 2.2842\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 18 [val]: 100%|██████████████████████████████████████████████████████████████████| 69/69 [00:49<00:00,  1.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18: val loss = 2.3918, CER = 0.6558\n",
            "\n",
            "Sample predictions:\n",
            "GT:    As to the mere Act of Coining considered by itself\n",
            "Pred:  I to the ee t of beenenenenee ee\n",
            "---\n",
            "GT:    is compelled in the first instance to discover and surrender his\n",
            "Pred:  i tt i the pat in hen e en e e e e\n",
            "---\n",
            "GT:    : specting the actual past and present matter of fact . 2 . If\n",
            "Pred:  : ttiiny the ala h e e ine e e\n",
            "---\n",
            "GT:    first day of every term by themselves respecttively or their\n",
            "Pred:  ft by o oy hen by thne en ar e eeee\n",
            "---\n",
            "GT:    =ry for the purpose of any other Art  , the use and possession\n",
            "Pred:  :g fo the pepee  a ee ee\n",
            "---\n",
            "Saved new best model.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 19 [train]: 100%|██████████████████████████████████████████████████████████████| 552/552 [24:42<00:00,  2.69s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19: train loss = 2.2481\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 19 [val]: 100%|██████████████████████████████████████████████████████████████████| 69/69 [00:50<00:00,  1.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19: val loss = 2.3959, CER = 0.6491\n",
            "\n",
            "Sample predictions:\n",
            "GT:    As to the mere Act of Coining considered by itself\n",
            "Pred:  Is to thee  t of enen enen en en e o.\n",
            "---\n",
            "GT:    is compelled in the first instance to discover and surrender his\n",
            "Pred:  doaptt i the fit in hen e en ee e er oee\n",
            "---\n",
            "GT:    : specting the actual past and present matter of fact . 2 . If\n",
            "Pred:  :paig thealeeee heeen ee eene oe\n",
            "---\n",
            "GT:    first day of every term by themselves respecttively or their\n",
            "Pred:  fat by of oy tomn by theenenenen en ere ar e ioe\n",
            "---\n",
            "GT:    =ry for the purpose of any other Art  , the use and possession\n",
            "Pred:  :g for the peporoneroa e ar enee ee\n",
            "---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 20 [train]: 100%|██████████████████████████████████████████████████████████████| 552/552 [24:17<00:00,  2.64s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20: train loss = 2.1923\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 20 [val]: 100%|██████████████████████████████████████████████████████████████████| 69/69 [00:50<00:00,  1.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20: val loss = 2.3159, CER = 0.6291\n",
            "\n",
            "Sample predictions:\n",
            "GT:    As to the mere Act of Coining considered by itself\n",
            "Pred:  As to the e at of boeen onen en en e e.\n",
            "---\n",
            "GT:    is compelled in the first instance to discover and surrender his\n",
            "Pred:  i aptad i the fit inhen e e en or e at\n",
            "---\n",
            "GT:    : specting the actual past and present matter of fact . 2 . If\n",
            "Pred:  : patiny he alat hereen e enen en e\n",
            "---\n",
            "GT:    first day of every term by themselves respecttively or their\n",
            "Pred:  fit hy f oy tmn by themnon e e a e\n",
            "---\n",
            "GT:    =ry for the purpose of any other Art  , the use and possession\n",
            "Pred:  :g for the peporen  a  anerene ae\n",
            "---\n",
            "Saved new best model.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 21 [train]: 100%|██████████████████████████████████████████████████████████████| 552/552 [24:59<00:00,  2.72s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 21: train loss = 2.1461\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 21 [val]: 100%|██████████████████████████████████████████████████████████████████| 69/69 [00:50<00:00,  1.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 21: val loss = 2.2921, CER = 0.6143\n",
            "\n",
            "Sample predictions:\n",
            "GT:    As to the mere Act of Coining considered by itself\n",
            "Pred:  A to the ere aat of linenenen en e ene\n",
            "---\n",
            "GT:    is compelled in the first instance to discover and surrender his\n",
            "Pred:  io alald in the fist inhe e en en er e ee\n",
            "---\n",
            "GT:    : specting the actual past and present matter of fact . 2 . If\n",
            "Pred:  : etlinr thealel peeen en e en enen e en e\n",
            "---\n",
            "GT:    first day of every term by themselves respecttively or their\n",
            "Pred:  fut dy o ony tn by thenen en en on en an o oe\n",
            "---\n",
            "GT:    =ry for the purpose of any other Art  , the use and possession\n",
            "Pred:  \"g for the pepose o f en enener ene\n",
            "---\n",
            "Saved new best model.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 22 [train]: 100%|██████████████████████████████████████████████████████████████| 552/552 [23:54<00:00,  2.60s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 22: train loss = 2.0936\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 22 [val]: 100%|██████████████████████████████████████████████████████████████████| 69/69 [00:49<00:00,  1.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 22: val loss = 2.2668, CER = 0.6126\n",
            "\n",
            "Sample predictions:\n",
            "GT:    As to the mere Act of Coining considered by itself\n",
            "Pred:  As to the mere at of ioaninnen e=\n",
            "---\n",
            "GT:    is compelled in the first instance to discover and surrender his\n",
            "Pred:  i anpttd in the fist inhen e en en oe  oe\n",
            "---\n",
            "GT:    : specting the actual past and present matter of fact . 2 . If\n",
            "Pred:  : pedig the alel pha en ane en en e\n",
            "---\n",
            "GT:    first day of every term by themselves respecttively or their\n",
            "Pred:  fit y of ory tomn by themsen er  ea o oe\n",
            "---\n",
            "GT:    =ry for the purpose of any other Art  , the use and possession\n",
            "Pred:  :ny forr the pepo oo ane o ee\n",
            "---\n",
            "Saved new best model.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 23 [train]: 100%|██████████████████████████████████████████████████████████████| 552/552 [23:17<00:00,  2.53s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 23: train loss = 2.0439\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 23 [val]: 100%|██████████████████████████████████████████████████████████████████| 69/69 [00:51<00:00,  1.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 23: val loss = 2.2522, CER = 0.5917\n",
            "\n",
            "Sample predictions:\n",
            "GT:    As to the mere Act of Coining considered by itself\n",
            "Pred:  A to the ee at oof Con on on e en he hen=\n",
            "---\n",
            "GT:    is compelled in the first instance to discover and surrender his\n",
            "Pred:  i anptlade in the foif ine en  en  e an e=\n",
            "---\n",
            "GT:    : specting the actual past and present matter of fact . 2 . If\n",
            "Pred:  : peliny the alt per en en o a enin en er e\n",
            "---\n",
            "GT:    first day of every term by themselves respecttively or their\n",
            "Pred:  fit y of ory to by theni o er o e o ie\n",
            "---\n",
            "GT:    =ry for the purpose of any other Art  , the use and possession\n",
            "Pred:  :y for the pupoe e on aro o ee\n",
            "---\n",
            "Saved new best model.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 24 [train]: 100%|██████████████████████████████████████████████████████████████| 552/552 [22:58<00:00,  2.50s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 24: train loss = 1.9963\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 24 [val]: 100%|██████████████████████████████████████████████████████████████████| 69/69 [00:49<00:00,  1.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 24: val loss = 2.2203, CER = 0.5764\n",
            "\n",
            "Sample predictions:\n",
            "GT:    As to the mere Act of Coining considered by itself\n",
            "Pred:  Is to the mere t of leiinin en en en e ee\n",
            "---\n",
            "GT:    is compelled in the first instance to discover and surrender his\n",
            "Pred:  inanptt in the fisf ine e e en e en ee\n",
            "---\n",
            "GT:    : specting the actual past and present matter of fact . 2 . If\n",
            "Pred:  : ptng the alt her a en on o o ee e e\n",
            "---\n",
            "GT:    first day of every term by themselves respecttively or their\n",
            "Pred:  fit dy of ory tm boy tent o  e  oe\n",
            "---\n",
            "GT:    =ry for the purpose of any other Art  , the use and possession\n",
            "Pred:  - y for the pupoo e  oe en e n oo ee\n",
            "---\n",
            "Saved new best model.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 25 [train]: 100%|██████████████████████████████████████████████████████████████| 552/552 [22:13<00:00,  2.42s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 25: train loss = 1.9466\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 25 [val]: 100%|██████████████████████████████████████████████████████████████████| 69/69 [00:52<00:00,  1.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 25: val loss = 2.1937, CER = 0.5754\n",
            "\n",
            "Sample predictions:\n",
            "GT:    As to the mere Act of Coining considered by itself\n",
            "Pred:  Is to the mere t of n binin on eneneneee\n",
            "---\n",
            "GT:    is compelled in the first instance to discover and surrender his\n",
            "Pred:  iscptad in the fast in he e e e e anee\n",
            "---\n",
            "GT:    : specting the actual past and present matter of fact . 2 . If\n",
            "Pred:  : rpecting the aacleal the i a  e he e en ee\n",
            "---\n",
            "GT:    first day of every term by themselves respecttively or their\n",
            "Pred:  fit day of oy thom boy tn i as e er hen en on oe\n",
            "---\n",
            "GT:    =ry for the purpose of any other Art  , the use and possession\n",
            "Pred:  :y frr the punpoee  fo on an  oee\n",
            "---\n",
            "Saved new best model.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 26 [train]: 100%|██████████████████████████████████████████████████████████████| 552/552 [21:51<00:00,  2.38s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 26: train loss = 1.8937\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 26 [val]: 100%|██████████████████████████████████████████████████████████████████| 69/69 [00:49<00:00,  1.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 26: val loss = 2.1367, CER = 0.5559\n",
            "\n",
            "Sample predictions:\n",
            "GT:    As to the mere Act of Coining considered by itself\n",
            "Pred:  As to the mere t of in in in en en en a on e\n",
            "---\n",
            "GT:    is compelled in the first instance to discover and surrender his\n",
            "Pred:  i cmptatd in the fist in e e e e e on en e\n",
            "---\n",
            "GT:    : specting the actual past and present matter of fact . 2 . If\n",
            "Pred:  : rpecting the aeleab the e en en enin e e een ee\n",
            "---\n",
            "GT:    first day of every term by themselves respecttively or their\n",
            "Pred:  fiot day of orny tm by theme en e en e e e e\n",
            "---\n",
            "GT:    =ry for the purpose of any other Art  , the use and possession\n",
            "Pred:  : y for the pupoo e e an en n e e e ene\n",
            "---\n",
            "Saved new best model.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 27 [train]: 100%|██████████████████████████████████████████████████████████████| 552/552 [21:36<00:00,  2.35s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 27: train loss = 1.8510\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 27 [val]: 100%|██████████████████████████████████████████████████████████████████| 69/69 [00:53<00:00,  1.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 27: val loss = 2.1274, CER = 0.5345\n",
            "\n",
            "Sample predictions:\n",
            "GT:    As to the mere Act of Coining considered by itself\n",
            "Pred:  As to the mere t foff n linanen an n a e oe =\n",
            "---\n",
            "GT:    is compelled in the first instance to discover and surrender his\n",
            "Pred:  is cnptad in the fist ine  e e a ee\n",
            "---\n",
            "GT:    : specting the actual past and present matter of fact . 2 . If\n",
            "Pred:  : rpecting the aelal he  aher o en hen e en en ae\n",
            "---\n",
            "GT:    first day of every term by themselves respecttively or their\n",
            "Pred:  firt day of erny term by thenti e e e n ee\n",
            "---\n",
            "GT:    =ry for the purpose of any other Art  , the use and possession\n",
            "Pred:  : y for the pupose o er aree en ee\n",
            "---\n",
            "Saved new best model.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 28 [train]: 100%|██████████████████████████████████████████████████████████████| 552/552 [21:01<00:00,  2.29s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 28: train loss = 1.8067\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 28 [val]: 100%|██████████████████████████████████████████████████████████████████| 69/69 [00:49<00:00,  1.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 28: val loss = 2.0773, CER = 0.5436\n",
            "\n",
            "Sample predictions:\n",
            "GT:    As to the mere Act of Coining considered by itself\n",
            "Pred:  As to the mere aet of Ciinin n nin ene\n",
            "---\n",
            "GT:    is compelled in the first instance to discover and surrender his\n",
            "Pred:  i cnmpaltad in the frist in en en en en en e an en e\n",
            "---\n",
            "GT:    : specting the actual past and present matter of fact . 2 . If\n",
            "Pred:  : spedting he aetealad hen anhan h in hen een en ee\n",
            "---\n",
            "GT:    first day of every term by themselves respecttively or their\n",
            "Pred:  firt day of erry term by thensiela e het es\n",
            "---\n",
            "GT:    =ry for the purpose of any other Art  , the use and possession\n",
            "Pred:  : ryf forr the pupoee o en ane eee\n",
            "---\n",
            "Saved new best model.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 29 [train]: 100%|██████████████████████████████████████████████████████████████| 552/552 [20:51<00:00,  2.27s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 29: train loss = 1.7706\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 29 [val]: 100%|██████████████████████████████████████████████████████████████████| 69/69 [00:50<00:00,  1.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 29: val loss = 2.0685, CER = 0.5219\n",
            "\n",
            "Sample predictions:\n",
            "GT:    As to the mere Act of Coining considered by itself\n",
            "Pred:  A to the mere aet of linin  min  e on oe\n",
            "---\n",
            "GT:    is compelled in the first instance to discover and surrender his\n",
            "Pred:  is cnplladt in the frcst inhe e r e e\n",
            "---\n",
            "GT:    : specting the actual past and present matter of fact . 2 . If\n",
            "Pred:  : rpecting the aeleal he at har h he r e e en e e\n",
            "---\n",
            "GT:    first day of every term by themselves respecttively or their\n",
            "Pred:  firt day of erny term by themnsiel os er e i oe\n",
            "---\n",
            "GT:    =ry for the purpose of any other Art  , the use and possession\n",
            "Pred:  : y for the pupoe e  o en er  e en e ene\n",
            "---\n",
            "Saved new best model.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 30 [train]: 100%|██████████████████████████████████████████████████████████████| 552/552 [21:06<00:00,  2.29s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 30: train loss = 1.7394\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 30 [val]: 100%|██████████████████████████████████████████████████████████████████| 69/69 [00:48<00:00,  1.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 30: val loss = 2.0884, CER = 0.5311\n",
            "\n",
            "Sample predictions:\n",
            "GT:    As to the mere Act of Coining considered by itself\n",
            "Pred:  A to the mere at of linin n n an n an oe\n",
            "---\n",
            "GT:    is compelled in the first instance to discover and surrender his\n",
            "Pred:  'icmpttd in the frst i e en e e\n",
            "---\n",
            "GT:    : specting the actual past and present matter of fact . 2 . If\n",
            "Pred:  : specting the aeleal heaa o s han e i en oe\n",
            "---\n",
            "GT:    first day of every term by themselves respecttively or their\n",
            "Pred:  firut day of ery trm by thes l r he en en oe\n",
            "---\n",
            "GT:    =ry for the purpose of any other Art  , the use and possession\n",
            "Pred:  : y for the pupose o  ar ne en e ene\n",
            "---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 31 [train]: 100%|██████████████████████████████████████████████████████████████| 552/552 [19:32<00:00,  2.12s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 31: train loss = 1.7077\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 31 [val]: 100%|██████████████████████████████████████████████████████████████████| 69/69 [00:48<00:00,  1.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 31: val loss = 2.0620, CER = 0.5164\n",
            "\n",
            "Sample predictions:\n",
            "GT:    As to the mere Act of Coining considered by itself\n",
            "Pred:  As to the mere act off n on on n e n on en hen o=\n",
            "---\n",
            "GT:    is compelled in the first instance to discover and surrender his\n",
            "Pred:  is cmpellead in the finist insa e a e en e on e =\n",
            "---\n",
            "GT:    : specting the actual past and present matter of fact . 2 . If\n",
            "Pred:  : specting the aeteal phe a on n n he en  en oe\n",
            "---\n",
            "GT:    first day of every term by themselves respecttively or their\n",
            "Pred:  firt day of ery term by thers e  he en n ae\n",
            "---\n",
            "GT:    =ry for the purpose of any other Art  , the use and possession\n",
            "Pred:  : ry for the pupo e ef  e en ar  en e e e\n",
            "---\n",
            "Saved new best model.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 32 [train]: 100%|██████████████████████████████████████████████████████████████| 552/552 [18:58<00:00,  2.06s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 32: train loss = 1.6667\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 32 [val]: 100%|██████████████████████████████████████████████████████████████████| 69/69 [00:48<00:00,  1.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 32: val loss = 2.0309, CER = 0.5041\n",
            "\n",
            "Sample predictions:\n",
            "GT:    As to the mere Act of Coining considered by itself\n",
            "Pred:  As to the mere aet ff r enan e  n   on o.\n",
            "---\n",
            "GT:    is compelled in the first instance to discover and surrender his\n",
            "Pred:  icmnpllad in the frist inse an e en e ar e e\n",
            "---\n",
            "GT:    : specting the actual past and present matter of fact . 2 . If\n",
            "Pred:  : rpeeteing the aeleal phe a hat thn en he en e en en oe\n",
            "---\n",
            "GT:    first day of every term by themselves respecttively or their\n",
            "Pred:  frot day of erery term by themsiel e en in are\n",
            "---\n",
            "GT:    =ry for the purpose of any other Art  , the use and possession\n",
            "Pred:  : ry for the pupose  fo n ar  en en e en e\n",
            "---\n",
            "Saved new best model.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 33 [train]: 100%|██████████████████████████████████████████████████████████████| 552/552 [18:26<00:00,  2.01s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 33: train loss = 1.6315\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 33 [val]: 100%|██████████████████████████████████████████████████████████████████| 69/69 [00:58<00:00,  1.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 33: val loss = 2.0485, CER = 0.5074\n",
            "\n",
            "Sample predictions:\n",
            "GT:    As to the mere Act of Coining considered by itself\n",
            "Pred:  As to the mere act ff r in in on en en an hen oe\n",
            "---\n",
            "GT:    is compelled in the first instance to discover and surrender his\n",
            "Pred:  icompllad in the frist in e en o an e ae\n",
            "---\n",
            "GT:    : specting the actual past and present matter of fact . 2 . If\n",
            "Pred:  : rpecting the aeleal he an er on an thar en en er en o e\n",
            "---\n",
            "GT:    first day of every term by themselves respecttively or their\n",
            "Pred:  frot day of ery term by theme ler er e en en oe\n",
            "---\n",
            "GT:    =ry for the purpose of any other Art  , the use and possession\n",
            "Pred:  : ry forr the pupose a an e en o en en e\n",
            "---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 34 [train]: 100%|██████████████████████████████████████████████████████████████| 552/552 [19:12<00:00,  2.09s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 34: train loss = 1.6062\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 34 [val]: 100%|██████████████████████████████████████████████████████████████████| 69/69 [00:51<00:00,  1.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 34: val loss = 2.0431, CER = 0.5015\n",
            "\n",
            "Sample predictions:\n",
            "GT:    As to the mere Act of Coining considered by itself\n",
            "Pred:  A to the mere act of CEindin  in a an ar oe\n",
            "---\n",
            "GT:    is compelled in the first instance to discover and surrender his\n",
            "Pred:  is cmpallad in the frist inses e e e o a an en e\n",
            "---\n",
            "GT:    : specting the actual past and present matter of fact . 2 . If\n",
            "Pred:  : rpeeting the aclial he s a s s hen n e en en an ae\n",
            "---\n",
            "GT:    first day of every term by themselves respecttively or their\n",
            "Pred:  frt day of ery term by themster i er re en n ae\n",
            "---\n",
            "GT:    =ry for the purpose of any other Art  , the use and possession\n",
            "Pred:  : ry for the purpso a or e an ar n er en en en e\n",
            "---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 35 [train]: 100%|██████████████████████████████████████████████████████████████| 552/552 [19:35<00:00,  2.13s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 35: train loss = 1.5851\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 35 [val]: 100%|██████████████████████████████████████████████████████████████████| 69/69 [00:49<00:00,  1.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 35: val loss = 2.0441, CER = 0.4859\n",
            "\n",
            "Sample predictions:\n",
            "GT:    As to the mere Act of Coining considered by itself\n",
            "Pred:  As to the mere aet of Coini in en ar ane hen oe\n",
            "---\n",
            "GT:    is compelled in the first instance to discover and surrender his\n",
            "Pred:  icompaillud in the frist inse e e e o e er e e\n",
            "---\n",
            "GT:    : specting the actual past and present matter of fact . 2 . If\n",
            "Pred:  : rpecting he actial pao he en e en en oe\n",
            "---\n",
            "GT:    first day of every term by themselves respecttively or their\n",
            "Pred:  frot day of eerny term by themsele e  ee en es\n",
            "---\n",
            "GT:    =ry for the purpose of any other Art  , the use and possession\n",
            "Pred:  : ry for the purpose of  ar n e en en e e\n",
            "---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 36 [train]: 100%|██████████████████████████████████████████████████████████████| 552/552 [18:56<00:00,  2.06s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 36: train loss = 1.5632\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 36 [val]: 100%|██████████████████████████████████████████████████████████████████| 69/69 [00:52<00:00,  1.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 36: val loss = 2.0264, CER = 0.4960\n",
            "\n",
            "Sample predictions:\n",
            "GT:    As to the mere Act of Coining considered by itself\n",
            "Pred:  As to the mere act of lCin in n en on on on ho o=\n",
            "---\n",
            "GT:    is compelled in the first instance to discover and surrender his\n",
            "Pred:  iwompllad in the frist in e e en e n e e\n",
            "---\n",
            "GT:    : specting the actual past and present matter of fact . 2 . If\n",
            "Pred:  : rpecting the aelial p e ht o o he en e on en o e\n",
            "---\n",
            "GT:    first day of every term by themselves respecttively or their\n",
            "Pred:  frot day of erny term by themsi  he e en e\n",
            "---\n",
            "GT:    =ry for the purpose of any other Art  , the use and possession\n",
            "Pred:  : ny for the purpose ff n  en on e er o e e\n",
            "---\n",
            "Saved new best model.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 37 [train]: 100%|██████████████████████████████████████████████████████████████| 552/552 [18:55<00:00,  2.06s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 37: train loss = 1.5461\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 37 [val]: 100%|██████████████████████████████████████████████████████████████████| 69/69 [00:51<00:00,  1.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 37: val loss = 2.0381, CER = 0.4863\n",
            "\n",
            "Sample predictions:\n",
            "GT:    As to the mere Act of Coining considered by itself\n",
            "Pred:  A to the mere act of Clinsi in  ho oe\n",
            "---\n",
            "GT:    is compelled in the first instance to discover and surrender his\n",
            "Pred:  icompllad in the frist is e es an e e\n",
            "---\n",
            "GT:    : specting the actual past and present matter of fact . 2 . If\n",
            "Pred:  : rpecting the aclial pas t n es en o n en o e\n",
            "---\n",
            "GT:    first day of every term by themselves respecttively or their\n",
            "Pred:  firt day of eery term by themsel s o e e oe\n",
            "---\n",
            "GT:    =ry for the purpose of any other Art  , the use and possession\n",
            "Pred:  : ry for the pupose o an an e n te ee\n",
            "---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 38 [train]: 100%|██████████████████████████████████████████████████████████████| 552/552 [18:50<00:00,  2.05s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 38: train loss = 1.5201\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 38 [val]: 100%|██████████████████████████████████████████████████████████████████| 69/69 [00:51<00:00,  1.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 38: val loss = 2.0237, CER = 0.4847\n",
            "\n",
            "Sample predictions:\n",
            "GT:    As to the mere Act of Coining considered by itself\n",
            "Pred:  A to the mere act of Cininin in en en in en oe\n",
            "---\n",
            "GT:    is compelled in the first instance to discover and surrender his\n",
            "Pred:  is compullad in the frist ins a tot o en e an e e\n",
            "---\n",
            "GT:    : specting the actual past and present matter of fact . 2 . If\n",
            "Pred:  : rhecting the aclial pasos an er e on en o oe\n",
            "---\n",
            "GT:    first day of every term by themselves respecttively or their\n",
            "Pred:  firt day of ererny term by themslel s or et en en oe\n",
            "---\n",
            "GT:    =ry for the purpose of any other Art  , the use and possession\n",
            "Pred:  : ny for the pupose of an n in es hon ene\n",
            "---\n",
            "Saved new best model.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 39 [train]: 100%|██████████████████████████████████████████████████████████████| 552/552 [18:40<00:00,  2.03s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 39: train loss = 1.4941\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 39 [val]: 100%|██████████████████████████████████████████████████████████████████| 69/69 [00:50<00:00,  1.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 39: val loss = 2.0324, CER = 0.4973\n",
            "\n",
            "Sample predictions:\n",
            "GT:    As to the mere Act of Coining considered by itself\n",
            "Pred:  As to the mere aet of Ci i i in  en an en hen e.\n",
            "---\n",
            "GT:    is compelled in the first instance to discover and surrender his\n",
            "Pred:  icmplled in the frst inin a e a e e an en en e ae\n",
            "---\n",
            "GT:    : specting the actual past and present matter of fact . 2 . If\n",
            "Pred:  : rpecteng the actial pe n e oi enthen  e ar en e ae\n",
            "---\n",
            "GT:    first day of every term by themselves respecttively or their\n",
            "Pred:  frtt day of eery term by themeler r e  o e sen e\n",
            "---\n",
            "GT:    =ry for the purpose of any other Art  , the use and possession\n",
            "Pred:  :ny for the purpose f an an n e en en ene\n",
            "---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 40 [train]: 100%|██████████████████████████████████████████████████████████████| 552/552 [18:26<00:00,  2.01s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 40: train loss = 1.4882\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 40 [val]: 100%|██████████████████████████████████████████████████████████████████| 69/69 [00:53<00:00,  1.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 40: val loss = 2.0609, CER = 0.4745\n",
            "\n",
            "Sample predictions:\n",
            "GT:    As to the mere Act of Coining considered by itself\n",
            "Pred:  As to the mere acet of Cinin en ar in on oe\n",
            "---\n",
            "GT:    is compelled in the first instance to discover and surrender his\n",
            "Pred:  iscmpellad in the frst ine a o n o an oe e\n",
            "---\n",
            "GT:    : specting the actual past and present matter of fact . 2 . If\n",
            "Pred:  : rpecting the actial pa os n han en e t en o ae\n",
            "---\n",
            "GT:    first day of every term by themselves respecttively or their\n",
            "Pred:  frtt day of exery term by thembleleas  e e  ae\n",
            "---\n",
            "GT:    =ry for the purpose of any other Art  , the use and possession\n",
            "Pred:  : ry for the purpose o    an an h on e n e\n",
            "---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 41 [train]: 100%|██████████████████████████████████████████████████████████████| 552/552 [18:08<00:00,  1.97s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 41: train loss = 1.4644\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 41 [val]: 100%|██████████████████████████████████████████████████████████████████| 69/69 [00:49<00:00,  1.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 41: val loss = 2.0885, CER = 0.4716\n",
            "\n",
            "Sample predictions:\n",
            "GT:    As to the mere Act of Coining considered by itself\n",
            "Pred:  A to the merve act of Cinin en on on oe\n",
            "---\n",
            "GT:    is compelled in the first instance to discover and surrender his\n",
            "Pred:  icompellad in thes frist insta e n e  e\n",
            "---\n",
            "GT:    : specting the actual past and present matter of fact . 2 . If\n",
            "Pred:  : rpecting the actial paost an en o en en o e\n",
            "---\n",
            "GT:    first day of every term by themselves respecttively or their\n",
            "Pred:  firot day of enery term by themseles s s e  e en aie\n",
            "---\n",
            "GT:    =ry for the purpose of any other Art  , the use and possession\n",
            "Pred:  :nry for the purpose of a  an en e en en ee\n",
            "---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 42 [train]: 100%|██████████████████████████████████████████████████████████████| 552/552 [17:56<00:00,  1.95s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 42: train loss = 1.4524\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 42 [val]: 100%|██████████████████████████████████████████████████████████████████| 69/69 [00:49<00:00,  1.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 42: val loss = 2.0241, CER = 0.4819\n",
            "\n",
            "Sample predictions:\n",
            "GT:    As to the mere Act of Coining considered by itself\n",
            "Pred:  A to the mere acet of Codidan on en an an he a=\n",
            "---\n",
            "GT:    is compelled in the first instance to discover and surrender his\n",
            "Pred:  Iscompallad in the frist iset a e on e an he e\n",
            "---\n",
            "GT:    : specting the actual past and present matter of fact . 2 . If\n",
            "Pred:  : rpecting the actial paos nan en oe on en on te\n",
            "---\n",
            "GT:    first day of every term by themselves respecttively or their\n",
            "Pred:  fortt day of exery term by themsel o ese hos en en ane\n",
            "---\n",
            "GT:    =ry for the purpose of any other Art  , the use and possession\n",
            "Pred:  :nry for the purpose of on n an an an en an ene\n",
            "---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 43 [train]: 100%|██████████████████████████████████████████████████████████████| 552/552 [17:39<00:00,  1.92s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 43: train loss = 1.4266\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 43 [val]: 100%|██████████████████████████████████████████████████████████████████| 69/69 [00:50<00:00,  1.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 43: val loss = 2.0459, CER = 0.4911\n",
            "\n",
            "Sample predictions:\n",
            "GT:    As to the mere Act of Coining considered by itself\n",
            "Pred:  A to the merve act of lid in ir on an ie hen ti=\n",
            "---\n",
            "GT:    is compelled in the first instance to discover and surrender his\n",
            "Pred:  ircompilld in the frist inset a o on et an he  e\n",
            "---\n",
            "GT:    : specting the actual past and present matter of fact . 2 . If\n",
            "Pred:  : specting the aclial haa os an han en en en en ote\n",
            "---\n",
            "GT:    first day of every term by themselves respecttively or their\n",
            "Pred:  firtt day of every term by temste os ef ero en en e\n",
            "---\n",
            "GT:    =ry for the purpose of any other Art  , the use and possession\n",
            "Pred:  :ny for the purpose o o n n en e ten en ene\n",
            "---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 44 [train]: 100%|██████████████████████████████████████████████████████████████| 552/552 [17:10<00:00,  1.87s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 44: train loss = 1.4139\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 44 [val]: 100%|██████████████████████████████████████████████████████████████████| 69/69 [00:51<00:00,  1.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 44: val loss = 2.0260, CER = 0.4799\n",
            "\n",
            "Sample predictions:\n",
            "GT:    As to the mere Act of Coining considered by itself\n",
            "Pred:  As to the mere act of Cin n sen n en an an he e=\n",
            "---\n",
            "GT:    is compelled in the first instance to discover and surrender his\n",
            "Pred:  icompelld in the frist ina e a e on e ene he e\n",
            "---\n",
            "GT:    : specting the actual past and present matter of fact . 2 . If\n",
            "Pred:  : rpecteing the actiial pas nat en en er en o ae\n",
            "---\n",
            "GT:    first day of every term by themselves respecttively or their\n",
            "Pred:  frot day of everny term by themsel or s e  e en ee\n",
            "---\n",
            "GT:    =ry for the purpose of any other Art  , the use and possession\n",
            "Pred:  - ry for the purpose of a n an an e e ene\n",
            "---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 45 [train]: 100%|██████████████████████████████████████████████████████████████| 552/552 [17:01<00:00,  1.85s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 45: train loss = 1.3983\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 45 [val]: 100%|██████████████████████████████████████████████████████████████████| 69/69 [00:49<00:00,  1.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 45: val loss = 2.0901, CER = 0.4672\n",
            "\n",
            "Sample predictions:\n",
            "GT:    As to the mere Act of Coining considered by itself\n",
            "Pred:  As to the mere act of Cisi in en  t an han he ee\n",
            "---\n",
            "GT:    is compelled in the first instance to discover and surrender his\n",
            "Pred:  i compellad in the frist inses te et e e en e =\n",
            "---\n",
            "GT:    : specting the actual past and present matter of fact . 2 . If\n",
            "Pred:  : rpecting the actial pas at en en en on o toe\n",
            "---\n",
            "GT:    first day of every term by themselves respecttively or their\n",
            "Pred:  frt day of exerny term by themsele ese eo en sen ane\n",
            "---\n",
            "GT:    =ry for the purpose of any other Art  , the use and possession\n",
            "Pred:  : ry for the purpose of aan an e en e e e\n",
            "---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 46 [train]: 100%|██████████████████████████████████████████████████████████████| 552/552 [16:40<00:00,  1.81s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 46: train loss = 1.3875\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 46 [val]: 100%|██████████████████████████████████████████████████████████████████| 69/69 [00:49<00:00,  1.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 46: val loss = 2.0400, CER = 0.4700\n",
            "\n",
            "Sample predictions:\n",
            "GT:    As to the mere Act of Coining considered by itself\n",
            "Pred:  As to the mere acet of Cininin in en ar an en es\n",
            "---\n",
            "GT:    is compelled in the first instance to discover and surrender his\n",
            "Pred:  is compelld in the frst inte a on n e en e e\n",
            "---\n",
            "GT:    : specting the actual past and present matter of fact . 2 . If\n",
            "Pred:  : rpecting te acetial pas in an en en on en o ae\n",
            "---\n",
            "GT:    first day of every term by themselves respecttively or their\n",
            "Pred:  firot day of exerny term by themsel ef are o  en en aeie\n",
            "---\n",
            "GT:    =ry for the purpose of any other Art  , the use and possession\n",
            "Pred:  : ry for the purpose of a n a on as en e  e\n",
            "---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 47 [train]: 100%|██████████████████████████████████████████████████████████████| 552/552 [16:04<00:00,  1.75s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 47: train loss = 1.3763\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 47 [val]: 100%|██████████████████████████████████████████████████████████████████| 69/69 [00:46<00:00,  1.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 47: val loss = 2.0502, CER = 0.4736\n",
            "\n",
            "Sample predictions:\n",
            "GT:    As to the mere Act of Coining considered by itself\n",
            "Pred:  As to the mere act of Coin imin en er in e e=\n",
            "---\n",
            "GT:    is compelled in the first instance to discover and surrender his\n",
            "Pred:  i compellad in the frist inse e tet en a er e e\n",
            "---\n",
            "GT:    : specting the actual past and present matter of fact . 2 . If\n",
            "Pred:  : rpecting the aetial ha a a os ie het en e or e to oe\n",
            "---\n",
            "GT:    first day of every term by themselves respecttively or their\n",
            "Pred:  firt day of ereny term by themsel of oferethe en er eie\n",
            "---\n",
            "GT:    =ry for the purpose of any other Art  , the use and possession\n",
            "Pred:  : ny for the purpose o ot a n er en e en or e ne\n",
            "---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 48 [train]: 100%|██████████████████████████████████████████████████████████████| 552/552 [15:37<00:00,  1.70s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 48: train loss = 1.3697\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 48 [val]: 100%|██████████████████████████████████████████████████████████████████| 69/69 [00:48<00:00,  1.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 48: val loss = 2.0878, CER = 0.4723\n",
            "\n",
            "Sample predictions:\n",
            "GT:    As to the mere Act of Coining considered by itself\n",
            "Pred:  A to the mere act of Cdinipin e an aen he ae\n",
            "---\n",
            "GT:    is compelled in the first instance to discover and surrender his\n",
            "Pred:  icompellad in the finrst instean e e r e ae\n",
            "---\n",
            "GT:    : specting the actual past and present matter of fact . 2 . If\n",
            "Pred:  : rpecteing the actial pas eaen en en on en o ae\n",
            "---\n",
            "GT:    first day of every term by themselves respecttively or their\n",
            "Pred:  first day of eeny term by themsel de ef ire hes n en ee\n",
            "---\n",
            "GT:    =ry for the purpose of any other Art  , the use and possession\n",
            "Pred:  : ny for the pupose of a n an an er in an ene\n",
            "---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 49 [train]: 100%|██████████████████████████████████████████████████████████████| 552/552 [15:31<00:00,  1.69s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 49: train loss = 1.3545\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 49 [val]: 100%|██████████████████████████████████████████████████████████████████| 69/69 [00:48<00:00,  1.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 49: val loss = 2.0648, CER = 0.4719\n",
            "\n",
            "Sample predictions:\n",
            "GT:    As to the mere Act of Coining considered by itself\n",
            "Pred:  A to the mere act of Cinisin en ar in e tie\n",
            "---\n",
            "GT:    is compelled in the first instance to discover and surrender his\n",
            "Pred:  iscompellad in the fnrist insten tet o o ar e e\n",
            "---\n",
            "GT:    : specting the actual past and present matter of fact . 2 . If\n",
            "Pred:  : rpecteing the aetial pasos ir an on en e e on on oe\n",
            "---\n",
            "GT:    first day of every term by themselves respecttively or their\n",
            "Pred:  firot day of enery term by themsel is fef s toe e er e e\n",
            "---\n",
            "GT:    =ry for the purpose of any other Art  , the use and possession\n",
            "Pred:  : ry for the purpose oaf a an an en on in e e\n",
            "---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 50 [train]: 100%|██████████████████████████████████████████████████████████████| 552/552 [15:24<00:00,  1.67s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 50: train loss = 1.3459\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 50 [val]: 100%|██████████████████████████████████████████████████████████████████| 69/69 [00:47<00:00,  1.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 50: val loss = 2.0738, CER = 0.4664\n",
            "\n",
            "Sample predictions:\n",
            "GT:    As to the mere Act of Coining considered by itself\n",
            "Pred:  As to the mere act of Cnin im hen ar in e a=\n",
            "---\n",
            "GT:    is compelled in the first instance to discover and surrender his\n",
            "Pred:  icompellad in the furst inhe e on e en e ae=\n",
            "---\n",
            "GT:    : specting the actual past and present matter of fact . 2 . If\n",
            "Pred:  : rpecting the actial pas an en on on en on ae\n",
            "---\n",
            "GT:    first day of every term by themselves respecttively or their\n",
            "Pred:  forot day of everny term by thembllrore e o enhen anie\n",
            "---\n",
            "GT:    =ry for the purpose of any other Art  , the use and possession\n",
            "Pred:  :ny for the purpose o a n tan en er en ane e e\n",
            "---\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def train_one_epoch(epoch):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images, labels, label_lengths, widths, batch in tqdm(train_loader, desc=f\"Epoch {epoch} [train]\"):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        label_lengths = label_lengths.to(device)\n",
        "\n",
        "        # After CNN: width is divided by 4 (due to two pools)\n",
        "        W = images.shape[-1]\n",
        "        T = W // 4\n",
        "        input_lengths = torch.full(\n",
        "            size=(images.size(0),),\n",
        "            fill_value=T,\n",
        "            dtype=torch.long,\n",
        "            device=device,\n",
        "        )\n",
        "\n",
        "        logits = model(images)              # (T, B, num_chars)\n",
        "        log_probs = logits.log_softmax(2)\n",
        "\n",
        "        loss = ctc_loss(log_probs, labels, input_lengths, label_lengths)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch}: train loss = {avg_loss:.4f}\")\n",
        "\n",
        "def validate(epoch):\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    all_gt = []\n",
        "    all_pred = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels, label_lengths, widths, batch in tqdm(val_loader, desc=f\"Epoch {epoch} [val]\"):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            label_lengths = label_lengths.to(device)\n",
        "\n",
        "            W = images.shape[-1]\n",
        "            T = W // 4\n",
        "            input_lengths = torch.full(\n",
        "                size=(images.size(0),),\n",
        "                fill_value=T,\n",
        "                dtype=torch.long,\n",
        "                device=device,\n",
        "            )\n",
        "\n",
        "            logits = model(images)\n",
        "            log_probs = logits.log_softmax(2)\n",
        "            loss = ctc_loss(log_probs, labels, input_lengths, label_lengths)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            decoded = greedy_decode(logits.cpu())\n",
        "            for i, d in enumerate(decoded):\n",
        "                all_pred.append(d)\n",
        "                all_gt.append(batch[i][\"text\"])\n",
        "\n",
        "    avg_loss = val_loss / len(val_loader)\n",
        "    val_cer = cer(all_gt, all_pred)\n",
        "    print(f\"Epoch {epoch}: val loss = {avg_loss:.4f}, CER = {val_cer:.4f}\")\n",
        "\n",
        "    print(\"\\nSample predictions:\")\n",
        "    for i in range(5):\n",
        "        print(\"GT:   \", all_gt[i])\n",
        "        print(\"Pred: \", all_pred[i])\n",
        "        print(\"---\")\n",
        "\n",
        "    return avg_loss, val_cer\n",
        "\n",
        "num_epochs = 50 # start with smaller, e.g. 3–5, on CPU\n",
        "best_val = float(\"inf\")\n",
        "\n",
        "history_val_loss = []\n",
        "history_val_cer = []\n",
        "\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    train_one_epoch(epoch)\n",
        "    val_loss, val_cer = validate(epoch)\n",
        "\n",
        "    history_val_loss.append(val_loss)\n",
        "    history_val_cer.append(val_cer)\n",
        "\n",
        "    if val_loss < best_val:\n",
        "        best_val = val_loss\n",
        "        torch.save(model.state_dict(), \"crnn_bentham_best.pt\")\n",
        "        print(\"Saved new best model.\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cebcec5b-7787-4373-85aa-6d9c94076248",
      "metadata": {
        "id": "cebcec5b-7787-4373-85aa-6d9c94076248"
      },
      "source": [
        "### 3.6 Baseline Results: Loss and CER over Epochs\n",
        "\n",
        "After training, we log and visualise:\n",
        "\n",
        "- training and validation loss curves, and\n",
        "- validation CER across epochs.\n",
        "\n",
        "These plots reveal how well (or poorly) the CRNN baseline fits the Bentham data.  \n",
        "In practice, the model struggles to achieve low CER, which motivates the move to transfer learning with a stronger pre-trained model (TrOCR).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8c22539-06c5-4ce6-ba31-e826daa4ce12",
      "metadata": {
        "id": "b8c22539-06c5-4ce6-ba31-e826daa4ce12",
        "outputId": "da5c380b-82ef-4501-ba27-5605c8dbe71e"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epochs = list(range(1, len(history_val_loss) + 1))\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plot validation loss\n",
        "plt.plot(epochs, history_val_loss, label=\"Validation Loss\", linewidth=2)\n",
        "\n",
        "# Plot CER (ideally normalize since it's a percentage-like value)\n",
        "plt.plot(epochs, history_val_cer, label=\"CER\", linewidth=2)\n",
        "\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Value\")\n",
        "plt.title(\"Validation Loss and CER over Training Epochs\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c39fe91a-eb29-45ee-abe7-f460f9addf10",
      "metadata": {
        "id": "c39fe91a-eb29-45ee-abe7-f460f9addf10"
      },
      "source": [
        "### 3.7 Baseline Inference Helper\n",
        "\n",
        "For qualitative inspection, we define an inference helper that:\n",
        "\n",
        "- runs the baseline model on a single line image,\n",
        "- decodes the output using greedy CTC,\n",
        "- prints the ground-truth transcription and the model prediction.\n",
        "\n",
        "These spot checks help us understand typical error patterns, such as confusion between visually similar letters or difficulty with long lines.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec541c6b-d96b-4a39-8673-7535dad3077e",
      "metadata": {
        "id": "ec541c6b-d96b-4a39-8673-7535dad3077e",
        "outputId": "9ff3a091-c53d-424b-ed90-02a998a77cb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GT: gunpowder not properly secured  ; and you , being at a dis :\n",
            "Pred: gumpowuder not properly on e o on o o o.\n"
          ]
        }
      ],
      "source": [
        "def load_model(model_path=\"crnn_bentham_best.pt\"):\n",
        "    m = CRNN(img_height=64, num_chars=len(idx2char))\n",
        "    m.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    m.to(device)\n",
        "    m.eval()\n",
        "    return m\n",
        "\n",
        "def ocr_line(model, img_path, img_height=64, max_width=512):\n",
        "    from PIL import Image\n",
        "    import numpy as np\n",
        "\n",
        "    img = Image.open(img_path).convert(\"L\")\n",
        "    w, h = img.size\n",
        "    new_h = img_height\n",
        "    new_w = int(w * (new_h / h))\n",
        "    img = img.resize((new_w, new_h), Image.BILINEAR)\n",
        "\n",
        "    arr = np.array(img, dtype=np.float32) / 255.0\n",
        "    arr = 1.0 - arr\n",
        "    arr = arr[None, :, :]\n",
        "\n",
        "    if new_w > max_width:\n",
        "        arr = arr[:, :, :max_width]\n",
        "        new_w = max_width\n",
        "    else:\n",
        "        pad_w = max_width - new_w\n",
        "        arr = np.pad(arr, ((0,0), (0,0), (0,pad_w)),\n",
        "                     mode=\"constant\", constant_values=0.0)\n",
        "\n",
        "    tensor = torch.from_numpy(arr).unsqueeze(0).to(device)  # (1, 1, H, W)\n",
        "    with torch.no_grad():\n",
        "        logits = model(tensor)\n",
        "    return greedy_decode(logits.cpu())[0]\n",
        "\n",
        "# quick sanity check on a random sample\n",
        "import random\n",
        "example = random.choice(samples)\n",
        "loaded_model = load_model()  # after training\n",
        "print(\"GT:\", example[\"text\"])\n",
        "print(\"Pred:\", ocr_line(loaded_model, example[\"img_path\"]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d331b994-7a32-4444-ad51-50cc212d23e0",
      "metadata": {
        "id": "d331b994-7a32-4444-ad51-50cc212d23e0"
      },
      "source": [
        "## 4. TrOCR Transfer-Learning on Bentham\n",
        "\n",
        "The second model in our study is **TrOCR**, a transformer-based OCR system released by Microsoft.  \n",
        "Unlike the CRNN baseline, TrOCR is a large **VisionEncoderDecoderModel** pre-trained on massive synthetic OCR data.\n",
        "\n",
        "In this section we:\n",
        "\n",
        "1. fine-tune a pre-trained TrOCR checkpoint on the Bentham line images, and  \n",
        "2. compare its performance to the scratch-built baseline.\n",
        "\n",
        "Because TrOCR already encodes rich visual and language knowledge, we expect it to reach substantially lower CER with fewer epochs of fine-tuning.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8c9fc26-ba90-43ca-871d-2014cb869569",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8c9fc26-ba90-43ca-871d-2014cb869569",
        "outputId": "eb3ef103-f1dd-44d5-b1fc-7533ce02a5c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Torch version:       2.9.0+cu126\n",
            "Transformers version: 4.57.1\n"
          ]
        }
      ],
      "source": [
        "import torch, transformers\n",
        "print(\"Torch version:      \", torch.__version__)\n",
        "print(\"Transformers version:\", transformers.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QfArt24OhI1Z",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QfArt24OhI1Z",
        "outputId": "2eccb921-7b53-49e1-d5da-e78f22765a50"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'NVIDIA L4'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check GPU\n",
        "import torch\n",
        "torch.cuda.get_device_name(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b242582c-7451-4f0a-a4ff-28343ddb3edf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "b242582c-7451-4f0a-a4ff-28343ddb3edf",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "6e5de339-f224-4142-f846-b4f26df321f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.11.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.12/dist-packages (0.4.6)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.9.0+cu126)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.13.3)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "#Packages required\n",
        "!pip install transformers datasets accelerate evaluate pillow sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f33cd6a-3eaa-40ad-b882-4c10e7a4df6f",
      "metadata": {
        "id": "1f33cd6a-3eaa-40ad-b882-4c10e7a4df6f"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "\n",
        "from datasets import Dataset\n",
        "from transformers import (\n",
        "    VisionEncoderDecoderModel,\n",
        "    TrOCRProcessor,\n",
        "    ViTImageProcessor,\n",
        "    XLMRobertaTokenizer,\n",
        "    Seq2SeqTrainer,\n",
        "    Seq2SeqTrainingArguments,\n",
        ")\n",
        "\n",
        "import evaluate\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c61446ae-cc7d-4dbd-8136-7e092c7dae5b",
      "metadata": {
        "id": "c61446ae-cc7d-4dbd-8136-7e092c7dae5b"
      },
      "source": [
        "### 4.1 Wrapping Bentham Samples into a Hugging Face Dataset\n",
        "\n",
        "We reuse the earlier `samples` list and convert it into a **Hugging Face `Dataset`** object containing:\n",
        "\n",
        "- `image_path`: the path to the line image\n",
        "- `text`: the corresponding transcription\n",
        "\n",
        "The dataset is then split into training and validation partitions.  \n",
        "This structure is required by the Hugging Face `Seq2SeqTrainer`, which expects batched input-output pairs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae1db085-5901-45fa-86ac-0cdbdc869384",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae1db085-5901-45fa-86ac-0cdbdc869384",
        "outputId": "b73bcb07-3cae-456f-d488-1423e1862f43"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'img_path': PosixPath('/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/Images/Lines/071_181_001_04_20.png'),\n",
              "  'bbox': None,\n",
              "  'text': 'Now'},\n",
              " {'img_path': PosixPath('/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/Images/Lines/071_112_001_05_02.png'),\n",
              "  'bbox': None,\n",
              "  'text': 'that she liked the counterfeit husband better than the real . This happened in'}]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "samples[:2]\n",
        "# [{'img_path': WindowsPath('...png'), 'bbox': None, 'text': '...'}, ...]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ec44014-4791-4809-bf99-a6c7c34fe365",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ec44014-4791-4809-bf99-a6c7c34fe365",
        "outputId": "c6d32c4a-7bbc-4e19-87f3-cb3bafd6c2d9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(Dataset({\n",
              "     features: ['image_path', 'text'],\n",
              "     num_rows: 2308\n",
              " }),\n",
              " Dataset({\n",
              "     features: ['image_path', 'text'],\n",
              "     num_rows: 578\n",
              " }))"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hf_examples = [\n",
        "    {\n",
        "        \"image_path\": str(s[\"img_path\"]),\n",
        "        \"text\": s[\"text\"],\n",
        "    }\n",
        "    for s in samples\n",
        "]\n",
        "\n",
        "raw_ds = Dataset.from_list(hf_examples)\n",
        "\n",
        "raw_ds = raw_ds.train_test_split(test_size=0.2, seed=42)\n",
        "train_ds = raw_ds[\"train\"]\n",
        "val_ds   = raw_ds[\"test\"]\n",
        "\n",
        "train_ds, val_ds\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a0b7180-0b5a-4125-a3ce-17d23e0b1c1d",
      "metadata": {
        "id": "3a0b7180-0b5a-4125-a3ce-17d23e0b1c1d"
      },
      "source": [
        "### 4.2 Evaluation Metric for TrOCR\n",
        "\n",
        "As with the baseline, we use **Character Error Rate (CER)** as the main evaluation metric.\n",
        "\n",
        "For TrOCR:\n",
        "\n",
        "- logits from the decoder are converted into token predictions,\n",
        "- special tokens and padding indices are removed,\n",
        "- the resulting strings are passed to the `evaluate` library's CER implementation.\n",
        "\n",
        "During training, this CER is computed on the **teacher-forced decoder outputs**, which provides a convenient, though optimistic, view of model performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3a76885-0cec-43af-8bba-1be84a41912b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3a76885-0cec-43af-8bba-1be84a41912b",
        "outputId": "f11ef77d-4ed2-4dde-e342-d83c9d4dc5e6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-small-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_name = \"microsoft/trocr-small-handwritten\"\n",
        "\n",
        "# 1) Image processor and tokenizer\n",
        "image_processor = ViTImageProcessor.from_pretrained(model_name)\n",
        "tokenizer = XLMRobertaTokenizer.from_pretrained(model_name, use_fast=False)\n",
        "\n",
        "# 2) Build the processor manually\n",
        "processor = TrOCRProcessor(\n",
        "    image_processor=image_processor,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "# 3) Load the VisionEncoderDecoder model\n",
        "model = VisionEncoderDecoderModel.from_pretrained(model_name)\n",
        "\n",
        "# Fix special tokens\n",
        "model.config.decoder_start_token_id = tokenizer.cls_token_id\n",
        "model.config.eos_token_id           = tokenizer.sep_token_id\n",
        "model.config.pad_token_id           = tokenizer.pad_token_id\n",
        "model.config.vocab_size             = model.config.decoder.vocab_size\n",
        "\n",
        "max_target_length = 128\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "device\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b47ce9d5-1047-4d26-9927-f5c33beca294",
      "metadata": {
        "id": "b47ce9d5-1047-4d26-9927-f5c33beca294"
      },
      "source": [
        "### 4.3 Custom Trainer to Avoid Out-of-Memory Errors\n",
        "\n",
        "Direct evaluation with `model.generate(...)` inside the training loop is memory-intensive on Colab GPUs.  \n",
        "To keep the process tractable, we define a **custom `Seq2SeqTrainer`** that:\n",
        "\n",
        "- uses the standard forward pass with labels to obtain decoder logits,\n",
        "- returns these logits (instead of generated sequences) to the `compute_metrics` function,\n",
        "- avoids the more expensive autoregressive generation step during evaluation.\n",
        "\n",
        "This design trades some realism in the metric for greatly reduced memory usage, allowing us to fine-tune TrOCR within the available hardware limits.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "333d1ab1-9243-4c4c-8cc3-7617eecb30c9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "d8aa4bf50f204576a494c660ad8239b6",
            "6c0e2e93980c42d49b5a9b06e149290e",
            "dac9243c67db420f97a6e5ae881339bb",
            "1c91f0ade6e7412985e502217be2b7bd",
            "5a4d3785c73c4bdca5a73c5ab26ba5f3",
            "b25f1fdab7134efb8536b22c9d9d0af1",
            "e26470ffd9f346d8b6770ff3cb98a998",
            "66b0f0b3f25c47a7bb5bf655cc85bda0",
            "abcb5a11441b48aebafd6365693f0023",
            "7c25f2aa95d6480f955ef45c184470ec",
            "d5d3b4062c2146fdbaf0645f28ced197",
            "f28d25b4bd044702bba2b44e0bcc961e",
            "98a897aa173d4c3595fae62bbe32fb67",
            "f16ea1d3844540c59ced5e42f8386ce1",
            "e87a388ea9cb46c58098ec0024227cf4",
            "08250e2ff455447eab3efa46f550c849",
            "fc943b2f922e417689407c4b6ece0ced",
            "b775cb54901b443bbed0dea74fd8a6f2",
            "4aa96caa1347443ca2bf9303184a81bc",
            "faeb9b7259c2497c9a77b831be22366e",
            "fc7c6197eb3c47b79edf69bb5c2a026b",
            "90ea4c0eaed243d2958d63e0b769476c"
          ]
        },
        "id": "333d1ab1-9243-4c4c-8cc3-7617eecb30c9",
        "outputId": "a9b7377d-33ff-42d9-abff-8544b871b3b3"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d8aa4bf50f204576a494c660ad8239b6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/2308 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f28d25b4bd044702bba2b44e0bcc961e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/578 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "def load_images(batch):\n",
        "    batch[\"image\"] = [\n",
        "        Image.open(p).convert(\"RGB\") for p in batch[\"image_path\"]\n",
        "    ]\n",
        "    return batch\n",
        "\n",
        "train_ds = train_ds.map(load_images, batched=True)\n",
        "val_ds   = val_ds.map(load_images, batched=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "syqHCeEwbfa6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "syqHCeEwbfa6",
        "outputId": "f3ad0e37-4fba-4482-be79-2a8b565fb1b7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n# Reduce training set to 2000 samples\\ntrain_ds_small = train_ds.select(range(2000))\\n\\n# Reduce validation set to 400 samples\\nval_ds_small = val_ds.select(range(400))\\n\\ntrain_ds = train_ds_small\\nval_ds   = val_ds_small\\n\\nlen(train_ds), len(val_ds)\\n'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "# Reduce training set to 2000 samples\n",
        "train_ds_small = train_ds.select(range(2000))\n",
        "\n",
        "# Reduce validation set to 400 samples\n",
        "val_ds_small = val_ds.select(range(400))\n",
        "\n",
        "train_ds = train_ds_small\n",
        "val_ds   = val_ds_small\n",
        "\n",
        "len(train_ds), len(val_ds)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sMLlLHy66FWw",
      "metadata": {
        "id": "sMLlLHy66FWw"
      },
      "source": [
        "### 4.4 Training Configuration\n",
        "\n",
        "We specify `Seq2SeqTrainingArguments` to control:\n",
        "\n",
        "- batch sizes for training and evaluation,\n",
        "- learning rate and number of epochs,\n",
        "- logging and checkpointing frequency,\n",
        "- the use of mixed-precision (`fp16`) when a GPU is available,\n",
        "- the choice of **CER** as the metric used to select the best checkpoint.\n",
        "\n",
        "These hyperparameters are chosen to balance performance and stability given the size of the Bentham subset and the constraints of the Colab environment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80NGVtON6IwT",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706,
          "referenced_widgets": [
            "7e82844cfe9d4b368475c5d5556df0c1",
            "5debda65471047bda8888d388d770256",
            "59013032548d4939ad8cc3e83e0e1e30",
            "cc885ebe475f4ba3980301286579ae05",
            "16570c56719f4bd6b6b926cc13a478d4",
            "addaaf3d0479444e972173bc96dc4ea4",
            "dc0a50a72e494423bc0d23dd46c7f962",
            "aa99ab89fcf14ad28c584c1828e172b0",
            "0de671b623ff4fe5ba03644903a44822",
            "9075f9d3b1264d1692e1d9e4fa3c196a",
            "7f9e59a0e28d495e8293900010f1a0db",
            "ad95b7c4c3f24a0490ea820241ccdb67",
            "47c9914b007542ddaa3b8642dc8234e1",
            "338816836a1640d6b3ed3e60e7cbcab2",
            "a6cd67abf3194f81b65688262b5ae184",
            "198f28c676f14bb19940ee061a948181",
            "9442884e0ea544b48ffc76c501cd5044",
            "754471aba0d9455bb7797886054b96fb",
            "890d9563a78a4c57875523c216fc05bd",
            "27981b05d08b434980fa4ec52f818f3b",
            "24be26d6cba94780ac1fcef698281a86",
            "488f8794555647debc027985ba101905"
          ]
        },
        "id": "80NGVtON6IwT",
        "outputId": "3f243514-c172-4ece-deef-dca0f1bd27e7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7e82844cfe9d4b368475c5d5556df0c1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/2308 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ad95b7c4c3f24a0490ea820241ccdb67",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/578 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'pixel_values': tensor([[[0.7804, 0.7882, 0.7725,  ..., 0.7255, 0.6863, 0.6157],\n",
              "          [0.7804, 0.7882, 0.7725,  ..., 0.7255, 0.6863, 0.6157],\n",
              "          [0.7804, 0.7882, 0.7725,  ..., 0.7255, 0.6863, 0.6078],\n",
              "          ...,\n",
              "          [0.7804, 0.7882, 0.7882,  ..., 0.7255, 0.7020, 0.6157],\n",
              "          [0.7804, 0.7882, 0.7882,  ..., 0.7255, 0.7020, 0.6157],\n",
              "          [0.7804, 0.7882, 0.7882,  ..., 0.7255, 0.7020, 0.6157]],\n",
              " \n",
              "         [[0.7804, 0.7882, 0.7725,  ..., 0.7255, 0.6863, 0.6157],\n",
              "          [0.7804, 0.7882, 0.7725,  ..., 0.7255, 0.6863, 0.6157],\n",
              "          [0.7804, 0.7882, 0.7725,  ..., 0.7255, 0.6863, 0.6078],\n",
              "          ...,\n",
              "          [0.7804, 0.7882, 0.7882,  ..., 0.7255, 0.7020, 0.6157],\n",
              "          [0.7804, 0.7882, 0.7882,  ..., 0.7255, 0.7020, 0.6157],\n",
              "          [0.7804, 0.7882, 0.7882,  ..., 0.7255, 0.7020, 0.6157]],\n",
              " \n",
              "         [[0.7804, 0.7882, 0.7725,  ..., 0.7255, 0.6863, 0.6157],\n",
              "          [0.7804, 0.7882, 0.7725,  ..., 0.7255, 0.6863, 0.6157],\n",
              "          [0.7804, 0.7882, 0.7725,  ..., 0.7255, 0.6863, 0.6078],\n",
              "          ...,\n",
              "          [0.7804, 0.7882, 0.7882,  ..., 0.7255, 0.7020, 0.6157],\n",
              "          [0.7804, 0.7882, 0.7882,  ..., 0.7255, 0.7020, 0.6157],\n",
              "          [0.7804, 0.7882, 0.7882,  ..., 0.7255, 0.7020, 0.6157]]]),\n",
              " 'labels': tensor([    0,   219,    37,   165,    60,  1060,   391, 13071,    43,     7,\n",
              "          3433,     9,     2,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1])}"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def preprocess_batch(batch):\n",
        "    images = batch[\"image\"]\n",
        "    texts  = batch[\"text\"]\n",
        "\n",
        "    enc = processor(\n",
        "        images=images,\n",
        "        text=texts,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=max_target_length,\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        \"pixel_values\": enc[\"pixel_values\"],\n",
        "        \"labels\": enc[\"labels\"],\n",
        "    }\n",
        "\n",
        "train_ds_proc = train_ds.map(\n",
        "    preprocess_batch,\n",
        "    batched=True,\n",
        "    remove_columns=[\"image_path\", \"image\", \"text\"],\n",
        ")\n",
        "\n",
        "val_ds_proc = val_ds.map(\n",
        "    preprocess_batch,\n",
        "    batched=True,\n",
        "    remove_columns=[\"image_path\", \"image\", \"text\"],\n",
        ")\n",
        "\n",
        "train_ds_proc.set_format(type=\"torch\")\n",
        "val_ds_proc.set_format(type=\"torch\")\n",
        "\n",
        "train_ds_proc[0]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "T__DmknO9az8",
      "metadata": {
        "id": "T__DmknO9az8"
      },
      "source": [
        "### 4.5 TrOCR Training Dynamics\n",
        "\n",
        "With the configuration above, TrOCR is fine-tuned for several epochs on the Bentham training set.  \n",
        "The trainer logs both:\n",
        "\n",
        "- training and validation loss, and\n",
        "- the evaluation CER computed from teacher-forced logits.\n",
        "\n",
        "Compared to the CRNN baseline, TrOCR converges more quickly and achieves markedly lower evaluation CER, confirming the benefits of starting from a strong pre-trained OCR model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Kgv4p-X19rX6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kgv4p-X19rX6",
        "outputId": "d3992a89-3167-4765-cd0a-2da3b7f2a3a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: jiwer in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.12/dist-packages (from jiwer) (8.3.1)\n",
            "Requirement already satisfied: rapidfuzz>=3.9.7 in /usr/local/lib/python3.12/dist-packages (from jiwer) (3.14.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install jiwer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZzPYwDr99bwT",
      "metadata": {
        "id": "ZzPYwDr99bwT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import evaluate\n",
        "\n",
        "cer_metric = evaluate.load(\"cer\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"\n",
        "    eval_pred.predictions: (batch, seq_len, vocab_size)\n",
        "    eval_pred.label_ids:   (batch, seq_len) with -100 for ignored positions\n",
        "    \"\"\"\n",
        "    logits, labels = eval_pred\n",
        "\n",
        "    # logits might be a numpy array\n",
        "    if isinstance(logits, np.ndarray):\n",
        "        pred_ids = logits.argmax(-1)\n",
        "    else:\n",
        "        pred_ids = np.array(logits).argmax(-1)\n",
        "\n",
        "    # Replace -100 with pad_token_id so we can decode\n",
        "    labels = np.where(labels == -100, tokenizer.pad_token_id, labels)\n",
        "\n",
        "    pred_texts  = tokenizer.batch_decode(pred_ids,  skip_special_tokens=True)\n",
        "    label_texts = tokenizer.batch_decode(labels,    skip_special_tokens=True)\n",
        "\n",
        "    cer = cer_metric.compute(predictions=pred_texts, references=label_texts)\n",
        "    return {\"cer\": cer}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-ssMCnjJ93dR",
      "metadata": {
        "id": "-ssMCnjJ93dR"
      },
      "source": [
        "### 4.6 Inference Helper and Qualitative Checking\n",
        "\n",
        "After training, we define an inference helper `trocr_ocr_line` that:\n",
        "\n",
        "- loads a single Bentham line image,\n",
        "- applies the TrOCR processor to obtain pixel values,\n",
        "- calls `model.generate(...)` to produce an output sequence,\n",
        "- decodes the sequence into readable text.\n",
        "\n",
        "By sampling random lines from `samples`, we can visually inspect TrOCR's predictions and compare them directly to ground truth.  \n",
        "These inspections reveal that TrOCR captures the general structure of the text much better than the baseline, but still makes non-trivial errors on challenging handwriting.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bWJICLcK94YE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWJICLcK94YE",
        "outputId": "522a3ac3-eb02-4a0b-9ebd-2d68c6a4ddd1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2836671820.py:56: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSeq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = CustomSeq2SeqTrainer(\n"
          ]
        }
      ],
      "source": [
        "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "\n",
        "# Extremely important for memory reduction:\n",
        "# - smaller batch sizes\n",
        "# - gradient accumulation\n",
        "# - fp16 mixed precision\n",
        "# - disable predict_with_generate\n",
        "# - force eval to micro-batches\n",
        "train_bs = 2        # was 8 → too large\n",
        "eval_bs  = 1        # force micro-batch eval\n",
        "\n",
        "class CustomSeq2SeqTrainer(Seq2SeqTrainer):\n",
        "    def prediction_step(self, model, inputs, prediction_loss_only, ignore_keys=None):\n",
        "        inputs = self._prepare_inputs(inputs)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "            if prediction_loss_only:\n",
        "                return (outputs.loss.detach(), None, None)\n",
        "            logits = outputs.logits\n",
        "            if isinstance(logits, tuple):\n",
        "                logits = logits[0]\n",
        "            # Move logits to CPU immediately after computation\n",
        "            logits = logits.cpu()\n",
        "            # Also ensure labels are on CPU for consistent numpy conversion in compute_metrics\n",
        "            labels = inputs[\"labels\"].cpu()\n",
        "            return (outputs.loss.detach(), logits, labels)\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./trocr_bentham_small\",\n",
        "    per_device_train_batch_size=train_bs,\n",
        "    per_device_eval_batch_size=eval_bs,\n",
        "\n",
        "    gradient_accumulation_steps=8,   # makes effective batch = 16\n",
        "    learning_rate = 3e-5,\n",
        "    num_train_epochs = 15,\n",
        "\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "\n",
        "    # ABSOLUTELY MUST BE FALSE or OOM will happen\n",
        "    predict_with_generate=False,\n",
        "\n",
        "    # Mixed precision → saves 50% mem and speeds up training\n",
        "    fp16=True,\n",
        "\n",
        "    # Important for ViT memory footprint\n",
        "    remove_unused_columns=False,\n",
        "\n",
        "    # Make Trainer use less memory\n",
        "    dataloader_num_workers=2,\n",
        "\n",
        "    # No reports to wandb\n",
        "    report_to=[],\n",
        ")\n",
        "\n",
        "trainer = CustomSeq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_ds_proc,\n",
        "    eval_dataset=val_ds_proc,\n",
        "    tokenizer=processor,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lcRjNMNM-Ckb",
      "metadata": {
        "id": "lcRjNMNM-Ckb"
      },
      "source": [
        "### 4.7 Validation-Based CER with Autoregressive Generation\n",
        "\n",
        "To obtain a **realistic estimate** of TrOCR's performance, we evaluate it on a subset of the validation data using `model.generate(...)`:\n",
        "\n",
        "- each validation image is passed through the encoder–decoder stack,\n",
        "- the decoder runs autoregressively, conditioning each new token on previous predictions,\n",
        "- predictions are compared to the ground-truth transcriptions to compute CER.\n",
        "\n",
        "This evaluation is closer to actual inference-time behaviour than the teacher-forced CER used inside the training loop.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gcJqOp8q-Fpk",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gcJqOp8q-Fpk",
        "outputId": "62b0c440-7c95-40d9-b45c-d06f78eaf68e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 0}.\n",
            "`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2175' max='2175' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2175/2175 3:48:13, Epoch 15/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Cer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.606199</td>\n",
              "      <td>0.713528</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.395913</td>\n",
              "      <td>0.498424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.227169</td>\n",
              "      <td>0.338851</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.767000</td>\n",
              "      <td>0.183926</td>\n",
              "      <td>0.275079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.767000</td>\n",
              "      <td>0.159805</td>\n",
              "      <td>0.213564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.767000</td>\n",
              "      <td>0.143056</td>\n",
              "      <td>0.195615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.146400</td>\n",
              "      <td>0.146043</td>\n",
              "      <td>0.192175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.146400</td>\n",
              "      <td>0.138382</td>\n",
              "      <td>0.175122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.146400</td>\n",
              "      <td>0.128677</td>\n",
              "      <td>0.168315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.146400</td>\n",
              "      <td>0.128996</td>\n",
              "      <td>0.166488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.081900</td>\n",
              "      <td>0.130504</td>\n",
              "      <td>0.161185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.081900</td>\n",
              "      <td>0.130268</td>\n",
              "      <td>0.162152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.081900</td>\n",
              "      <td>0.130890</td>\n",
              "      <td>0.157531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.050100</td>\n",
              "      <td>0.131162</td>\n",
              "      <td>0.157817</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.050100</td>\n",
              "      <td>0.132457</td>\n",
              "      <td>0.154235</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='578' max='578' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [578/578 13:48]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final evaluation: {'eval_loss': 0.13245715200901031, 'eval_cer': 0.1542347377472055, 'eval_runtime': 832.0567, 'eval_samples_per_second': 0.695, 'eval_steps_per_second': 0.695, 'epoch': 15.0}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "([0.6061986088752747,\n",
              "  0.39591339230537415,\n",
              "  0.22716888785362244,\n",
              "  0.1839258074760437,\n",
              "  0.15980450809001923,\n",
              "  0.14305613934993744,\n",
              "  0.14604267477989197,\n",
              "  0.1383821666240692,\n",
              "  0.12867674231529236,\n",
              "  0.1289963275194168,\n",
              "  0.1305035650730133,\n",
              "  0.130268394947052,\n",
              "  0.13089029490947723,\n",
              "  0.1311618536710739,\n",
              "  0.13245715200901031,\n",
              "  0.13245715200901031],\n",
              " [0.7135282315849814,\n",
              "  0.4984236170822585,\n",
              "  0.33885067354542847,\n",
              "  0.27507881914588705,\n",
              "  0.2135640584694755,\n",
              "  0.19561478933791918,\n",
              "  0.19217540842648323,\n",
              "  0.17512181140728003,\n",
              "  0.16831470335339638,\n",
              "  0.16648753224419605,\n",
              "  0.16118515333906563,\n",
              "  0.162152479220407,\n",
              "  0.15753081112066494,\n",
              "  0.15781742619661795,\n",
              "  0.1542347377472055,\n",
              "  0.1542347377472055])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "history_trocr_val_loss = []\n",
        "history_trocr_val_cer  = []\n",
        "\n",
        "train_result = trainer.train()\n",
        "\n",
        "# Evaluation (safe)\n",
        "eval_result = trainer.evaluate(max_length=max_target_length)\n",
        "print(\"Final evaluation:\", eval_result)\n",
        "\n",
        "# Collect metrics\n",
        "for log in trainer.state.log_history:\n",
        "    if \"eval_loss\" in log:\n",
        "        history_trocr_val_loss.append(log[\"eval_loss\"])\n",
        "    if \"eval_cer\" in log:\n",
        "        history_trocr_val_cer.append(log[\"eval_cer\"])\n",
        "\n",
        "history_trocr_val_loss, history_trocr_val_cer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "VQbwFZ98nIuV",
      "metadata": {
        "id": "VQbwFZ98nIuV"
      },
      "source": [
        "### 4.8 TrOCR Training Curves\n",
        "\n",
        "We also plot:\n",
        "\n",
        "- TrOCR training and validation loss over epochs, and\n",
        "- validation CER (as computed during training).\n",
        "\n",
        "These curves show that TrOCR reaches much lower loss values than the CRNN baseline and that the teacher-forced CER appears relatively small.  \n",
        "However, as discussed next, this optimistic CER does not fully reflect the model's true performance when used with autoregressive generation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "S_V5_v8xnJuQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "id": "S_V5_v8xnJuQ",
        "outputId": "5da5a6a0-b81a-4468-ccb6-64e1e9b9ac64"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epochs = list(range(1, len(history_trocr_val_loss) + 1))\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(epochs, history_trocr_val_loss, label=\"Validation Loss\")\n",
        "plt.plot(epochs, history_trocr_val_cer,  label=\"CER\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Value\")\n",
        "plt.title(\"TrOCR Validation Loss and CER over Training Epochs\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sd7kZOHCnYeU",
      "metadata": {
        "id": "sd7kZOHCnYeU"
      },
      "source": [
        "### 4.9 Saving the Fine-Tuned TrOCR Model\n",
        "\n",
        "For reproducibility and later reuse, the best-performing TrOCR checkpoint and its associated processor are saved to disk.\n",
        "\n",
        "The notebook then reloads the model from this directory and verifies that inference still works as expected.  \n",
        "This step ensures that the fine-tuned weights and configuration are self-contained and can be applied outside the training environment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FUQFq9cFncRn",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUQFq9cFncRn",
        "outputId": "60b3743e-9f88-4be3-e34b-e2ea20f5e343"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GT:    \" Agent rational or irrational \"  might be put\n",
            "Pred:  Agent or might put\n"
          ]
        }
      ],
      "source": [
        "from PIL import Image\n",
        "\n",
        "save_dir = \"./trocr_bentham_small_finetuned\"\n",
        "trainer.save_model(save_dir)\n",
        "processor.save_pretrained(save_dir)\n",
        "\n",
        "# Reload model + processor (optional, but shows how to use later)\n",
        "trocr_model = VisionEncoderDecoderModel.from_pretrained(save_dir).to(device)\n",
        "trocr_processor = TrOCRProcessor.from_pretrained(save_dir)\n",
        "trocr_model.eval()\n",
        "\n",
        "def trocr_ocr_line(image_path: str) -> str:\n",
        "    img = Image.open(image_path).convert(\"RGB\")\n",
        "    pixel_values = trocr_processor(images=img, return_tensors=\"pt\").pixel_values.to(device)\n",
        "    with torch.no_grad():\n",
        "        generated_ids = trocr_model.generate(pixel_values, max_length=max_target_length)\n",
        "    text = trocr_processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "    return text\n",
        "\n",
        "# Quick sanity check on a random example (using your 'samples' list with corrected paths)\n",
        "import random\n",
        "\n",
        "example = random.choice(samples)\n",
        "print(\"GT:   \", example[\"text\"])\n",
        "print(\"Pred: \", trocr_ocr_line(example[\"img_path\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "p6ouDuBVn-cb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6ouDuBVn-cb",
        "outputId": "746d7234-0ca6-4647-90ae-53b7639eb28a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GT:    be sufficient to produce uneasiness in a man if it be against his\n",
            "Pred:  be to uneasiness a if be his\n"
          ]
        }
      ],
      "source": [
        "example = random.choice(samples)\n",
        "print(\"GT:   \", example[\"text\"])\n",
        "print(\"Pred: \", trocr_ocr_line(example[\"img_path\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Xk0yeAkSqKus",
      "metadata": {
        "id": "Xk0yeAkSqKus"
      },
      "source": [
        "### 4.10 TrOCR Evaluation on Random Samples\n",
        "\n",
        "Finally, we draw a small random subset of Bentham lines and:\n",
        "\n",
        "- generate predictions with the fine-tuned TrOCR model, and\n",
        "- compute per-line CER using the same `evaluate`-based metric.\n",
        "\n",
        "We tabulate the ground truth, predictions, and CER values to provide a qualitative and quantitative picture of performance on held-out data.  \n",
        "These examples are also useful for identifying systematic error patterns that might be addressed by future post-correction or language-modelling steps.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hBGo9XS9qQ8W",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBGo9XS9qQ8W",
        "outputId": "739a300b-0bf8-46b6-f434-f78ff265e80c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "╒═════════════════════════════════════════════════════════════════════════╤══════════════════════════════════════╤═══════╕\n",
            "│ GT                                                                      │ Pred                                 │   CER │\n",
            "╞═════════════════════════════════════════════════════════════════════════╪══════════════════════════════════════╪═══════╡\n",
            "│ of action , as soon as it appears to express any thing , appears to     │ of , soon it to to any , appears     │ 0.552 │\n",
            "├─────────────────────────────────────────────────────────────────────────┼──────────────────────────────────────┼───────┤\n",
            "│ acts as he could not discover to be productive of any particular        │ acts he not to productive any        │ 0.547 │\n",
            "├─────────────────────────────────────────────────────────────────────────┼──────────────────────────────────────┼───────┤\n",
            "│ Room .                                                                  │ Room                                 │ 0.333 │\n",
            "├─────────────────────────────────────────────────────────────────────────┼──────────────────────────────────────┼───────┤\n",
            "│ Yourself :  and such an injury if offered with impunity ,               │ Yourself and an if with , ,          │ 0.544 │\n",
            "├─────────────────────────────────────────────────────────────────────────┼──────────────────────────────────────┼───────┤\n",
            "│ the prisoners consent not greater than the half                         │ the consent greater the              │ 0.511 │\n",
            "├─────────────────────────────────────────────────────────────────────────┼──────────────────────────────────────┼───────┤\n",
            "│ -taining and employing one thousand Male Convicts at                    │ training employing thousand Cons at  │ 0.365 │\n",
            "├─────────────────────────────────────────────────────────────────────────┼──────────────────────────────────────┼───────┤\n",
            "│ the Maximum of Perfection .                                             │ the of . . .                         │ 0.667 │\n",
            "├─────────────────────────────────────────────────────────────────────────┼──────────────────────────────────────┼───────┤\n",
            "│ other purposes therein mentioned , or under such other direct-          │ others there mentioned order other-  │ 0.435 │\n",
            "├─────────────────────────────────────────────────────────────────────────┼──────────────────────────────────────┼───────┤\n",
            "│ and for such considerations , terms , conditions , powers , li-         │ and such , , , , , , , powers li     │ 0.571 │\n",
            "├─────────────────────────────────────────────────────────────────────────┼──────────────────────────────────────┼───────┤\n",
            "│ it is a species of Family Imposture .                                   │ it a of Impoture                     │ 0.568 │\n",
            "├─────────────────────────────────────────────────────────────────────────┼──────────────────────────────────────┼───────┤\n",
            "│ agreed that on the discharge of every such Pris-                        │ agreed on discharge every Pri-       │ 0.375 │\n",
            "├─────────────────────────────────────────────────────────────────────────┼──────────────────────────────────────┼───────┤\n",
            "│ of giving his assistance ; for instance , from malice , wantonness ,    │ of his ; ; ; ; , instance from ,     │ 0.618 │\n",
            "├─────────────────────────────────────────────────────────────────────────┼──────────────────────────────────────┼───────┤\n",
            "│ -ding or Buildings adjoining , a Chapel fit for the use of              │ - ors adjoining a fit the of         │ 0.517 │\n",
            "├─────────────────────────────────────────────────────────────────────────┼──────────────────────────────────────┼───────┤\n",
            "│ but a blow from a servant to a gentleman dishonours the                 │ but blow servant a dishonor the      │ 0.436 │\n",
            "├─────────────────────────────────────────────────────────────────────────┼──────────────────────────────────────┼───────┤\n",
            "│ Instructions to the Judge .                                             │ Instructions Judge                   │ 0.333 │\n",
            "├─────────────────────────────────────────────────────────────────────────┼──────────────────────────────────────┼───────┤\n",
            "│ .  .  . Let us determine what reliance we can place on his engagements  │ . . us what we can on his            │ 0.643 │\n",
            "├─────────────────────────────────────────────────────────────────────────┼──────────────────────────────────────┼───────┤\n",
            "│ -ber of the four last years of Peace :   [ though it may increase , yet │ ber the last of Peace [ though may , │ 0.493 │\n",
            "├─────────────────────────────────────────────────────────────────────────┼──────────────────────────────────────┼───────┤\n",
            "│ is it not pursued still without deviation , pursued                     │ is not still deviation pursued       │ 0.412 │\n",
            "├─────────────────────────────────────────────────────────────────────────┼──────────────────────────────────────┼───────┤\n",
            "│ or Assignees jointly or successively of the said Jeremy Ben-            │ or jointly successive of said Ben    │ 0.45  │\n",
            "├─────────────────────────────────────────────────────────────────────────┼──────────────────────────────────────┼───────┤\n",
            "│ payable on account thereof shall not in the whole exceed the se-        │ payable account shall in whole the-  │ 0.453 │\n",
            "╘═════════════════════════════════════════════════════════════════════════╧══════════════════════════════════════╧═══════╛\n",
            "\n",
            "Average CER over sample: 0.4911883190681503\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from tabulate import tabulate\n",
        "from PIL import Image\n",
        "\n",
        "# CER metric\n",
        "cer_metric = evaluate.load(\"cer\")\n",
        "\n",
        "def trocr_predict(image_path):\n",
        "    img = Image.open(image_path).convert(\"RGB\")\n",
        "    pixel_values = trocr_processor(images=img, return_tensors=\"pt\").pixel_values.to(device)\n",
        "    with torch.no_grad():\n",
        "        generated_ids = trocr_model.generate(pixel_values, max_length=max_target_length)\n",
        "    return trocr_processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "\n",
        "def cer(gt, pred):\n",
        "    return cer_metric.compute(predictions=[pred], references=[gt])\n",
        "\n",
        "# Number of examples to evaluate\n",
        "N = 20\n",
        "subset = random.sample(samples, N)\n",
        "\n",
        "table = []\n",
        "cers = []\n",
        "\n",
        "for s in subset:\n",
        "    gt = s[\"text\"]\n",
        "    pred = trocr_predict(s[\"img_path\"])\n",
        "    c = cer(gt, pred)\n",
        "    cers.append(c)\n",
        "    table.append([gt, pred, f\"{c:.3f}\"])\n",
        "\n",
        "print(tabulate(table, headers=[\"GT\", \"Pred\", \"CER\"], tablefmt=\"fancy_grid\"))\n",
        "print(\"\\nAverage CER over sample:\", np.mean(cers))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "077d40e0-c486-4d73-a4d9-ad394fe196e4",
      "metadata": {
        "id": "077d40e0-c486-4d73-a4d9-ad394fe196e4"
      },
      "source": [
        "### 4.11 Understanding the CER Discrepancy for TrOCR\n",
        "\n",
        "A key observation in this assignment is that TrOCR exhibits a notable discrepancy between:\n",
        "\n",
        "- the **CER reported during training**, computed from teacher-forced decoder outputs given the ground-truth labels, and\n",
        "- the **CER observed during manual evaluation**, computed from fully autoregressive `model.generate(...)` predictions.\n",
        "\n",
        "Teacher forcing makes the decoding problem easier because each prediction is conditioned on the *true* previous token.  \n",
        "As a result, the training-time CER (for example, around 0.15) significantly underestimates the error rate observed when the model must rely on its **own previous predictions**, where errors compound (with CER closer to 0.5 on sample subsets).\n",
        "\n",
        "This phenomenon highlights an important methodological lesson:  \n",
        "metrics based on teacher-forced outputs can be overly optimistic for sequence-to-sequence models, and realistic evaluation should involve the same decoding strategy that will be used at inference time.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "W3zfIZ3jDBlG",
      "metadata": {
        "id": "W3zfIZ3jDBlG"
      },
      "source": [
        "## 5. Kraken OCR Training Pipeline\n",
        "\n",
        "The third model evaluated in this notebook is **Kraken**, a well-established OCR/HTR engine built around convolutional and recurrent layers trained with CTC loss.\n",
        "\n",
        "Unlike the PyTorch baseline and TrOCR, which are implemented directly in Python using PyTorch and Hugging Face, Kraken is used via its command-line interface (`ketos`) and high-level Python APIs.  \n",
        "This section documents how the Bentham data is adapted to Kraken's expected format, how the model is trained, and how its performance is evaluated.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SiIREHC2DLeA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SiIREHC2DLeA",
        "outputId": "b7dd84a3-6de2-4a81-91b8-e57ae6156ec4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m85.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.6/300.6 kB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.2/102.2 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m97.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.2/115.2 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m811.0/811.0 kB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.0/15.0 MB\u001b[0m \u001b[31m145.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m131.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.2/38.2 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m114.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.0/821.0 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.7/155.7 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m120.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.0/325.0 kB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.7/70.7 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.5/849.5 kB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tsfresh 0.21.1 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\n",
            "torchaudio 2.9.0+cu126 requires torch==2.9.0, but you have torch 2.7.1 which is incompatible.\n",
            "spopt 0.7.0 requires shapely>=2.1.0, but you have shapely 2.0.7 which is incompatible.\n",
            "esda 2.8.0 requires shapely>=2.1, but you have shapely 2.0.7 which is incompatible.\n",
            "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.5.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Just install kraken and python-bidi; let Colab keep its default pillow\n",
        "!pip install -q kraken python-bidi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jXWebCLa3ZK0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXWebCLa3ZK0",
        "outputId": "3229ffdc-1058-482f-91e5-b03878133918"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Torch: 2.7.1+cu126\n",
            "CUDA available: True\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(\"Torch:\", torch.__version__)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xvuzrFua2TSV",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvuzrFua2TSV",
        "outputId": "18e0ba2f-86cd-412d-86a2-e211431ca846"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ketos, version 6.0.2\n"
          ]
        }
      ],
      "source": [
        "!ketos --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccsu7Ner2Tdx",
      "metadata": {
        "id": "ccsu7Ner2Tdx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "l7ORTRnRECQW",
      "metadata": {
        "id": "l7ORTRnRECQW"
      },
      "source": [
        "### 5.1 Preparing Bentham Data for Kraken\n",
        "\n",
        "Kraken expects separate directories for:\n",
        "\n",
        "- line images, and\n",
        "- corresponding ground-truth text files with matching base names.\n",
        "\n",
        "Using the unified `samples` list, we:\n",
        "\n",
        "1. copy all Bentham line images into a dedicated `lines/` directory under `/content/kraken_bentham`, and  \n",
        "2. create matching `.gt.txt` files in a `gt/` directory containing the manual transcriptions.\n",
        "\n",
        "This yields a clean, self-contained dataset that can be consumed directly by `ketos train`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ncpnGEXoOVco",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncpnGEXoOVco",
        "outputId": "198862e0-1be4-49fc-ad74-588c1c5b3899"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created: /content/kraken_bentham\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import os\n",
        "from shutil import copyfile\n",
        "\n",
        "root = Path(\"/content/kraken_bentham\")\n",
        "(root / \"lines\").mkdir(parents=True, exist_ok=True)\n",
        "(root / \"gt\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"Created:\", root)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GfR0Baa0T2p8",
      "metadata": {
        "id": "GfR0Baa0T2p8"
      },
      "outputs": [],
      "source": [
        "!rm -rf /content/kraken_bentham/lines\n",
        "\n",
        "# Make sure target folder exists\n",
        "!mkdir -p /content/kraken_bentham/lines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "itxJlGUbWBsX",
      "metadata": {
        "id": "itxJlGUbWBsX"
      },
      "outputs": [],
      "source": [
        "# Copy the *contents* of Lines/ into /content/kraken_bentham/lines\n",
        "!cp -r \"/content/drive/MyDrive/Bentham/BenthamDatasetR0-GT/Images/Lines/.\" \\\n",
        "      \"/content/kraken_bentham/lines/\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ipbgeID6OnLi",
      "metadata": {
        "id": "ipbgeID6OnLi"
      },
      "source": [
        "### 5.2 Exporting Lines and Transcriptions\n",
        "\n",
        "To make the Bentham subset explicit for Kraken, we iterate over `samples` and write:\n",
        "\n",
        "- one text file per line, named after the line image stem and\n",
        "- containing exactly the ground-truth transcription for that line.\n",
        "\n",
        "These exported files provide the alignment between images and text that Kraken uses to train its CNN–RNN–CTC recogniser.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TVYPqlX3OoOt",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVYPqlX3OoOt",
        "outputId": "906c5948-2ed8-4a30-ca76-d496ba372de7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exported line count: 11473\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "root = Path(\"/content/kraken_bentham\")\n",
        "(root / \"gt\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "exported = 0\n",
        "\n",
        "for s in samples:\n",
        "    text = s[\"text\"]\n",
        "    stem = s[\"img_path\"].stem\n",
        "\n",
        "    # Image is already in /content/kraken_bentham/lines/<stem>.png\n",
        "    # We just create the corresponding .gt.txt file\n",
        "    txt_out = root / \"gt\" / f\"{stem}.gt.txt\"\n",
        "\n",
        "    with open(txt_out, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(text)\n",
        "\n",
        "    exported += 1\n",
        "\n",
        "print(\"Exported line count:\", exported)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Z7SMdzxS8Zk4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7SMdzxS8Zk4",
        "outputId": "6301c0ef-6373-47d5-e2c9-d16447a78874"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GT sidecar files written: 11473\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "lines_dir = Path(\"/content/kraken_bentham/lines\")\n",
        "lines_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "exported = 0\n",
        "\n",
        "for s in samples:\n",
        "    stem = s[\"img_path\"].stem          # e.g. 115_085_004_02_23\n",
        "    text = s[\"text\"]\n",
        "\n",
        "    gt_path = lines_dir / f\"{stem}.gt.txt\"\n",
        "    with open(gt_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(text)\n",
        "\n",
        "    exported += 1\n",
        "\n",
        "print(\"GT sidecar files written:\", exported)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "CgEU-WyuXKrd",
      "metadata": {
        "id": "CgEU-WyuXKrd"
      },
      "source": [
        "### 5.3 Training and Evaluating the Kraken Model\n",
        "\n",
        "We invoke Kraken's `ketos train` command with appropriate options for:\n",
        "\n",
        "- GPU selection,\n",
        "- batch size, and\n",
        "- number of epochs.\n",
        "\n",
        "After training, we run `ketos test` on the selected test lines.  \n",
        "Kraken reports aggregated recognition metrics, including **character accuracy** and **word accuracy**, computed from the decoded output of its CNN–RNN–CTC recogniser.\n",
        "\n",
        "Although the exact numerical values depend on the chosen subset and hyperparameters, this experiment shows how Kraken can be integrated into the same Bentham-based pipeline used for the PyTorch baseline and TrOCR models.\n",
        "\n",
        "---\n",
        "\n",
        "## 6. Comparative Discussion of the Three Models\n",
        "\n",
        "Across the three approaches implemented in this notebook, we can summarise the main observations as follows:\n",
        "\n",
        "- The **PyTorch CRNN baseline** provides a transparent, educational model but struggles to achieve low CER on Bentham handwriting, reflecting both its limited capacity and the difficulty of training from scratch on a relatively small dataset.\n",
        "- **TrOCR**, thanks to large-scale pre-training, reaches substantially better loss and teacher-forced CER values and produces qualitatively stronger transcriptions. However, the gap between teacher-forced and autoregressive CER underlines the importance of evaluating transformer-based OCR models with the same decoding strategy used at inference time.\n",
        "- **Kraken** offers a mature, task-focused implementation of CNN–RNN–CTC models with convenient training and testing tools. Its performance on Bentham is competitive, and it benefits from design choices and defaults tailored to historical OCR/HTR.\n",
        "\n",
        "From a practical perspective, these experiments suggest that:\n",
        "\n",
        "- for maximum control and pedagogical value, a hand-built PyTorch baseline is useful;\n",
        "- for high accuracy with moderate engineering effort, fine-tuning TrOCR or another pre-trained transformer is attractive, provided that evaluation is done carefully; and\n",
        "- for robust, production-oriented workflows on historical material, Kraken remains a strong choice, especially when combined with downstream text-normalisation or language-modelling steps.\n",
        "\n",
        "The notebook thus serves both as a comparative study of OCR architectures and as a template for future work on historical English text transcription.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nU956aQ99vUu",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "nU956aQ99vUu",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "2b5348b6-002f-4d91-ffe6-c9c714919ff3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: kraken 6.0.2\n",
            "Uninstalling kraken-6.0.2:\n",
            "  Successfully uninstalled kraken-6.0.2\n",
            "Collecting kraken>=0.11.0\n",
            "  Using cached kraken-6.0.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.12/dist-packages (from kraken>=0.11.0) (4.25.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from kraken>=0.11.0) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kraken>=0.11.0) (2.32.4)\n",
            "Requirement already satisfied: click<8.3,>=8.1 in /usr/local/lib/python3.12/dist-packages (from kraken>=0.11.0) (8.2.1)\n",
            "Requirement already satisfied: numpy~=2.0.0 in /usr/local/lib/python3.12/dist-packages (from kraken>=0.11.0) (2.0.2)\n",
            "Requirement already satisfied: Pillow>=9.2.0 in /usr/local/lib/python3.12/dist-packages (from kraken>=0.11.0) (11.3.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from kraken>=0.11.0) (2025.11.3)\n",
            "Requirement already satisfied: scipy~=1.13.0 in /usr/local/lib/python3.12/dist-packages (from kraken>=0.11.0) (1.13.1)\n",
            "Requirement already satisfied: protobuf>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from kraken>=0.11.0) (5.29.5)\n",
            "Requirement already satisfied: coremltools~=8.1 in /usr/local/lib/python3.12/dist-packages (from kraken>=0.11.0) (8.3.0)\n",
            "Requirement already satisfied: jinja2~=3.0 in /usr/local/lib/python3.12/dist-packages (from kraken>=0.11.0) (3.1.6)\n",
            "Requirement already satisfied: python-bidi~=0.6.0 in /usr/local/lib/python3.12/dist-packages (from kraken>=0.11.0) (0.6.7)\n",
            "Requirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from kraken>=0.11.0) (0.22.1)\n",
            "Requirement already satisfied: torch<2.8.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from kraken>=0.11.0) (2.7.1)\n",
            "Requirement already satisfied: scikit-learn~=1.5.0 in /usr/local/lib/python3.12/dist-packages (from kraken>=0.11.0) (1.5.2)\n",
            "Requirement already satisfied: scikit-image~=0.24.0 in /usr/local/lib/python3.12/dist-packages (from kraken>=0.11.0) (0.24.0)\n",
            "Requirement already satisfied: shapely>=2.0.6,~=2.0.6 in /usr/local/lib/python3.12/dist-packages (from kraken>=0.11.0) (2.0.7)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.12/dist-packages (from kraken>=0.11.0) (18.1.0)\n",
            "Requirement already satisfied: htrmopo>=0.3,~=0.3 in /usr/local/lib/python3.12/dist-packages (from kraken>=0.11.0) (0.3.0)\n",
            "Requirement already satisfied: lightning~=2.4.0 in /usr/local/lib/python3.12/dist-packages (from kraken>=0.11.0) (2.4.0)\n",
            "Requirement already satisfied: torchmetrics>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from kraken>=0.11.0) (1.8.2)\n",
            "Requirement already satisfied: threadpoolctl~=3.5.0 in /usr/local/lib/python3.12/dist-packages (from kraken>=0.11.0) (3.5.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from kraken>=0.11.0) (4.5.0)\n",
            "Requirement already satisfied: rich!=14.1.0 in /usr/local/lib/python3.12/dist-packages (from kraken>=0.11.0) (13.9.4)\n",
            "Requirement already satisfied: iso639-lang in /usr/local/lib/python3.12/dist-packages (from kraken>=0.11.0) (2.6.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from coremltools~=8.1->kraken>=0.11.0) (1.14.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from coremltools~=8.1->kraken>=0.11.0) (4.67.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from coremltools~=8.1->kraken>=0.11.0) (24.2)\n",
            "Requirement already satisfied: attrs>=21.3.0 in /usr/local/lib/python3.12/dist-packages (from coremltools~=8.1->kraken>=0.11.0) (25.4.0)\n",
            "Requirement already satisfied: cattrs in /usr/local/lib/python3.12/dist-packages (from coremltools~=8.1->kraken>=0.11.0) (25.3.0)\n",
            "Requirement already satisfied: pyaml in /usr/local/lib/python3.12/dist-packages (from coremltools~=8.1->kraken>=0.11.0) (25.7.0)\n",
            "Requirement already satisfied: flufl.lock in /usr/local/lib/python3.12/dist-packages (from htrmopo>=0.3,~=0.3->kraken>=0.11.0) (9.0.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from htrmopo>=0.3,~=0.3->kraken>=0.11.0) (6.0.3)\n",
            "Requirement already satisfied: sickle in /usr/local/lib/python3.12/dist-packages (from htrmopo>=0.3,~=0.3->kraken>=0.11.0) (0.7.0)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.12/dist-packages (from htrmopo>=0.3,~=0.3->kraken>=0.11.0) (3.10)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from htrmopo>=0.3,~=0.3->kraken>=0.11.0) (2.9.0.post0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2~=3.0->kraken>=0.11.0) (3.0.3)\n",
            "Requirement already satisfied: fsspec<2026.0,>=2022.5.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning~=2.4.0->kraken>=0.11.0) (2025.3.0)\n",
            "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from lightning~=2.4.0->kraken>=0.11.0) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions<6.0,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from lightning~=2.4.0->kraken>=0.11.0) (4.15.0)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.12/dist-packages (from lightning~=2.4.0->kraken>=0.11.0) (2.6.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich!=14.1.0->kraken>=0.11.0) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich!=14.1.0->kraken>=0.11.0) (2.19.2)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.12/dist-packages (from scikit-image~=0.24.0->kraken>=0.11.0) (3.6)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image~=0.24.0->kraken>=0.11.0) (2.37.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image~=0.24.0->kraken>=0.11.0) (2025.10.16)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image~=0.24.0->kraken>=0.11.0) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn~=1.5.0->kraken>=0.11.0) (1.5.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.4.0->kraken>=0.11.0) (3.20.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.4.0->kraken>=0.11.0) (75.2.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.4.0->kraken>=0.11.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.4.0->kraken>=0.11.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.4.0->kraken>=0.11.0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.4.0->kraken>=0.11.0) (9.5.1.17)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.4.0->kraken>=0.11.0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.4.0->kraken>=0.11.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.4.0->kraken>=0.11.0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.4.0->kraken>=0.11.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.4.0->kraken>=0.11.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.4.0->kraken>=0.11.0) (0.6.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.4.0->kraken>=0.11.0) (2.26.2)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.4.0->kraken>=0.11.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.4.0->kraken>=0.11.0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.4.0->kraken>=0.11.0) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.3.1 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.4.0->kraken>=0.11.0) (3.3.1)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema->kraken>=0.11.0) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema->kraken>=0.11.0) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema->kraken>=0.11.0) (0.29.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kraken>=0.11.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->kraken>=0.11.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->kraken>=0.11.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->kraken>=0.11.0) (2025.11.12)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning~=2.4.0->kraken>=0.11.0) (3.13.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich!=14.1.0->kraken>=0.11.0) (0.1.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->coremltools~=8.1->kraken>=0.11.0) (1.3.0)\n",
            "Requirement already satisfied: atpublic in /usr/local/lib/python3.12/dist-packages (from flufl.lock->htrmopo>=0.3,~=0.3->kraken>=0.11.0) (5.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from flufl.lock->htrmopo>=0.3,~=0.3->kraken>=0.11.0) (5.9.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil->htrmopo>=0.3,~=0.3->kraken>=0.11.0) (1.17.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning~=2.4.0->kraken>=0.11.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning~=2.4.0->kraken>=0.11.0) (1.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning~=2.4.0->kraken>=0.11.0) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning~=2.4.0->kraken>=0.11.0) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning~=2.4.0->kraken>=0.11.0) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning~=2.4.0->kraken>=0.11.0) (1.22.0)\n",
            "Using cached kraken-6.0.2-py3-none-any.whl (5.0 MB)\n",
            "Installing collected packages: kraken\n",
            "Successfully installed kraken-6.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall -y kraken\n",
        "!pip install \"kraken>=0.11.0\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eowcR2_C97ce",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "eowcR2_C97ce",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "b4f47ec3-0415-4428-a573-c239ccb4f3fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kraken in /usr/local/lib/python3.12/dist-packages (6.0.2)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.12/dist-packages (from kraken) (4.25.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from kraken) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kraken) (2.32.4)\n",
            "Requirement already satisfied: click<8.3,>=8.1 in /usr/local/lib/python3.12/dist-packages (from kraken) (8.2.1)\n",
            "Requirement already satisfied: numpy~=2.0.0 in /usr/local/lib/python3.12/dist-packages (from kraken) (2.0.2)\n",
            "Requirement already satisfied: Pillow>=9.2.0 in /usr/local/lib/python3.12/dist-packages (from kraken) (11.3.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from kraken) (2025.11.3)\n",
            "Requirement already satisfied: scipy~=1.13.0 in /usr/local/lib/python3.12/dist-packages (from kraken) (1.13.1)\n",
            "Requirement already satisfied: protobuf>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from kraken) (5.29.5)\n",
            "Requirement already satisfied: coremltools~=8.1 in /usr/local/lib/python3.12/dist-packages (from kraken) (8.3.0)\n",
            "Requirement already satisfied: jinja2~=3.0 in /usr/local/lib/python3.12/dist-packages (from kraken) (3.1.6)\n",
            "Requirement already satisfied: python-bidi~=0.6.0 in /usr/local/lib/python3.12/dist-packages (from kraken) (0.6.7)\n",
            "Requirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from kraken) (0.22.1)\n",
            "Requirement already satisfied: torch<2.8.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from kraken) (2.7.1)\n",
            "Requirement already satisfied: scikit-learn~=1.5.0 in /usr/local/lib/python3.12/dist-packages (from kraken) (1.5.2)\n",
            "Requirement already satisfied: scikit-image~=0.24.0 in /usr/local/lib/python3.12/dist-packages (from kraken) (0.24.0)\n",
            "Requirement already satisfied: shapely>=2.0.6,~=2.0.6 in /usr/local/lib/python3.12/dist-packages (from kraken) (2.0.7)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.12/dist-packages (from kraken) (18.1.0)\n",
            "Requirement already satisfied: htrmopo>=0.3,~=0.3 in /usr/local/lib/python3.12/dist-packages (from kraken) (0.3.0)\n",
            "Requirement already satisfied: lightning~=2.4.0 in /usr/local/lib/python3.12/dist-packages (from kraken) (2.4.0)\n",
            "Requirement already satisfied: torchmetrics>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from kraken) (1.8.2)\n",
            "Requirement already satisfied: threadpoolctl~=3.5.0 in /usr/local/lib/python3.12/dist-packages (from kraken) (3.5.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from kraken) (4.5.0)\n",
            "Requirement already satisfied: rich!=14.1.0 in /usr/local/lib/python3.12/dist-packages (from kraken) (13.9.4)\n",
            "Requirement already satisfied: iso639-lang in /usr/local/lib/python3.12/dist-packages (from kraken) (2.6.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from coremltools~=8.1->kraken) (1.14.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from coremltools~=8.1->kraken) (4.67.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from coremltools~=8.1->kraken) (24.2)\n",
            "Requirement already satisfied: attrs>=21.3.0 in /usr/local/lib/python3.12/dist-packages (from coremltools~=8.1->kraken) (25.4.0)\n",
            "Requirement already satisfied: cattrs in /usr/local/lib/python3.12/dist-packages (from coremltools~=8.1->kraken) (25.3.0)\n",
            "Requirement already satisfied: pyaml in /usr/local/lib/python3.12/dist-packages (from coremltools~=8.1->kraken) (25.7.0)\n",
            "Requirement already satisfied: flufl.lock in /usr/local/lib/python3.12/dist-packages (from htrmopo>=0.3,~=0.3->kraken) (9.0.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from htrmopo>=0.3,~=0.3->kraken) (6.0.3)\n",
            "Requirement already satisfied: sickle in /usr/local/lib/python3.12/dist-packages (from htrmopo>=0.3,~=0.3->kraken) (0.7.0)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.12/dist-packages (from htrmopo>=0.3,~=0.3->kraken) (3.10)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from htrmopo>=0.3,~=0.3->kraken) (2.9.0.post0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2~=3.0->kraken) (3.0.3)\n",
            "Requirement already satisfied: fsspec<2026.0,>=2022.5.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning~=2.4.0->kraken) (2025.3.0)\n",
            "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from lightning~=2.4.0->kraken) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions<6.0,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from lightning~=2.4.0->kraken) (4.15.0)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.12/dist-packages (from lightning~=2.4.0->kraken) (2.6.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich!=14.1.0->kraken) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich!=14.1.0->kraken) (2.19.2)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.12/dist-packages (from scikit-image~=0.24.0->kraken) (3.6)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image~=0.24.0->kraken) (2.37.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image~=0.24.0->kraken) (2025.10.16)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image~=0.24.0->kraken) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn~=1.5.0->kraken) (1.5.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.4.0->kraken) (3.20.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.4.0->kraken) (75.2.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.4.0->kraken) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.4.0->kraken) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.4.0->kraken) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.4.0->kraken) (9.5.1.17)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.4.0->kraken) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.4.0->kraken) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.4.0->kraken) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.4.0->kraken) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.4.0->kraken) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.4.0->kraken) (0.6.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.4.0->kraken) (2.26.2)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.4.0->kraken) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.4.0->kraken) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.4.0->kraken) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.3.1 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.4.0->kraken) (3.3.1)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema->kraken) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema->kraken) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema->kraken) (0.29.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kraken) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->kraken) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->kraken) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->kraken) (2025.11.12)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning~=2.4.0->kraken) (3.13.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich!=14.1.0->kraken) (0.1.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->coremltools~=8.1->kraken) (1.3.0)\n",
            "Requirement already satisfied: atpublic in /usr/local/lib/python3.12/dist-packages (from flufl.lock->htrmopo>=0.3,~=0.3->kraken) (5.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from flufl.lock->htrmopo>=0.3,~=0.3->kraken) (5.9.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil->htrmopo>=0.3,~=0.3->kraken) (1.17.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning~=2.4.0->kraken) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning~=2.4.0->kraken) (1.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning~=2.4.0->kraken) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning~=2.4.0->kraken) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning~=2.4.0->kraken) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning~=2.4.0->kraken) (1.22.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade kraken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BOM05nQL-WPB",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOM05nQL-WPB",
        "outputId": "555c1800-1f6d-41be-b362-c62d887879bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ketos, version 6.0.2\n"
          ]
        }
      ],
      "source": [
        "!ketos --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4E82aZfe_5YP",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4E82aZfe_5YP",
        "outputId": "b4cf1e44-14db-4cee-d1d6-343d3ccab583"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: kraken 6.0.2\n",
            "Uninstalling kraken-6.0.2:\n",
            "  Successfully uninstalled kraken-6.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall -y kraken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "J5aWWXTa_8Iz",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "J5aWWXTa_8Iz",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "b2434f06-bb98-4492-cc62-74de1e30d7c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting kraken\n",
            "  Using cached kraken-6.0.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.12/dist-packages (from kraken) (4.25.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from kraken) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kraken) (2.32.4)\n",
            "Requirement already satisfied: click<8.3,>=8.1 in /usr/local/lib/python3.12/dist-packages (from kraken) (8.2.1)\n",
            "Requirement already satisfied: numpy~=2.0.0 in /usr/local/lib/python3.12/dist-packages (from kraken) (2.0.2)\n",
            "Requirement already satisfied: Pillow>=9.2.0 in /usr/local/lib/python3.12/dist-packages (from kraken) (11.3.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from kraken) (2025.11.3)\n",
            "Requirement already satisfied: scipy~=1.13.0 in /usr/local/lib/python3.12/dist-packages (from kraken) (1.13.1)\n",
            "Requirement already satisfied: protobuf>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from kraken) (5.29.5)\n",
            "Requirement already satisfied: coremltools~=8.1 in /usr/local/lib/python3.12/dist-packages (from kraken) (8.3.0)\n",
            "Requirement already satisfied: jinja2~=3.0 in /usr/local/lib/python3.12/dist-packages (from kraken) (3.1.6)\n",
            "Requirement already satisfied: python-bidi~=0.6.0 in /usr/local/lib/python3.12/dist-packages (from kraken) (0.6.7)\n",
            "Requirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from kraken) (0.22.1)\n",
            "Requirement already satisfied: torch<2.8.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from kraken) (2.7.1)\n",
            "Requirement already satisfied: scikit-learn~=1.5.0 in /usr/local/lib/python3.12/dist-packages (from kraken) (1.5.2)\n",
            "Requirement already satisfied: scikit-image~=0.24.0 in /usr/local/lib/python3.12/dist-packages (from kraken) (0.24.0)\n",
            "Requirement already satisfied: shapely>=2.0.6,~=2.0.6 in /usr/local/lib/python3.12/dist-packages (from kraken) (2.0.7)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.12/dist-packages (from kraken) (18.1.0)\n",
            "Requirement already satisfied: htrmopo>=0.3,~=0.3 in /usr/local/lib/python3.12/dist-packages (from kraken) (0.3.0)\n",
            "Requirement already satisfied: lightning~=2.4.0 in /usr/local/lib/python3.12/dist-packages (from kraken) (2.4.0)\n",
            "Requirement already satisfied: torchmetrics>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from kraken) (1.8.2)\n",
            "Requirement already satisfied: threadpoolctl~=3.5.0 in /usr/local/lib/python3.12/dist-packages (from kraken) (3.5.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from kraken) (4.5.0)\n",
            "Requirement already satisfied: rich!=14.1.0 in /usr/local/lib/python3.12/dist-packages (from kraken) (13.9.4)\n",
            "Requirement already satisfied: iso639-lang in /usr/local/lib/python3.12/dist-packages (from kraken) (2.6.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from coremltools~=8.1->kraken) (1.14.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from coremltools~=8.1->kraken) (4.67.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from coremltools~=8.1->kraken) (24.2)\n",
            "Requirement already satisfied: attrs>=21.3.0 in /usr/local/lib/python3.12/dist-packages (from coremltools~=8.1->kraken) (25.4.0)\n",
            "Requirement already satisfied: cattrs in /usr/local/lib/python3.12/dist-packages (from coremltools~=8.1->kraken) (25.3.0)\n",
            "Requirement already satisfied: pyaml in /usr/local/lib/python3.12/dist-packages (from coremltools~=8.1->kraken) (25.7.0)\n",
            "Requirement already satisfied: flufl.lock in /usr/local/lib/python3.12/dist-packages (from htrmopo>=0.3,~=0.3->kraken) (9.0.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from htrmopo>=0.3,~=0.3->kraken) (6.0.3)\n",
            "Requirement already satisfied: sickle in /usr/local/lib/python3.12/dist-packages (from htrmopo>=0.3,~=0.3->kraken) (0.7.0)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.12/dist-packages (from htrmopo>=0.3,~=0.3->kraken) (3.10)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from htrmopo>=0.3,~=0.3->kraken) (2.9.0.post0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2~=3.0->kraken) (3.0.3)\n",
            "Requirement already satisfied: fsspec<2026.0,>=2022.5.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning~=2.4.0->kraken) (2025.3.0)\n",
            "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from lightning~=2.4.0->kraken) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions<6.0,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from lightning~=2.4.0->kraken) (4.15.0)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.12/dist-packages (from lightning~=2.4.0->kraken) (2.6.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich!=14.1.0->kraken) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich!=14.1.0->kraken) (2.19.2)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.12/dist-packages (from scikit-image~=0.24.0->kraken) (3.6)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image~=0.24.0->kraken) (2.37.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image~=0.24.0->kraken) (2025.10.16)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image~=0.24.0->kraken) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn~=1.5.0->kraken) (1.5.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.4.0->kraken) (3.20.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.4.0->kraken) (75.2.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.4.0->kraken) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.4.0->kraken) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.4.0->kraken) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.4.0->kraken) (9.5.1.17)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.4.0->kraken) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.4.0->kraken) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.4.0->kraken) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.4.0->kraken) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.4.0->kraken) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.4.0->kraken) (0.6.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.4.0->kraken) (2.26.2)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.4.0->kraken) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.4.0->kraken) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.4.0->kraken) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.3.1 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.4.0->kraken) (3.3.1)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema->kraken) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema->kraken) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema->kraken) (0.29.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kraken) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->kraken) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->kraken) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->kraken) (2025.11.12)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning~=2.4.0->kraken) (3.13.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich!=14.1.0->kraken) (0.1.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->coremltools~=8.1->kraken) (1.3.0)\n",
            "Requirement already satisfied: atpublic in /usr/local/lib/python3.12/dist-packages (from flufl.lock->htrmopo>=0.3,~=0.3->kraken) (5.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from flufl.lock->htrmopo>=0.3,~=0.3->kraken) (5.9.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil->htrmopo>=0.3,~=0.3->kraken) (1.17.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning~=2.4.0->kraken) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning~=2.4.0->kraken) (1.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning~=2.4.0->kraken) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning~=2.4.0->kraken) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning~=2.4.0->kraken) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning~=2.4.0->kraken) (1.22.0)\n",
            "Using cached kraken-6.0.2-py3-none-any.whl (5.0 MB)\n",
            "Installing collected packages: kraken\n",
            "Successfully installed kraken-6.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip install -U kraken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Ww7SX6C8Ziln",
      "metadata": {
        "id": "Ww7SX6C8Ziln"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tgxNYI1oB9mw",
      "metadata": {
        "id": "tgxNYI1oB9mw"
      },
      "outputs": [],
      "source": [
        "!ls -lh /content/kraken_bentham/lines | grep mlmodel\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QxGlUTpFE8qV",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxGlUTpFE8qV",
        "outputId": "91ea4a1b-b165-4538-ff3f-6e010aaecbc8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ketos, version 6.0.2\n",
            "Usage: ketos train [OPTIONS] [GROUND_TRUTH]...\n",
            "\n",
            "  Trains a model from image-text pairs.\n",
            "\n",
            "Options:\n",
            "  -B, --batch-size INTEGER        batch sample size  [default: 1]\n",
            "  --pad INTEGER                   Left and right padding around lines\n",
            "                                  [default: 16]\n",
            "  -o, --output PATH               Output model file  [default: model]\n",
            "  -s, --spec TEXT                 VGSL spec of the network to train. CTC layer\n",
            "                                  will be added automatically.  [default:\n",
            "                                  [1,120,0,1 Cr3,13,32 Do0.1,2 Mp2,2 Cr3,13,32\n",
            "                                  Do0.1,2 Mp2,2 Cr3,9,64 Do0.1,2 Mp2,2\n",
            "                                  Cr3,9,64 Do0.1,2 S1(1x0)1,3 Lbx200 Do0.1,2\n",
            "                                  Lbx200 Do0.1,2 Lbx200 Do]]\n",
            "  -a, --append INTEGER            Removes layers before argument and then\n",
            "                                  appends spec. Only works when loading an\n",
            "                                  existing model\n",
            "  -i, --load PATH                 Load existing file to continue training\n",
            "  -F, --freq FLOAT                Model saving and report generation frequency\n",
            "                                  in epochs during training. If frequency is\n",
            "                                  >1 it must be an integer, i.e. running\n",
            "                                  validation every n-th epoch.  [default: 1.0]\n",
            "  -q, --quit [early|fixed]        Stop condition for training. Set to `early`\n",
            "                                  for early stooping or `fixed` for fixed\n",
            "                                  number of epochs  [default: early]\n",
            "  -N, --epochs INTEGER            Number of epochs to train for  [default: -1]\n",
            "  --min-epochs INTEGER            Minimal number of epochs to train for when\n",
            "                                  using early stopping.  [default: 0]\n",
            "  --lag INTEGER                   Number of evaluations (--report frequency)\n",
            "                                  to wait before stopping training without\n",
            "                                  improvement  [default: 10]\n",
            "  --min-delta FLOAT               Minimum improvement between epochs to reset\n",
            "                                  early stopping. Default is scales the delta\n",
            "                                  by the best loss\n",
            "  --optimizer [Adam|AdamW|SGD|RMSprop]\n",
            "                                  Select optimizer  [default: Adam]\n",
            "  -r, --lrate FLOAT               Learning rate  [default: 0.001]\n",
            "  -m, --momentum FLOAT            Momentum  [default: 0.9]\n",
            "  -w, --weight-decay FLOAT        Weight decay  [default: 0.0]\n"
          ]
        }
      ],
      "source": [
        "!ketos --version\n",
        "!ketos train --help | head -40\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "he2Mbq7UIzUf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "he2Mbq7UIzUf",
        "outputId": "413132b7-bfbf-4db3-e937-8a5c2ee2d4ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[90m━━━━━━━━━━━\u001b[0m 11/287    \u001b[33m0:00:08 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[90m━━━━━━━━━━━\u001b[0m 11/287    \u001b[33m0:00:08 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[90m━━━━━━━━━━━\u001b[0m 12/287    \u001b[33m0:00:10 •   \u001b[0m \u001b[31m1.06it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[90m━━━━━━━━━━━\u001b[0m 12/287    \u001b[33m0:00:10 •   \u001b[0m \u001b[31m1.06it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[90m━━━━━━━━━━━\u001b[0m 13/287    \u001b[33m0:00:11 •   \u001b[0m \u001b[31m1.09it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[90m━━━━━━━━━━━\u001b[0m 13/287    \u001b[33m0:00:11 •   \u001b[0m \u001b[31m1.09it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m 14/287    \u001b[33m0:00:12 •   \u001b[0m \u001b[31m1.09it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m 14/287    \u001b[33m0:00:12 •   \u001b[0m \u001b[31m1.09it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m 15/287    \u001b[33m0:00:12 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m 15/287    \u001b[33m0:00:12 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m 16/287    \u001b[33m0:00:13 •   \u001b[0m \u001b[31m1.11it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m 16/287    \u001b[33m0:00:13 •   \u001b[0m \u001b[31m1.11it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m 17/287    \u001b[33m0:00:13 •   \u001b[0m \u001b[31m1.15it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m 17/287    \u001b[33m0:00:13 •   \u001b[0m \u001b[31m1.15it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m 18/287    \u001b[33m0:00:14 •   \u001b[0m \u001b[31m1.15it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m 18/287    \u001b[33m0:00:14 •   \u001b[0m \u001b[31m1.15it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m 19/287    \u001b[33m0:00:15 •   \u001b[0m \u001b[31m1.18it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m 19/287    \u001b[33m0:00:15 •   \u001b[0m \u001b[31m1.18it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m 20/287    \u001b[33m0:00:16 •   \u001b[0m \u001b[31m1.18it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m 20/287    \u001b[33m0:00:16 •   \u001b[0m \u001b[31m1.18it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m 21/287    \u001b[33m0:00:16 •   \u001b[0m \u001b[31m1.20it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m 21/287    \u001b[33m0:00:16 •   \u001b[0m \u001b[31m1.20it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m 22/287    \u001b[33m0:00:17 •   \u001b[0m \u001b[31m1.23it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m 22/287    \u001b[33m0:00:17 •   \u001b[0m \u001b[31m1.23it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m 23/287    \u001b[33m0:00:18 •   \u001b[0m \u001b[31m1.21it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m 23/287    \u001b[33m0:00:18 •   \u001b[0m \u001b[31m1.21it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m 24/287    \u001b[33m0:00:19 •   \u001b[0m \u001b[31m1.17it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m 24/287    \u001b[33m0:00:19 •   \u001b[0m \u001b[31m1.17it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m 25/287    \u001b[33m0:00:20 •   \u001b[0m \u001b[31m1.15it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m 25/287    \u001b[33m0:00:20 •   \u001b[0m \u001b[31m1.15it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m 26/287    \u001b[33m0:00:21 •   \u001b[0m \u001b[31m1.16it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m 26/287    \u001b[33m0:00:21 •   \u001b[0m \u001b[31m1.16it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m 27/287    \u001b[33m0:00:22 •   \u001b[0m \u001b[31m1.18it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m 27/287    \u001b[33m0:00:22 •   \u001b[0m \u001b[31m1.18it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m 28/287    \u001b[33m0:00:22 •   \u001b[0m \u001b[31m1.18it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m 28/287    \u001b[33m0:00:22 •   \u001b[0m \u001b[31m1.18it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m 29/287    \u001b[33m0:00:23 •   \u001b[0m \u001b[31m1.19it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m 29/287    \u001b[33m0:00:23 •   \u001b[0m \u001b[31m1.19it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m 30/287    \u001b[33m0:00:24 •   \u001b[0m \u001b[31m1.19it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m 30/287    \u001b[33m0:00:24 •   \u001b[0m \u001b[31m1.19it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m 31/287    \u001b[33m0:00:24 •   \u001b[0m \u001b[31m1.22it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m 31/287    \u001b[33m0:00:24 •   \u001b[0m \u001b[31m1.22it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m 32/287    \u001b[33m0:00:25 •   \u001b[0m \u001b[31m1.23it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m 32/287    \u001b[33m0:00:25 •   \u001b[0m \u001b[31m1.23it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m 33/287    \u001b[33m0:00:25 •   \u001b[0m \u001b[31m1.25it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m 33/287    \u001b[33m0:00:25 •   \u001b[0m \u001b[31m1.25it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m 34/287    \u001b[33m0:00:26 •   \u001b[0m \u001b[31m1.27it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m 34/287    \u001b[33m0:00:26 •   \u001b[0m \u001b[31m1.27it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m 35/287    \u001b[33m0:00:26 •   \u001b[0m \u001b[31m1.27it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m 35/287    \u001b[33m0:00:26 •   \u001b[0m \u001b[31m1.27it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m 36/287    \u001b[33m0:00:28 •   \u001b[0m \u001b[31m1.25it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m 36/287    \u001b[33m0:00:28 •   \u001b[0m \u001b[31m1.25it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m 37/287    \u001b[33m0:00:28 •   \u001b[0m \u001b[31m1.25it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m 37/287    \u001b[33m0:00:28 •   \u001b[0m \u001b[31m1.25it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m 38/287    \u001b[33m0:00:29 •   \u001b[0m \u001b[31m1.24it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m 38/287    \u001b[33m0:00:29 •   \u001b[0m \u001b[31m1.24it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m 39/287    \u001b[33m0:00:30 •   \u001b[0m \u001b[31m1.27it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m 39/287    \u001b[33m0:00:30 •   \u001b[0m \u001b[31m1.27it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m 40/287    \u001b[33m0:00:31 •   \u001b[0m \u001b[31m1.29it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m 40/287    \u001b[33m0:00:31 •   \u001b[0m \u001b[31m1.29it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m 41/287    \u001b[33m0:00:32 •   \u001b[0m \u001b[31m1.26it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m 41/287    \u001b[33m0:00:32 •   \u001b[0m \u001b[31m1.26it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m 42/287    \u001b[33m0:00:33 •   \u001b[0m \u001b[31m1.24it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m 42/287    \u001b[33m0:00:33 •   \u001b[0m \u001b[31m1.24it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m 43/287    \u001b[33m0:00:34 •   \u001b[0m \u001b[31m1.25it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m 43/287    \u001b[33m0:00:34 •   \u001b[0m \u001b[31m1.25it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m 44/287    \u001b[33m0:00:35 •   \u001b[0m \u001b[31m1.25it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m 44/287    \u001b[33m0:00:35 •   \u001b[0m \u001b[31m1.25it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m 45/287    \u001b[33m0:00:35 •   \u001b[0m \u001b[31m1.22it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m 45/287    \u001b[33m0:00:35 •   \u001b[0m \u001b[31m1.22it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m 46/287    \u001b[33m0:00:36 •   \u001b[0m \u001b[31m1.23it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m 46/287    \u001b[33m0:00:36 •   \u001b[0m \u001b[31m1.23it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m 47/287    \u001b[33m0:00:37 •   \u001b[0m \u001b[31m1.24it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m 47/287    \u001b[33m0:00:37 •   \u001b[0m \u001b[31m1.24it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m 48/287    \u001b[33m0:00:38 •   \u001b[0m \u001b[31m1.26it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m 48/287    \u001b[33m0:00:38 •   \u001b[0m \u001b[31m1.26it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m 49/287    \u001b[33m0:00:39 •   \u001b[0m \u001b[31m1.29it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m 49/287    \u001b[33m0:00:39 •   \u001b[0m \u001b[31m1.29it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m 50/287    \u001b[33m0:00:39 •   \u001b[0m \u001b[31m1.29it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m 50/287    \u001b[33m0:00:39 •   \u001b[0m \u001b[31m1.29it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m 51/287    \u001b[33m0:00:41 •   \u001b[0m \u001b[31m1.24it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m 51/287    \u001b[33m0:00:41 •   \u001b[0m \u001b[31m1.24it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m 52/287    \u001b[33m0:00:42 •   \u001b[0m \u001b[31m1.24it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m 52/287    \u001b[33m0:00:42 •   \u001b[0m \u001b[31m1.24it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m 53/287    \u001b[33m0:00:43 •   \u001b[0m \u001b[31m1.24it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m 53/287    \u001b[33m0:00:43 •   \u001b[0m \u001b[31m1.24it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m 54/287    \u001b[33m0:00:44 •   \u001b[0m \u001b[31m1.22it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m 54/287    \u001b[33m0:00:44 •   \u001b[0m \u001b[31m1.22it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m 55/287    \u001b[33m0:00:44 •   \u001b[0m \u001b[31m1.23it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m 55/287    \u001b[33m0:00:44 •   \u001b[0m \u001b[31m1.23it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m 56/287    \u001b[33m0:00:45 •   \u001b[0m \u001b[31m1.23it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m 56/287    \u001b[33m0:00:45 •   \u001b[0m \u001b[31m1.23it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m 57/287    \u001b[33m0:00:45 •   \u001b[0m \u001b[31m1.24it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m 57/287    \u001b[33m0:00:46 •   \u001b[0m \u001b[31m1.24it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m 58/287    \u001b[33m0:00:47 •   \u001b[0m \u001b[31m1.18it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m 58/287    \u001b[33m0:00:47 •   \u001b[0m \u001b[31m1.18it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m 59/287    \u001b[33m0:00:48 •   \u001b[0m \u001b[31m1.20it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m 59/287    \u001b[33m0:00:48 •   \u001b[0m \u001b[31m1.20it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m 60/287    \u001b[33m0:00:49 •   \u001b[0m \u001b[31m1.21it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m 60/287    \u001b[33m0:00:49 •   \u001b[0m \u001b[31m1.21it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m 61/287    \u001b[33m0:00:50 •   \u001b[0m \u001b[31m1.21it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m 61/287    \u001b[33m0:00:50 •   \u001b[0m \u001b[31m1.21it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m 62/287    \u001b[33m0:00:51 •   \u001b[0m \u001b[31m1.20it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m 62/287    \u001b[33m0:00:51 •   \u001b[0m \u001b[31m1.20it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m 63/287    \u001b[33m0:00:52 •   \u001b[0m \u001b[31m1.20it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m 63/287    \u001b[33m0:00:52 •   \u001b[0m \u001b[31m1.20it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m 64/287    \u001b[33m0:00:53 •   \u001b[0m \u001b[31m1.17it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m 64/287    \u001b[33m0:00:53 •   \u001b[0m \u001b[31m1.17it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m 65/287    \u001b[33m0:00:54 •   \u001b[0m \u001b[31m1.14it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m 65/287    \u001b[33m0:00:54 •   \u001b[0m \u001b[31m1.14it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m 66/287    \u001b[33m0:00:55 •   \u001b[0m \u001b[31m1.11it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m 66/287    \u001b[33m0:00:55 •   \u001b[0m \u001b[31m1.11it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m 67/287    \u001b[33m0:00:56 •   \u001b[0m \u001b[31m1.10it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m 67/287    \u001b[33m0:00:56 •   \u001b[0m \u001b[31m1.10it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m 68/287    \u001b[33m0:00:56 •   \u001b[0m \u001b[31m1.10it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m 68/287    \u001b[33m0:00:56 •   \u001b[0m \u001b[31m1.10it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m 69/287    \u001b[33m0:00:58 •   \u001b[0m \u001b[31m1.10it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m 69/287    \u001b[33m0:00:58 •   \u001b[0m \u001b[31m1.10it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m 70/287    \u001b[33m0:00:59 •   \u001b[0m \u001b[31m1.09it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m 70/287    \u001b[33m0:00:59 •   \u001b[0m \u001b[31m1.09it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m 71/287    \u001b[33m0:01:00 •   \u001b[0m \u001b[31m1.08it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m 71/287    \u001b[33m0:01:00 •   \u001b[0m \u001b[31m1.08it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m 72/287    \u001b[33m0:01:01 •   \u001b[0m \u001b[31m1.07it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m 72/287    \u001b[33m0:01:01 •   \u001b[0m \u001b[31m1.07it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m 73/287    \u001b[33m0:01:02 •   \u001b[0m \u001b[31m1.07it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m 73/287    \u001b[33m0:01:02 •   \u001b[0m \u001b[31m1.07it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m 74/287    \u001b[33m0:01:03 •   \u001b[0m \u001b[31m1.05it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m 74/287    \u001b[33m0:01:03 •   \u001b[0m \u001b[31m1.05it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m 75/287    \u001b[33m0:01:04 •   \u001b[0m \u001b[31m1.05it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m 75/287    \u001b[33m0:01:04 •   \u001b[0m \u001b[31m1.05it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m 76/287    \u001b[33m0:01:04 •   \u001b[0m \u001b[31m1.07it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m 76/287    \u001b[33m0:01:04 •   \u001b[0m \u001b[31m1.07it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m 77/287    \u001b[33m0:01:06 •   \u001b[0m \u001b[31m1.05it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m 77/287    \u001b[33m0:01:06 •   \u001b[0m \u001b[31m1.05it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m 78/287    \u001b[33m0:01:06 •   \u001b[0m \u001b[31m1.05it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m 78/287    \u001b[33m0:01:06 •   \u001b[0m \u001b[31m1.05it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m 79/287    \u001b[33m0:01:07 •   \u001b[0m \u001b[31m1.08it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m 79/287    \u001b[33m0:01:07 •   \u001b[0m \u001b[31m1.08it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m 80/287    \u001b[33m0:01:08 •   \u001b[0m \u001b[31m1.08it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m 80/287    \u001b[33m0:01:08 •   \u001b[0m \u001b[31m1.08it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m 81/287    \u001b[33m0:01:09 •   \u001b[0m \u001b[31m1.07it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m 81/287    \u001b[33m0:01:09 •   \u001b[0m \u001b[31m1.07it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m 82/287    \u001b[33m0:01:10 •   \u001b[0m \u001b[31m1.10it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m 82/287    \u001b[33m0:01:10 •   \u001b[0m \u001b[31m1.10it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m 83/287    \u001b[33m0:01:10 •   \u001b[0m \u001b[31m1.10it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m 83/287    \u001b[33m0:01:10 •   \u001b[0m \u001b[31m1.10it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m 84/287    \u001b[33m0:01:11 •   \u001b[0m \u001b[31m1.11it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m 84/287    \u001b[33m0:01:11 •   \u001b[0m \u001b[31m1.11it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m 85/287    \u001b[33m0:01:13 •   \u001b[0m \u001b[31m1.08it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m 85/287    \u001b[33m0:01:13 •   \u001b[0m \u001b[31m1.08it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m 86/287    \u001b[33m0:01:13 •   \u001b[0m \u001b[31m1.08it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m 86/287    \u001b[33m0:01:13 •   \u001b[0m \u001b[31m1.08it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m 87/287    \u001b[33m0:01:14 •   \u001b[0m \u001b[31m1.05it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m 87/287    \u001b[33m0:01:14 •   \u001b[0m \u001b[31m1.05it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m 88/287    \u001b[33m0:01:16 •   \u001b[0m \u001b[31m1.05it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m 88/287    \u001b[33m0:01:16 •   \u001b[0m \u001b[31m1.05it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m 89/287    \u001b[33m0:01:17 •   \u001b[0m \u001b[31m1.04it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m 89/287    \u001b[33m0:01:17 •   \u001b[0m \u001b[31m1.04it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m 90/287    \u001b[33m0:01:18 •   \u001b[0m \u001b[31m1.05it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m 90/287    \u001b[33m0:01:18 •   \u001b[0m \u001b[31m1.05it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m 91/287    \u001b[33m0:01:19 •   \u001b[0m \u001b[31m1.04it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m 91/287    \u001b[33m0:01:19 •   \u001b[0m \u001b[31m1.04it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m 92/287    \u001b[33m0:01:19 •   \u001b[0m \u001b[31m1.07it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m 92/287    \u001b[33m0:01:19 •   \u001b[0m \u001b[31m1.07it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m 93/287    \u001b[33m0:01:21 •   \u001b[0m \u001b[31m1.04it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m 93/287    \u001b[33m0:01:21 •   \u001b[0m \u001b[31m1.04it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m 94/287    \u001b[33m0:01:21 •   \u001b[0m \u001b[31m1.05it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m 94/287    \u001b[33m0:01:21 •   \u001b[0m \u001b[31m1.05it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m 95/287    \u001b[33m0:01:22 •   \u001b[0m \u001b[31m1.07it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m 95/287    \u001b[33m0:01:22 •   \u001b[0m \u001b[31m1.07it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m 96/287    \u001b[33m0:01:23 •   \u001b[0m \u001b[31m1.07it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m 96/287    \u001b[33m0:01:23 •   \u001b[0m \u001b[31m1.07it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m 97/287    \u001b[33m0:01:24 •   \u001b[0m \u001b[31m1.07it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m 97/287    \u001b[33m0:01:24 •   \u001b[0m \u001b[31m1.07it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m 98/287    \u001b[33m0:01:25 •   \u001b[0m \u001b[31m1.05it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m 98/287    \u001b[33m0:01:25 •   \u001b[0m \u001b[31m1.05it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m 99/287    \u001b[33m0:01:26 •   \u001b[0m \u001b[31m1.05it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m 99/287    \u001b[33m0:01:26 •   \u001b[0m \u001b[31m1.05it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m 100/287   \u001b[33m0:01:26 •   \u001b[0m \u001b[31m1.07it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m 100/287   \u001b[33m0:01:26 •   \u001b[0m \u001b[31m1.07it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m 101/287   \u001b[33m0:01:27 •   \u001b[0m \u001b[31m1.08it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m 101/287   \u001b[33m0:01:27 •   \u001b[0m \u001b[31m1.08it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m 102/287   \u001b[33m0:01:28 •   \u001b[0m \u001b[31m1.10it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m 102/287   \u001b[33m0:01:28 •   \u001b[0m \u001b[31m1.10it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m 103/287   \u001b[33m0:01:29 •   \u001b[0m \u001b[31m1.11it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m 103/287   \u001b[33m0:01:29 •   \u001b[0m \u001b[31m1.11it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m 104/287   \u001b[33m0:01:30 •   \u001b[0m \u001b[31m1.10it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m 104/287   \u001b[33m0:01:30 •   \u001b[0m \u001b[31m1.10it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m 105/287   \u001b[33m0:01:30 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m 105/287   \u001b[33m0:01:30 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m 106/287   \u001b[33m0:01:31 •   \u001b[0m \u001b[31m1.14it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m 106/287   \u001b[33m0:01:31 •   \u001b[0m \u001b[31m1.14it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m 107/287   \u001b[33m0:01:31 •   \u001b[0m \u001b[31m1.16it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m 107/287   \u001b[33m0:01:31 •   \u001b[0m \u001b[31m1.16it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m 108/287   \u001b[33m0:01:33 •   \u001b[0m \u001b[31m1.16it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m 108/287   \u001b[33m0:01:33 •   \u001b[0m \u001b[31m1.16it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m 109/287   \u001b[33m0:01:33 •   \u001b[0m \u001b[31m1.17it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m 109/287   \u001b[33m0:01:33 •   \u001b[0m \u001b[31m1.17it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m 110/287   \u001b[33m0:01:35 •   \u001b[0m \u001b[31m1.14it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m 110/287   \u001b[33m0:01:35 •   \u001b[0m \u001b[31m1.14it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m 111/287   \u001b[33m0:01:36 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m 111/287   \u001b[33m0:01:36 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m 112/287   \u001b[33m0:01:37 •   \u001b[0m \u001b[31m1.10it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m 112/287   \u001b[33m0:01:37 •   \u001b[0m \u001b[31m1.10it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m 113/287   \u001b[33m0:01:38 •   \u001b[0m \u001b[31m1.10it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m 113/287   \u001b[33m0:01:38 •   \u001b[0m \u001b[31m1.10it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m 114/287   \u001b[33m0:01:39 •   \u001b[0m \u001b[31m1.10it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m 114/287   \u001b[33m0:01:39 •   \u001b[0m \u001b[31m1.10it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m 115/287   \u001b[33m0:01:40 •   \u001b[0m \u001b[31m1.08it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m 115/287   \u001b[33m0:01:40 •   \u001b[0m \u001b[31m1.08it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m 116/287   \u001b[33m0:01:41 •   \u001b[0m \u001b[31m1.07it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m 116/287   \u001b[33m0:01:41 •   \u001b[0m \u001b[31m1.07it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m 117/287   \u001b[33m0:01:41 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m 117/287   \u001b[33m0:01:41 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m 118/287   \u001b[33m0:01:42 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m 118/287   \u001b[33m0:01:42 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m 119/287   \u001b[33m0:01:43 •   \u001b[0m \u001b[31m1.13it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m 119/287   \u001b[33m0:01:43 •   \u001b[0m \u001b[31m1.13it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m 120/287   \u001b[33m0:01:44 •   \u001b[0m \u001b[31m1.13it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m 120/287   \u001b[33m0:01:44 •   \u001b[0m \u001b[31m1.13it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m 121/287   \u001b[33m0:01:44 •   \u001b[0m \u001b[31m1.15it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m 121/287   \u001b[33m0:01:44 •   \u001b[0m \u001b[31m1.15it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m 122/287   \u001b[33m0:01:45 •   \u001b[0m \u001b[31m1.15it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m 122/287   \u001b[33m0:01:45 •   \u001b[0m \u001b[31m1.15it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m 123/287   \u001b[33m0:01:46 •   \u001b[0m \u001b[31m1.18it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m 123/287   \u001b[33m0:01:46 •   \u001b[0m \u001b[31m1.18it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m 124/287   \u001b[33m0:01:47 •   \u001b[0m \u001b[31m1.18it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m 124/287   \u001b[33m0:01:47 •   \u001b[0m \u001b[31m1.18it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m 125/287   \u001b[33m0:01:47 •   \u001b[0m \u001b[31m1.19it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m 125/287   \u001b[33m0:01:47 •   \u001b[0m \u001b[31m1.19it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m 126/287   \u001b[33m0:01:49 •   \u001b[0m \u001b[31m1.15it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m 126/287   \u001b[33m0:01:49 •   \u001b[0m \u001b[31m1.15it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m 127/287   \u001b[33m0:01:50 •   \u001b[0m \u001b[31m1.15it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m 127/287   \u001b[33m0:01:50 •   \u001b[0m \u001b[31m1.15it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m 128/287   \u001b[33m0:01:51 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m 128/287   \u001b[33m0:01:51 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m 129/287   \u001b[33m0:01:52 •   \u001b[0m \u001b[31m1.14it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m 129/287   \u001b[33m0:01:52 •   \u001b[0m \u001b[31m1.14it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m 130/287   \u001b[33m0:01:53 •   \u001b[0m \u001b[31m1.13it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m 130/287   \u001b[33m0:01:53 •   \u001b[0m \u001b[31m1.13it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m 131/287   \u001b[33m0:01:54 •   \u001b[0m \u001b[31m1.13it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m 131/287   \u001b[33m0:01:54 •   \u001b[0m \u001b[31m1.13it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m 132/287   \u001b[33m0:01:55 •   \u001b[0m \u001b[31m1.14it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m 132/287   \u001b[33m0:01:55 •   \u001b[0m \u001b[31m1.14it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m 133/287   \u001b[33m0:01:55 •   \u001b[0m \u001b[31m1.15it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m 133/287   \u001b[33m0:01:55 •   \u001b[0m \u001b[31m1.15it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m 134/287   \u001b[33m0:01:57 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m 134/287   \u001b[33m0:01:57 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m 135/287   \u001b[33m0:01:58 •   \u001b[0m \u001b[31m1.10it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m 135/287   \u001b[33m0:01:58 •   \u001b[0m \u001b[31m1.10it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m 136/287   \u001b[33m0:01:58 •   \u001b[0m \u001b[31m1.11it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m 136/287   \u001b[33m0:01:58 •   \u001b[0m \u001b[31m1.11it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m 137/287   \u001b[33m0:01:59 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m 137/287   \u001b[33m0:01:59 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m 138/287   \u001b[33m0:02:00 •   \u001b[0m \u001b[31m1.11it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m 138/287   \u001b[33m0:02:00 •   \u001b[0m \u001b[31m1.11it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m 139/287   \u001b[33m0:02:01 •   \u001b[0m \u001b[31m1.08it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m 139/287   \u001b[33m0:02:01 •   \u001b[0m \u001b[31m1.08it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m 140/287   \u001b[33m0:02:02 •   \u001b[0m \u001b[31m1.10it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m 140/287   \u001b[33m0:02:02 •   \u001b[0m \u001b[31m1.10it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m 141/287   \u001b[33m0:02:02 •   \u001b[0m \u001b[31m1.11it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m 141/287   \u001b[33m0:02:02 •   \u001b[0m \u001b[31m1.11it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m 142/287   \u001b[33m0:02:03 •   \u001b[0m \u001b[31m1.11it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m 142/287   \u001b[33m0:02:03 •   \u001b[0m \u001b[31m1.11it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m 143/287   \u001b[33m0:02:04 •   \u001b[0m \u001b[31m1.14it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m 143/287   \u001b[33m0:02:04 •   \u001b[0m \u001b[31m1.14it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m 144/287   \u001b[33m0:02:04 •   \u001b[0m \u001b[31m1.15it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m 144/287   \u001b[33m0:02:04 •   \u001b[0m \u001b[31m1.15it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m 145/287   \u001b[33m0:02:05 •   \u001b[0m \u001b[31m1.15it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m 145/287   \u001b[33m0:02:05 •   \u001b[0m \u001b[31m1.15it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m 146/287   \u001b[33m0:02:06 •   \u001b[0m \u001b[31m1.16it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m 146/287   \u001b[33m0:02:06 •   \u001b[0m \u001b[31m1.16it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m 147/287   \u001b[33m0:02:07 •   \u001b[0m \u001b[31m1.16it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m 147/287   \u001b[33m0:02:07 •   \u001b[0m \u001b[31m1.16it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m 148/287   \u001b[33m0:02:09 •   \u001b[0m \u001b[31m1.15it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m 148/287   \u001b[33m0:02:09 •   \u001b[0m \u001b[31m1.15it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m 149/287   \u001b[33m0:02:10 •   \u001b[0m \u001b[31m1.15it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m 149/287   \u001b[33m0:02:10 •   \u001b[0m \u001b[31m1.15it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m 150/287   \u001b[33m0:02:10 •   \u001b[0m \u001b[31m1.15it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m 150/287   \u001b[33m0:02:10 •   \u001b[0m \u001b[31m1.15it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m 151/287   \u001b[33m0:02:11 •   \u001b[0m \u001b[31m1.13it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m 151/287   \u001b[33m0:02:11 •   \u001b[0m \u001b[31m1.13it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m 152/287   \u001b[33m0:02:12 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m 152/287   \u001b[33m0:02:12 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m 153/287   \u001b[33m0:02:13 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m 153/287   \u001b[33m0:02:13 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m 154/287   \u001b[33m0:02:14 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m 154/287   \u001b[33m0:02:14 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m 155/287   \u001b[33m0:02:15 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m 155/287   \u001b[33m0:02:15 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m 156/287   \u001b[33m0:02:16 •   \u001b[0m \u001b[31m1.11it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m 156/287   \u001b[33m0:02:16 •   \u001b[0m \u001b[31m1.11it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m 157/287   \u001b[33m0:02:17 •   \u001b[0m \u001b[31m1.09it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m 157/287   \u001b[33m0:02:17 •   \u001b[0m \u001b[31m1.09it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m 158/287   \u001b[33m0:02:18 •   \u001b[0m \u001b[31m1.13it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m 158/287   \u001b[33m0:02:18 •   \u001b[0m \u001b[31m1.13it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m 159/287   \u001b[33m0:02:19 •   \u001b[0m \u001b[31m1.13it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m 159/287   \u001b[33m0:02:19 •   \u001b[0m \u001b[31m1.13it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m 160/287   \u001b[33m0:02:20 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m 160/287   \u001b[33m0:02:20 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m 161/287   \u001b[33m0:02:21 •   \u001b[0m \u001b[31m1.10it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m 161/287   \u001b[33m0:02:21 •   \u001b[0m \u001b[31m1.10it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m 162/287   \u001b[33m0:02:23 •   \u001b[0m \u001b[31m1.08it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m 162/287   \u001b[33m0:02:23 •   \u001b[0m \u001b[31m1.08it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m 163/287   \u001b[33m0:02:24 •   \u001b[0m \u001b[31m1.08it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m 163/287   \u001b[33m0:02:24 •   \u001b[0m \u001b[31m1.08it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m 164/287   \u001b[33m0:02:25 •   \u001b[0m \u001b[31m1.08it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m 164/287   \u001b[33m0:02:25 •   \u001b[0m \u001b[31m1.08it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m 165/287   \u001b[33m0:02:26 •   \u001b[0m \u001b[31m1.08it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m 165/287   \u001b[33m0:02:26 •   \u001b[0m \u001b[31m1.08it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m 166/287   \u001b[33m0:02:26 •   \u001b[0m \u001b[31m1.08it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m 166/287   \u001b[33m0:02:26 •   \u001b[0m \u001b[31m1.08it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m 167/287   \u001b[33m0:02:27 •   \u001b[0m \u001b[31m1.08it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m 167/287   \u001b[33m0:02:27 •   \u001b[0m \u001b[31m1.08it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m 168/287   \u001b[33m0:02:28 •   \u001b[0m \u001b[31m1.09it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m 168/287   \u001b[33m0:02:28 •   \u001b[0m \u001b[31m1.09it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m 169/287   \u001b[33m0:02:29 •   \u001b[0m \u001b[31m1.08it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m 169/287   \u001b[33m0:02:29 •   \u001b[0m \u001b[31m1.08it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m 170/287   \u001b[33m0:02:30 •   \u001b[0m \u001b[31m1.08it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m 170/287   \u001b[33m0:02:30 •   \u001b[0m \u001b[31m1.08it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m 171/287   \u001b[33m0:02:30 •   \u001b[0m \u001b[31m1.08it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m 171/287   \u001b[33m0:02:30 •   \u001b[0m \u001b[31m1.08it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m 172/287   \u001b[33m0:02:31 •   \u001b[0m \u001b[31m1.08it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m 172/287   \u001b[33m0:02:31 •   \u001b[0m \u001b[31m1.08it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m 173/287   \u001b[33m0:02:32 •   \u001b[0m \u001b[31m1.08it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m 173/287   \u001b[33m0:02:32 •   \u001b[0m \u001b[31m1.08it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m 174/287   \u001b[33m0:02:33 •   \u001b[0m \u001b[31m1.08it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m 174/287   \u001b[33m0:02:33 •   \u001b[0m \u001b[31m1.08it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m 175/287   \u001b[33m0:02:35 •   \u001b[0m \u001b[31m1.01it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m 175/287   \u001b[33m0:02:35 •   \u001b[0m \u001b[31m1.01it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m 176/287   \u001b[33m0:02:36 •   \u001b[0m \u001b[31m1.00it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m 176/287   \u001b[33m0:02:36 •   \u001b[0m \u001b[31m1.00it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m 177/287   \u001b[33m0:02:37 •   \u001b[0m \u001b[31m1.02it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m 177/287   \u001b[33m0:02:37 •   \u001b[0m \u001b[31m1.02it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m 178/287   \u001b[33m0:02:38 •   \u001b[0m \u001b[31m1.03it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m 178/287   \u001b[33m0:02:38 •   \u001b[0m \u001b[31m1.03it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m 179/287   \u001b[33m0:02:39 •   \u001b[0m \u001b[31m1.01it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m 179/287   \u001b[33m0:02:39 •   \u001b[0m \u001b[31m1.01it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m 180/287   \u001b[33m0:02:40 •   \u001b[0m \u001b[31m1.00it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m 180/287   \u001b[33m0:02:40 •   \u001b[0m \u001b[31m1.00it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m 181/287   \u001b[33m0:02:41 •   \u001b[0m \u001b[31m1.01it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m 181/287   \u001b[33m0:02:41 •   \u001b[0m \u001b[31m1.01it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m 182/287   \u001b[33m0:02:43 •   \u001b[0m \u001b[31m0.98it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m 182/287   \u001b[33m0:02:43 •   \u001b[0m \u001b[31m0.98it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m 183/287   \u001b[33m0:02:43 •   \u001b[0m \u001b[31m0.99it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m 183/287   \u001b[33m0:02:43 •   \u001b[0m \u001b[31m0.99it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m 184/287   \u001b[33m0:02:45 •   \u001b[0m \u001b[31m0.97it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m 184/287   \u001b[33m0:02:45 •   \u001b[0m \u001b[31m0.97it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m 185/287   \u001b[33m0:02:45 •   \u001b[0m \u001b[31m0.98it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m 185/287   \u001b[33m0:02:45 •   \u001b[0m \u001b[31m0.98it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m 186/287   \u001b[33m0:02:46 •   \u001b[0m \u001b[31m0.98it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m 186/287   \u001b[33m0:02:46 •   \u001b[0m \u001b[31m0.98it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m 187/287   \u001b[33m0:02:47 •   \u001b[0m \u001b[31m0.98it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m 187/287   \u001b[33m0:02:47 •   \u001b[0m \u001b[31m0.98it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m 188/287   \u001b[33m0:02:48 •   \u001b[0m \u001b[31m0.98it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m 188/287   \u001b[33m0:02:48 •   \u001b[0m \u001b[31m0.98it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m 189/287   \u001b[33m0:02:49 •   \u001b[0m \u001b[31m0.99it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m 189/287   \u001b[33m0:02:49 •   \u001b[0m \u001b[31m0.99it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m 190/287   \u001b[33m0:02:50 •   \u001b[0m \u001b[31m1.00it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m 190/287   \u001b[33m0:02:50 •   \u001b[0m \u001b[31m1.00it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m 191/287   \u001b[33m0:02:51 •   \u001b[0m \u001b[31m1.02it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m 191/287   \u001b[33m0:02:51 •   \u001b[0m \u001b[31m1.02it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m 192/287   \u001b[33m0:02:51 •   \u001b[0m \u001b[31m1.05it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m 192/287   \u001b[33m0:02:51 •   \u001b[0m \u001b[31m1.05it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m 193/287   \u001b[33m0:02:52 •   \u001b[0m \u001b[31m1.06it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m 193/287   \u001b[33m0:02:52 •   \u001b[0m \u001b[31m1.06it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m 194/287   \u001b[33m0:02:53 •   \u001b[0m \u001b[31m1.05it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m 194/287   \u001b[33m0:02:53 •   \u001b[0m \u001b[31m1.05it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m 195/287   \u001b[33m0:02:55 •   \u001b[0m \u001b[31m1.03it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m 195/287   \u001b[33m0:02:55 •   \u001b[0m \u001b[31m1.03it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m 196/287   \u001b[33m0:02:55 •   \u001b[0m \u001b[31m1.05it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m 196/287   \u001b[33m0:02:55 •   \u001b[0m \u001b[31m1.05it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m 197/287   \u001b[33m0:02:55 •   \u001b[0m \u001b[31m1.07it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m 197/287   \u001b[33m0:02:55 •   \u001b[0m \u001b[31m1.07it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m 198/287   \u001b[33m0:02:56 •   \u001b[0m \u001b[31m1.07it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m 198/287   \u001b[33m0:02:56 •   \u001b[0m \u001b[31m1.07it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m 199/287   \u001b[33m0:02:57 •   \u001b[0m \u001b[31m1.07it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m 199/287   \u001b[33m0:02:57 •   \u001b[0m \u001b[31m1.07it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m 200/287   \u001b[33m0:02:58 •   \u001b[0m \u001b[31m1.05it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m 200/287   \u001b[33m0:02:58 •   \u001b[0m \u001b[31m1.05it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m 201/287   \u001b[33m0:02:59 •   \u001b[0m \u001b[31m1.07it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m 201/287   \u001b[33m0:02:59 •   \u001b[0m \u001b[31m1.07it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m 202/287   \u001b[33m0:03:00 •   \u001b[0m \u001b[31m1.06it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m 202/287   \u001b[33m0:03:00 •   \u001b[0m \u001b[31m1.06it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m 203/287   \u001b[33m0:03:00 •   \u001b[0m \u001b[31m1.06it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m 203/287   \u001b[33m0:03:00 •   \u001b[0m \u001b[31m1.06it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m 204/287   \u001b[33m0:03:02 •   \u001b[0m \u001b[31m1.05it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m 204/287   \u001b[33m0:03:02 •   \u001b[0m \u001b[31m1.05it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m 205/287   \u001b[33m0:03:03 •   \u001b[0m \u001b[31m1.03it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m 205/287   \u001b[33m0:03:03 •   \u001b[0m \u001b[31m1.03it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m 206/287   \u001b[33m0:03:04 •   \u001b[0m \u001b[31m1.06it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m 206/287   \u001b[33m0:03:04 •   \u001b[0m \u001b[31m1.06it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m 207/287   \u001b[33m0:03:05 •   \u001b[0m \u001b[31m1.08it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m 207/287   \u001b[33m0:03:05 •   \u001b[0m \u001b[31m1.08it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m 208/287   \u001b[33m0:03:06 •   \u001b[0m \u001b[31m1.08it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m 208/287   \u001b[33m0:03:06 •   \u001b[0m \u001b[31m1.08it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m 209/287   \u001b[33m0:03:06 •   \u001b[0m \u001b[31m1.10it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m 209/287   \u001b[33m0:03:06 •   \u001b[0m \u001b[31m1.10it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m 210/287   \u001b[33m0:03:07 •   \u001b[0m \u001b[31m1.10it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m 210/287   \u001b[33m0:03:07 •   \u001b[0m \u001b[31m1.10it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m 211/287   \u001b[33m0:03:08 •   \u001b[0m \u001b[31m1.10it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m 211/287   \u001b[33m0:03:08 •   \u001b[0m \u001b[31m1.10it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m 212/287   \u001b[33m0:03:09 •   \u001b[0m \u001b[31m1.11it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m 212/287   \u001b[33m0:03:09 •   \u001b[0m \u001b[31m1.11it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m 213/287   \u001b[33m0:03:10 •   \u001b[0m \u001b[31m1.09it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m 213/287   \u001b[33m0:03:10 •   \u001b[0m \u001b[31m1.09it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m 214/287   \u001b[33m0:03:11 •   \u001b[0m \u001b[31m1.11it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m 214/287   \u001b[33m0:03:11 •   \u001b[0m \u001b[31m1.11it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m 215/287   \u001b[33m0:03:12 •   \u001b[0m \u001b[31m1.11it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m 215/287   \u001b[33m0:03:12 •   \u001b[0m \u001b[31m1.11it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m 216/287   \u001b[33m0:03:13 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m 216/287   \u001b[33m0:03:13 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m 217/287   \u001b[33m0:03:14 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m 217/287   \u001b[33m0:03:14 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m 218/287   \u001b[33m0:03:15 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m 218/287   \u001b[33m0:03:15 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m 219/287   \u001b[33m0:03:16 •   \u001b[0m \u001b[31m1.10it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m 219/287   \u001b[33m0:03:16 •   \u001b[0m \u001b[31m1.10it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m 220/287   \u001b[33m0:03:17 •   \u001b[0m \u001b[31m1.11it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m 220/287   \u001b[33m0:03:17 •   \u001b[0m \u001b[31m1.11it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m 221/287   \u001b[33m0:03:18 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m 221/287   \u001b[33m0:03:18 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m 222/287   \u001b[33m0:03:18 •   \u001b[0m \u001b[31m1.13it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m 222/287   \u001b[33m0:03:18 •   \u001b[0m \u001b[31m1.13it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m 223/287   \u001b[33m0:03:19 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m 223/287   \u001b[33m0:03:19 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m 224/287   \u001b[33m0:03:20 •   \u001b[0m \u001b[31m1.13it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m 224/287   \u001b[33m0:03:20 •   \u001b[0m \u001b[31m1.13it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m 225/287   \u001b[33m0:03:21 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m 225/287   \u001b[33m0:03:21 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m 226/287   \u001b[33m0:03:22 •   \u001b[0m \u001b[31m1.11it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m 226/287   \u001b[33m0:03:22 •   \u001b[0m \u001b[31m1.11it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m 227/287   \u001b[33m0:03:23 •   \u001b[0m \u001b[31m1.13it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m 227/287   \u001b[33m0:03:23 •   \u001b[0m \u001b[31m1.13it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m 228/287   \u001b[33m0:03:23 •   \u001b[0m \u001b[31m1.15it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m 228/287   \u001b[33m0:03:23 •   \u001b[0m \u001b[31m1.15it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m 229/287   \u001b[33m0:03:24 •   \u001b[0m \u001b[31m1.15it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m 229/287   \u001b[33m0:03:24 •   \u001b[0m \u001b[31m1.15it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m 230/287   \u001b[33m0:03:25 •   \u001b[0m \u001b[31m1.09it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m 230/287   \u001b[33m0:03:25 •   \u001b[0m \u001b[31m1.09it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m 231/287   \u001b[33m0:03:27 •   \u001b[0m \u001b[31m1.07it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m 231/287   \u001b[33m0:03:27 •   \u001b[0m \u001b[31m1.07it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m 232/287   \u001b[33m0:03:28 •   \u001b[0m \u001b[31m1.04it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m 232/287   \u001b[33m0:03:28 •   \u001b[0m \u001b[31m1.04it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m 233/287   \u001b[33m0:03:29 •   \u001b[0m \u001b[31m1.07it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m 233/287   \u001b[33m0:03:29 •   \u001b[0m \u001b[31m1.07it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m 234/287   \u001b[33m0:03:29 •   \u001b[0m \u001b[31m1.08it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m 234/287   \u001b[33m0:03:29 •   \u001b[0m \u001b[31m1.08it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m 235/287   \u001b[33m0:03:30 •   \u001b[0m \u001b[31m1.08it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m 235/287   \u001b[33m0:03:30 •   \u001b[0m \u001b[31m1.08it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m 236/287   \u001b[33m0:03:31 •   \u001b[0m \u001b[31m1.09it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m 236/287   \u001b[33m0:03:31 •   \u001b[0m \u001b[31m1.09it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m 237/287   \u001b[33m0:03:32 •   \u001b[0m \u001b[31m1.10it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m 237/287   \u001b[33m0:03:32 •   \u001b[0m \u001b[31m1.10it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m 238/287   \u001b[33m0:03:32 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m 238/287   \u001b[33m0:03:32 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m 239/287   \u001b[33m0:03:33 •   \u001b[0m \u001b[31m1.13it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m 239/287   \u001b[33m0:03:33 •   \u001b[0m \u001b[31m1.13it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m 240/287   \u001b[33m0:03:34 •   \u001b[0m \u001b[31m1.14it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m 240/287   \u001b[33m0:03:34 •   \u001b[0m \u001b[31m1.14it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m 241/287   \u001b[33m0:03:35 •   \u001b[0m \u001b[31m1.14it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m 241/287   \u001b[33m0:03:35 •   \u001b[0m \u001b[31m1.14it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m 242/287   \u001b[33m0:03:36 •   \u001b[0m \u001b[31m1.10it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m 242/287   \u001b[33m0:03:36 •   \u001b[0m \u001b[31m1.10it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m 243/287   \u001b[33m0:03:37 •   \u001b[0m \u001b[31m1.11it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m 243/287   \u001b[33m0:03:37 •   \u001b[0m \u001b[31m1.11it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m 244/287   \u001b[33m0:03:38 •   \u001b[0m \u001b[31m1.11it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m 244/287   \u001b[33m0:03:38 •   \u001b[0m \u001b[31m1.11it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m 245/287   \u001b[33m0:03:39 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m 245/287   \u001b[33m0:03:39 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m 246/287   \u001b[33m0:03:40 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m 246/287   \u001b[33m0:03:40 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m 247/287   \u001b[33m0:03:41 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m 247/287   \u001b[33m0:03:41 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m 248/287   \u001b[33m0:03:42 •   \u001b[0m \u001b[31m1.13it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m 248/287   \u001b[33m0:03:42 •   \u001b[0m \u001b[31m1.13it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m 249/287   \u001b[33m0:03:42 •   \u001b[0m \u001b[31m1.15it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m 249/287   \u001b[33m0:03:42 •   \u001b[0m \u001b[31m1.15it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m 250/287   \u001b[33m0:03:43 •   \u001b[0m \u001b[31m1.15it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m 250/287   \u001b[33m0:03:43 •   \u001b[0m \u001b[31m1.15it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m 251/287   \u001b[33m0:03:43 •   \u001b[0m \u001b[31m1.16it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m 251/287   \u001b[33m0:03:43 •   \u001b[0m \u001b[31m1.16it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m 252/287   \u001b[33m0:03:44 •   \u001b[0m \u001b[31m1.16it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m 252/287   \u001b[33m0:03:44 •   \u001b[0m \u001b[31m1.16it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m 253/287   \u001b[33m0:03:45 •   \u001b[0m \u001b[31m1.18it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m 253/287   \u001b[33m0:03:45 •   \u001b[0m \u001b[31m1.18it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m 254/287   \u001b[33m0:03:46 •   \u001b[0m \u001b[31m1.18it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m 254/287   \u001b[33m0:03:46 •   \u001b[0m \u001b[31m1.18it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m 255/287   \u001b[33m0:03:47 •   \u001b[0m \u001b[31m1.14it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m 255/287   \u001b[33m0:03:47 •   \u001b[0m \u001b[31m1.14it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m 256/287   \u001b[33m0:03:48 •   \u001b[0m \u001b[31m1.14it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m 256/287   \u001b[33m0:03:48 •   \u001b[0m \u001b[31m1.14it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m 257/287   \u001b[33m0:03:49 •   \u001b[0m \u001b[31m1.15it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m 257/287   \u001b[33m0:03:49 •   \u001b[0m \u001b[31m1.15it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m 258/287   \u001b[33m0:03:50 •   \u001b[0m \u001b[31m1.14it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m 258/287   \u001b[33m0:03:50 •   \u001b[0m \u001b[31m1.14it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m 259/287   \u001b[33m0:03:50 •   \u001b[0m \u001b[31m1.16it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m 259/287   \u001b[33m0:03:50 •   \u001b[0m \u001b[31m1.16it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m 260/287   \u001b[33m0:03:52 •   \u001b[0m \u001b[31m1.15it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m 260/287   \u001b[33m0:03:52 •   \u001b[0m \u001b[31m1.15it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m 261/287   \u001b[33m0:03:52 •   \u001b[0m \u001b[31m1.15it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m 261/287   \u001b[33m0:03:52 •   \u001b[0m \u001b[31m1.15it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m 262/287   \u001b[33m0:03:53 •   \u001b[0m \u001b[31m1.15it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m 262/287   \u001b[33m0:03:53 •   \u001b[0m \u001b[31m1.15it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m 263/287   \u001b[33m0:03:54 •   \u001b[0m \u001b[31m1.16it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m 263/287   \u001b[33m0:03:54 •   \u001b[0m \u001b[31m1.16it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m 264/287   \u001b[33m0:03:55 •   \u001b[0m \u001b[31m1.17it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m 264/287   \u001b[33m0:03:55 •   \u001b[0m \u001b[31m1.17it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m 265/287   \u001b[33m0:03:55 •   \u001b[0m \u001b[31m1.19it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m 265/287   \u001b[33m0:03:55 •   \u001b[0m \u001b[31m1.19it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m 266/287   \u001b[33m0:03:57 •   \u001b[0m \u001b[31m1.19it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m 266/287   \u001b[33m0:03:57 •   \u001b[0m \u001b[31m1.19it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m 267/287   \u001b[33m0:03:58 •   \u001b[0m \u001b[31m1.20it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m 267/287   \u001b[33m0:03:58 •   \u001b[0m \u001b[31m1.20it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m 268/287   \u001b[33m0:03:59 •   \u001b[0m \u001b[31m1.18it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m 268/287   \u001b[33m0:03:59 •   \u001b[0m \u001b[31m1.18it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m 269/287   \u001b[33m0:03:59 •   \u001b[0m \u001b[31m1.18it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m 269/287   \u001b[33m0:03:59 •   \u001b[0m \u001b[31m1.18it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m 270/287   \u001b[33m0:04:00 •   \u001b[0m \u001b[31m1.18it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m 270/287   \u001b[33m0:04:00 •   \u001b[0m \u001b[31m1.18it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m 271/287   \u001b[33m0:04:00 •   \u001b[0m \u001b[31m1.18it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m 271/287   \u001b[33m0:04:00 •   \u001b[0m \u001b[31m1.18it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m 272/287   \u001b[33m0:04:01 •   \u001b[0m \u001b[31m1.17it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m 272/287   \u001b[33m0:04:02 •   \u001b[0m \u001b[31m1.17it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m 273/287   \u001b[33m0:04:02 •   \u001b[0m \u001b[31m1.17it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m 273/287   \u001b[33m0:04:02 •   \u001b[0m \u001b[31m1.17it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m 274/287   \u001b[33m0:04:03 •   \u001b[0m \u001b[31m1.17it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m 274/287   \u001b[33m0:04:03 •   \u001b[0m \u001b[31m1.17it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m 275/287   \u001b[33m0:04:04 •   \u001b[0m \u001b[31m1.16it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m 275/287   \u001b[33m0:04:04 •   \u001b[0m \u001b[31m1.16it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m 276/287   \u001b[33m0:04:05 •   \u001b[0m \u001b[31m1.17it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m 276/287   \u001b[33m0:04:05 •   \u001b[0m \u001b[31m1.17it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m 277/287   \u001b[33m0:04:06 •   \u001b[0m \u001b[31m1.17it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m 277/287   \u001b[33m0:04:06 •   \u001b[0m \u001b[31m1.17it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m 278/287   \u001b[33m0:04:07 •   \u001b[0m \u001b[31m1.17it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m 278/287   \u001b[33m0:04:07 •   \u001b[0m \u001b[31m1.17it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m 279/287   \u001b[33m0:04:08 •   \u001b[0m \u001b[31m1.19it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m 279/287   \u001b[33m0:04:08 •   \u001b[0m \u001b[31m1.19it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m 280/287   \u001b[33m0:04:08 •   \u001b[0m \u001b[31m1.19it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m 280/287   \u001b[33m0:04:08 •   \u001b[0m \u001b[31m1.19it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m 281/287   \u001b[33m0:04:10 •   \u001b[0m \u001b[31m1.18it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m 281/287   \u001b[33m0:04:10 •   \u001b[0m \u001b[31m1.18it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m 282/287   \u001b[33m0:04:11 •   \u001b[0m \u001b[31m1.17it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m 282/287   \u001b[33m0:04:11 •   \u001b[0m \u001b[31m1.17it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m 283/287   \u001b[33m0:04:11 •   \u001b[0m \u001b[31m1.18it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m 283/287   \u001b[33m0:04:11 •   \u001b[0m \u001b[31m1.18it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m 284/287   \u001b[33m0:04:12 •   \u001b[0m \u001b[31m1.15it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m 284/287   \u001b[33m0:04:12 •   \u001b[0m \u001b[31m1.15it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m 285/287   \u001b[33m0:04:14 •   \u001b[0m \u001b[31m1.11it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m 285/287   \u001b[33m0:04:14 •   \u001b[0m \u001b[31m1.11it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m 286/287   \u001b[33m0:04:15 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m 286/287   \u001b[33m0:04:15 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[90m━━━━━━━━━━━\u001b[0m 287/287   \u001b[33m0:04:15 •   \u001b[0m \u001b[31m1.14it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.754                   \n",
            "Validation \u001b[90m━━━━━━━━━━━\u001b[0m 287/287   \u001b[33m0:04:15 •   \u001b[0m \u001b[31m1.14it/s\u001b[0m             early_stoppi…\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      9/10 0.91089 \n",
            "                                                       val_accura…              \n",
            "                                                       0.902                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.729                    \n",
            "                                                       train_loss…              \n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2Kstage 24/∞ \u001b[90m━━━━━━━━━━━\u001b[0m 2582/2582 \u001b[33m0:39:22 •   \u001b[0m \u001b[31m1.12it/s\u001b[0m train_loss… early_stoppi…\n",
            "                                 \u001b[33m0:00:00     \u001b[0m          12.030      10/10 0.91089\n",
            "                                                       val_accura…              \n",
            "                                                       0.907                    \n",
            "                                                       val_word_a…              \n",
            "                                                       0.739                    \n",
            "                                                       train_loss…              \n",
            "                                                       80.706                   \n",
            "\u001b[?25hMoving best model bentham_kraken_14.mlmodel (0.9108925461769104) to bentham_kraken_best.mlmodel\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!ketos -d cuda:0 train \\\n",
        "  --output bentham_kraken \\\n",
        "  --batch-size 4 \\\n",
        "  --epochs 10 \\\n",
        "  /content/kraken_bentham/lines/*.png\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OtrjGpdLojU7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtrjGpdLojU7",
        "outputId": "1de993d6-83f0-4e0c-b9b8-909b75975657"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root root  16M Dec  7 16:54 bentham_kraken_0.mlmodel\n",
            "-rw-r--r-- 1 root root  16M Dec  8 00:10 bentham_kraken_10.mlmodel\n",
            "-rw-r--r-- 1 root root  16M Dec  8 00:54 bentham_kraken_11.mlmodel\n",
            "-rw-r--r-- 1 root root  16M Dec  8 01:38 bentham_kraken_12.mlmodel\n",
            "-rw-r--r-- 1 root root  16M Dec  8 02:21 bentham_kraken_13.mlmodel\n",
            "-rw-r--r-- 1 root root  16M Dec  8 03:05 bentham_kraken_14.mlmodel\n",
            "-rw-r--r-- 1 root root  16M Dec  8 03:49 bentham_kraken_15.mlmodel\n",
            "-rw-r--r-- 1 root root  16M Dec  8 04:32 bentham_kraken_16.mlmodel\n",
            "-rw-r--r-- 1 root root  16M Dec  8 05:16 bentham_kraken_17.mlmodel\n",
            "-rw-r--r-- 1 root root  16M Dec  8 06:00 bentham_kraken_18.mlmodel\n",
            "-rw-r--r-- 1 root root  16M Dec  8 06:43 bentham_kraken_19.mlmodel\n",
            "-rw-r--r-- 1 root root  16M Dec  7 17:38 bentham_kraken_1.mlmodel\n",
            "-rw-r--r-- 1 root root  16M Dec  8 07:27 bentham_kraken_20.mlmodel\n",
            "-rw-r--r-- 1 root root  16M Dec  8 08:11 bentham_kraken_21.mlmodel\n",
            "-rw-r--r-- 1 root root  16M Dec  8 08:54 bentham_kraken_22.mlmodel\n",
            "-rw-r--r-- 1 root root  16M Dec  8 09:38 bentham_kraken_23.mlmodel\n",
            "-rw-r--r-- 1 root root  16M Dec  8 10:22 bentham_kraken_24.mlmodel\n",
            "-rw-r--r-- 1 root root  16M Dec  7 18:21 bentham_kraken_2.mlmodel\n",
            "-rw-r--r-- 1 root root  16M Dec  7 19:05 bentham_kraken_3.mlmodel\n",
            "-rw-r--r-- 1 root root  16M Dec  7 19:49 bentham_kraken_4.mlmodel\n",
            "-rw-r--r-- 1 root root  16M Dec  7 20:32 bentham_kraken_5.mlmodel\n",
            "-rw-r--r-- 1 root root  16M Dec  7 21:16 bentham_kraken_6.mlmodel\n",
            "-rw-r--r-- 1 root root  16M Dec  7 22:00 bentham_kraken_7.mlmodel\n",
            "-rw-r--r-- 1 root root  16M Dec  7 22:43 bentham_kraken_8.mlmodel\n",
            "-rw-r--r-- 1 root root  16M Dec  7 23:27 bentham_kraken_9.mlmodel\n",
            "-rw-r--r-- 1 root root  16M Dec  8 10:22 bentham_kraken_best.mlmodel\n"
          ]
        }
      ],
      "source": [
        "ls -lh | grep bentham_kraken\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ROL5A9NwgGCr",
      "metadata": {
        "id": "ROL5A9NwgGCr"
      },
      "outputs": [],
      "source": [
        "!cp /content/bentham_kraken_best.mlmodel /content/drive/MyDrive/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bA-uqeHDgvwS",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "bA-uqeHDgvwS",
        "outputId": "92bdcdac-81f4-4590-ab58-5c65dc366afd"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_8a51a0b8-962f-4f22-b1fc-ff0e6dd773c6\", \"bentham_kraken_best.mlmodel\", 16110753)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download('/content/bentham_kraken_best.mlmodel')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hfvhMGAtlX6c",
      "metadata": {
        "id": "hfvhMGAtlX6c"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DdcK_F3apoTZ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DdcK_F3apoTZ",
        "outputId": "7d8d576e-8de5-44e7-be80-a079b87f71d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-08 10:50:41.424396: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-08 10:50:41.442702: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1765191041.464614  303974 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1765191041.471339  303974 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1765191041.488003  303974 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765191041.488032  303974 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765191041.488035  303974 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765191041.488037  303974 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-08 10:50:41.492712: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Loading model bentham_kraken_21.mlmodel\t\u001b[0m\u001b[32m✓\u001b[0m\n",
            "Evaluating bentham_kraken_21.mlmodel\u001b[0m\n",
            "\u001b[2KEvaluating \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[35m11473/11473\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:45:06\u001b[0m\n",
            "\u001b[?25h=== report  ===\n",
            "\n",
            "530692\tCharacters\n",
            "41689\tErrors\n",
            "92.14%\tCharacter Accuracy\n",
            "92.23%\tCharacter Accuracy (Case-insensitive)\n",
            "77.16%\tWord Accuracy\n",
            "\n",
            "20229\tInsertions\n",
            "4674\tDeletions\n",
            "16786\tSubstitutions\n",
            "\n",
            "Count\tMissed\t%Right\n",
            "415018\t26478\t93.62%\tLatin\n",
            "115674\t10537\t90.89%\tCommon\n",
            "\n",
            "Errors\tCorrect-Generated\n",
            "4705\t{ SPACE } - {  }\n",
            "1912\t{ e } - {  }\n",
            "1492\t{  } - { SPACE }\n",
            "1271\t{ s } - {  }\n",
            "1199\t{ r } - {  }\n",
            "805\t{ o } - {  }\n",
            "796\t{ c } - {  }\n",
            "774\t{ t } - {  }\n",
            "720\t{ i } - {  }\n",
            "649\t{ a } - {  }\n",
            "541\t{ l } - { t }\n",
            "538\t{ n } - {  }\n",
            "531\t{ l } - {  }\n",
            "474\t{ . } - {  }\n",
            "404\t{ - } - {  }\n",
            "400\t{ r } - { n }\n",
            "398\t{ u } - {  }\n",
            "358\t{ e } - { i }\n",
            "358\t{ , } - {  }\n",
            "348\t{ e } - { o }\n",
            "346\t{ d } - {  }\n",
            "337\t{ a } - { o }\n",
            "334\t{  } - { i }\n",
            "308\t{  } - { e }\n",
            "305\t{ n } - { r }\n",
            "297\t{ s } - { r }\n",
            "288\t{  } - { r }\n",
            "284\t{ a } - { e }\n",
            "272\t{ : } - {  }\n",
            "263\t{ &#34; } - {  }\n",
            "249\t{ h } - {  }\n",
            "246\t{ o } - { e }\n",
            "245\t{  } - { t }\n",
            "225\t{ f } - {  }\n",
            "218\t{ c } - { e }\n",
            "217\t{ u } - { i }\n",
            "212\t{ m } - { n }\n",
            "210\t{  } - { s }\n",
            "203\t{ _ } - {  }\n",
            "198\t{ v } - {  }\n",
            "185\t{  } - { o }\n",
            "179\t{  } - { . }\n",
            "169\t{ u } - { n }\n",
            "167\t{ g } - {  }\n",
            "166\t{  } - { , }\n",
            "163\t{ b } - { t }\n",
            "161\t{  } - { n }\n",
            "160\t{ b } - {  }\n",
            "154\t{ y } - {  }\n",
            "141\t{ m } - {  }\n",
            "138\t{ i } - { e }\n",
            "137\t{ e } - { c }\n",
            "136\t{ p } - {  }\n",
            "133\t{ u } - { e }\n",
            "133\t{ ( } - {  }\n",
            "132\t{ n } - { m }\n",
            "127\t{ r } - { s }\n",
            "126\t{ - } - { SPACE }\n",
            "123\t{ s } - { n }\n",
            "122\t{ w } - {  }\n",
            "114\t{ a } - { u }\n",
            "113\t{ d } - { t }\n",
            "111\t{ ; } - { , }\n",
            "110\t{  } - { c }\n",
            "109\t{ a } - { i }\n",
            "108\t{ e } - { a }\n",
            "105\t{ s } - { t }\n",
            "103\t{ e } - { u }\n",
            "102\t{ I } - {  }\n",
            "102\t{ ) } - {  }\n",
            "99\t{ s } - { o }\n",
            "98\t{  } - { h }\n",
            "98\t{ t } - { s }\n",
            "91\t{ t } - { l }\n",
            "89\t{ o } - { a }\n",
            "86\t{ 1 } - {  }\n",
            "83\t{ o } - { s }\n",
            "78\t{ t } - { h }\n",
            "78\t{ o } - { i }\n",
            "75\t{ 0 } - {  }\n",
            "75\t{ : } - { . }\n",
            "74\t{ k } - { h }\n",
            "73\t{ T } - {  }\n",
            "73\t{  } - { a }\n",
            "72\t{ [ } - {  }\n",
            "72\t{ v } - { n }\n",
            "72\t{  } - { &#34; }\n",
            "70\t{ ] } - {  }\n",
            "70\t{ = } - {  }\n",
            "69\t{ i } - { o }\n",
            "69\t{ u } - { a }\n",
            "69\t{ &#39; } - {  }\n",
            "69\t{ f } - { p }\n",
            "68\t{ h } - { t }\n",
            "67\t{ a } - { n }\n",
            "67\t{ SPACE } - { = }\n",
            "65\t{  } - { u }\n",
            "64\t{ v } - { r }\n",
            "62\t{ c } - { s }\n",
            "62\t{ l } - { h }\n",
            "61\t{ A } - {  }\n",
            "61\t{ k } - { t }\n",
            "61\t{ SPACE } - { e }\n",
            "61\t{ e } - { s }\n",
            "61\t{  } - { : }\n",
            "60\t{ x } - {  }\n",
            "59\t{ b } - { l }\n",
            "59\t{ SPACE } - { . }\n",
            "58\t{ o } - { r }\n",
            "58\t{ b } - { h }\n",
            "57\t{ l } - { e }\n",
            "57\t{ s } - { v }\n",
            "57\t{ d } - { s }\n",
            "57\t{ s } - { f }\n",
            "56\t{ e } - { n }\n",
            "56\t{ / } - {  }\n",
            "56\t{ &gt; } - {  }\n",
            "56\t{  } - { - }\n",
            "55\t{ S } - {  }\n",
            "52\t{  } - { v }\n",
            "52\t{ 2 } - {  }\n",
            "50\t{ u } - { r }\n",
            "49\t{ e } - { r }\n",
            "49\t{ r } - { m }\n",
            "48\t{ SPACE } - { t }\n",
            "48\t{ - } - { = }\n",
            "46\t{ . } - { , }\n",
            "46\t{ e } - { SPACE }\n",
            "46\t{ s } - { e }\n",
            "46\t{  } - { f }\n",
            "44\t{ r } - { t }\n",
            "44\t{ s } - { d }\n",
            "44\t{ c } - { i }\n",
            "43\t{ o } - { n }\n",
            "43\t{ g } - { y }\n",
            "43\t{ = } - { : }\n",
            "42\t{ c } - { t }\n",
            "42\t{ r } - { i }\n",
            "42\t{ s } - { w }\n",
            "41\t{ c } - { r }\n",
            "41\t{ s } - { c }\n",
            "40\t{ ; } - {  }\n",
            "40\t{ s } - { SPACE }\n",
            "40\t{ 4 } - {  }\n",
            "40\t{ a } - { t }\n",
            "40\t{  } - { l }\n",
            "40\t{  } - { _ }\n",
            "39\t{ SPACE } - { r }\n",
            "39\t{ e } - { t }\n",
            "39\t{ 3 } - {  }\n",
            "39\t{ a } - { r }\n",
            "38\t{ x } - { r }\n",
            "38\t{ C } - {  }\n",
            "38\t{ SPACE } - { i }\n",
            "38\t{ i } - { u }\n",
            "37\t{ x } - { n }\n",
            "37\t{ n } - { s }\n",
            "37\t{ n } - { e }\n",
            "37\t{ r } - { u }\n",
            "37\t{ T } - { t }\n",
            "36\t{ c } - { a }\n",
            "36\t{ q } - { g }\n",
            "36\t{ r } - { e }\n",
            "36\t{  } - { d }\n",
            "36\t{ r } - { v }\n",
            "35\t{ l } - { b }\n",
            "35\t{ SPACE } - { s }\n",
            "35\t{ r } - { o }\n",
            "35\t{ u } - { o }\n",
            "35\t{ 0 } - { 8 }\n",
            "34\t{ u } - { m }\n",
            "34\t{  } - { g }\n",
            "34\t{ t } - { b }\n",
            "34\t{ p } - { f }\n",
            "34\t{ F } - {  }\n",
            "33\t{ . } - { SPACE }\n",
            "33\t{ w } - { n }\n",
            "33\t{ 4 } - { 1 }\n",
            "33\t{ &lt; } - {  }\n",
            "32\t{ O } - {  }\n",
            "32\t{ 5 } - {  }\n",
            "32\t{ SPACE } - { o }\n",
            "32\t{ s } - { p }\n",
            "32\t{ F } - { T }\n",
            "31\t{ k } - {  }\n",
            "31\t{ t } - { d }\n",
            "31\t{ y } - { g }\n",
            "31\t{ s } - { S }\n",
            "31\t{ &#39; } - { &#34; }\n",
            "30\t{ o } - { t }\n",
            "30\t{ i } - { t }\n",
            "30\t{ c } - { n }\n",
            "30\t{ s } - { i }\n",
            "29\t{ P } - {  }\n",
            "29\t{ v } - { s }\n",
            "28\t{ t } - { r }\n",
            "28\t{ v } - { o }\n",
            "28\t{ u } - { w }\n",
            "28\t{ v } - { w }\n",
            "28\t{ : } - { ; }\n",
            "28\t{ w } - { u }\n",
            "27\t{ D } - {  }\n",
            "27\t{ x } - { a }\n",
            "27\t{ p } - { t }\n",
            "27\t{ r } - { SPACE }\n",
            "27\t{  } - { w }\n",
            "27\t{ SPACE } - { n }\n",
            "27\t{  } - { = }\n",
            "27\t{ B } - {  }\n",
            "27\t{ SPACE } - { f }\n",
            "27\t{ w } - { v }\n",
            "27\t{ + } - {  }\n",
            "26\t{ o } - { u }\n",
            "26\t{ c } - { o }\n",
            "26\t{  } - { y }\n",
            "26\t{ f } - { t }\n",
            "26\t{ SPACE } - { h }\n",
            "26\t{ N } - {  }\n",
            "26\t{ | } - {  }\n",
            "25\t{ E } - {  }\n",
            "25\t{ g } - { p }\n",
            "25\t{ t } - { f }\n",
            "25\t{ r } - { h }\n",
            "25\t{ 9 } - {  }\n",
            "25\t{ a } - { c }\n",
            "25\t{ c } - { C }\n",
            "25\t{ L } - { l }\n",
            "24\t{ 8 } - {  }\n",
            "24\t{ i } - { r }\n",
            "24\t{ m } - { r }\n",
            "24\t{  } - { m }\n",
            "24\t{ e } - { l }\n",
            "24\t{ C } - { b }\n",
            "23\t{ i } - { n }\n",
            "23\t{ a } - { s }\n",
            "23\t{ n } - { i }\n",
            "23\t{ - } - { : }\n",
            "23\t{ : } - { , }\n",
            "23\t{ - } - { . }\n",
            "23\t{ P } - { p }\n",
            "22\t{ i } - { SPACE }\n",
            "22\t{ s } - { a }\n",
            "22\t{ o } - { SPACE }\n",
            "22\t{ r } - { a }\n",
            "22\t{ &amp; } - {  }\n",
            "21\t{ d } - { e }\n",
            "21\t{ t } - { i }\n",
            "21\t{ 2 } - { 1 }\n",
            "21\t{ e } - { w }\n",
            "21\t{ u } - { v }\n",
            "21\t{ 7 } - {  }\n",
            "21\t{ r } - { w }\n",
            "21\t{ p } - { h }\n",
            "21\t{ 3 } - { 2 }\n",
            "21\t{ S } - { s }\n",
            "20\t{ M } - {  }\n",
            "20\t{ L } - {  }\n",
            "20\t{  } - { p }\n",
            "20\t{ l } - { f }\n",
            "20\t{ s } - { m }\n",
            "20\t{ E } - { C }\n",
            "20\t{ x } - { s }\n",
            "20\t{ c } - { v }\n",
            "20\t{ S } - { T }\n",
            "19\t{ n } - { a }\n",
            "19\t{ e } - { h }\n",
            "19\t{ i } - { a }\n",
            "19\t{ o } - { w }\n",
            "19\t{  } - { 1 }\n",
            "19\t{ i } - { s }\n",
            "19\t{ f } - { s }\n",
            "18\t{ O } - { o }\n",
            "18\t{ t } - { n }\n",
            "18\t{ n } - { u }\n",
            "18\t{ d } - { l }\n",
            "18\t{ a } - { SPACE }\n",
            "18\t{ l } - { d }\n",
            "18\t{ SPACE } - { a }\n",
            "18\t{ w } - { e }\n",
            "18\t{ t } - { e }\n",
            "18\t{ l } - { i }\n",
            "18\t{ u } - { t }\n",
            "18\t{ o } - { O }\n",
            "18\t{ h } - { k }\n",
            "18\t{ ? } - {  }\n",
            "17\t{ x } - { v }\n",
            "17\t{ , } - { . }\n",
            "17\t{ o } - { m }\n",
            "17\t{ T } - { S }\n",
            "17\t{ c } - { SPACE }\n",
            "17\t{  } - { b }\n",
            "17\t{ c } - { u }\n",
            "17\t{ a } - { h }\n",
            "17\t{ s } - { y }\n",
            "17\t{ R } - {  }\n",
            "17\t{ z } - { n }\n",
            "17\t{ H } - {  }\n",
            "17\t{ t } - { c }\n",
            "16\t{ e } - { d }\n",
            "16\t{ h } - { b }\n",
            "16\t{ r } - { c }\n",
            "16\t{ w } - { s }\n",
            "16\t{ w } - { i }\n",
            "16\t{ p } - { g }\n",
            "16\t{ u } - { c }\n",
            "16\t{ q } - {  }\n",
            "16\t{ n } - { SPACE }\n",
            "16\t{ h } - { i }\n",
            "16\t{ M } - { m }\n",
            "16\t{ z } - { g }\n",
            "16\t{ d } - { b }\n",
            "16\t{ F } - { P }\n",
            "15\t{ 6 } - {  }\n",
            "15\t{ d } - { o }\n",
            "15\t{ h } - { l }\n",
            "15\t{ w } - { r }\n",
            "15\t{ p } - { s }\n",
            "15\t{ s } - { h }\n",
            "15\t{ c } - { l }\n",
            "15\t{ t } - { SPACE }\n",
            "15\t{ e } - { g }\n",
            "15\t{ l } - { n }\n",
            "15\t{ m } - { e }\n",
            "15\t{ d } - { D }\n",
            "15\t{ m } - { i }\n",
            "15\t{ V } - {  }\n",
            "15\t{ e } - { m }\n",
            "15\t{  } - { ) }\n",
            "15\t{ 1 } - { t }\n",
            "15\t{ g } - { G }\n",
            "15\t{ , } - { ; }\n",
            "15\t{ y } - { s }\n",
            "15\t{ H } - { W }\n",
            "14\t{ n } - { w }\n",
            "14\t{ n } - { t }\n",
            "14\t{ w } - { a }\n",
            "14\t{ h } - { e }\n",
            "14\t{ b } - { i }\n",
            "14\t{ &amp; } - { t }\n",
            "14\t{ d } - { n }\n",
            "14\t{ l } - { o }\n",
            "14\t{ J } - {  }\n",
            "14\t{ s } - { g }\n",
            "14\t{ v } - { c }\n",
            "14\t{ j } - {  }\n",
            "14\t{ ; } - { SPACE }\n",
            "14\t{ l } - { SPACE }\n",
            "14\t{ z } - {  }\n",
            "14\t{ a } - { A }\n",
            "14\t{ 5 } - { 1 }\n",
            "14\t{ W } - {  }\n",
            "14\t{ - } - { &#34; }\n",
            "13\t{ . } - { t }\n",
            "13\t{ n } - { o }\n",
            "13\t{ I } - { 2 }\n",
            "13\t{ n } - { v }\n",
            "13\t{ a } - { d }\n",
            "13\t{ e } - { y }\n",
            "13\t{ 3 } - { 8 }\n",
            "13\t{ y } - { SPACE }\n",
            "13\t{  } - { ; }\n",
            "13\t{ I } - { 1 }\n",
            "13\t{ ] } - { ) }\n",
            "13\t{ SPACE } - { l }\n",
            "13\t{ = } - { SPACE }\n",
            "13\t{ &#34; } - { SPACE }\n",
            "13\t{ 0 } - { 5 }\n",
            "12\t{ t } - { W }\n",
            "12\t{ p } - { r }\n",
            "12\t{ SPACE } - { ) }\n",
            "12\t{ p } - { o }\n",
            "12\t{ i } - { h }\n",
            "12\t{ J } - { p }\n",
            "12\t{ SPACE } - { g }\n",
            "12\t{ J } - { S }\n",
            "12\t{ c } - { w }\n",
            "12\t{ z } - { r }\n",
            "12\t{ : } - { SPACE }\n",
            "12\t{ 5 } - { 3 }\n",
            "12\t{ q } - { p }\n",
            "12\t{ g } - { s }\n",
            "12\t{ 5 } - { 8 }\n",
            "12\t{  } - { A }\n",
            "12\t{ o } - { v }\n",
            "12\t{ SPACE } - { , }\n",
            "12\t{ # } - {  }\n",
            "12\t{  } - { ? }\n",
            "11\t{ p } - { n }\n",
            "11\t{ S } - { t }\n",
            "11\t{ a } - { w }\n",
            "11\t{ c } - { d }\n",
            "11\t{ U } - {  }\n",
            "11\t{ b } - { C }\n",
            "11\t{ d } - { c }\n",
            "11\t{ SPACE } - { c }\n",
            "11\t{ , } - { o }\n",
            "11\t{ y } - { n }\n",
            "11\t{ SPACE } - { 1 }\n",
            "11\t{ w } - { m }\n",
            "11\t{ r } - { g }\n",
            "11\t{ P } - { S }\n",
            "11\t{ v } - { u }\n",
            "11\t{ D } - { B }\n",
            "11\t{ w } - { o }\n",
            "11\t{ d } - { a }\n",
            "11\t{ &#34; } - { : }\n",
            "10\t{ F } - { S }\n",
            "10\t{ t } - { p }\n",
            "10\t{ r } - { d }\n",
            "10\t{ m } - { o }\n",
            "10\t{ u } - { SPACE }\n",
            "10\t{ l } - { s }\n",
            "10\t{ m } - { t }\n",
            "10\t{ o } - { h }\n",
            "10\t{ o } - { g }\n",
            "10\t{ g } - { e }\n",
            "10\t{ w } - { t }\n",
            "10\t{ I } - { S }\n",
            "10\t{ S } - { I }\n",
            "10\t{ i } - { c }\n",
            "10\t{ C } - { l }\n",
            "10\t{ , } - { SPACE }\n",
            "10\t{ . } - { : }\n",
            "10\t{ L } - { S }\n",
            "10\t{ t } - { k }\n",
            "10\t{ R } - { P }\n",
            "10\t{ - } - { _ }\n",
            "10\t{ ! } - {  }\n",
            "9\t{ 8 } - { 3 }\n",
            "9\t{ h } - { SPACE }\n",
            "9\t{ h } - { o }\n",
            "9\t{ P } - { T }\n",
            "9\t{ c } - { m }\n",
            "9\t{ n } - { h }\n",
            "9\t{ v } - { i }\n",
            "9\t{ v } - { d }\n",
            "9\t{ s } - { u }\n",
            "9\t{ m } - { u }\n",
            "9\t{ l } - { c }\n",
            "9\t{ g } - { t }\n",
            "9\t{ SPACE } - { u }\n",
            "9\t{ 7 } - { 1 }\n",
            "9\t{ o } - { c }\n",
            "9\t{ I } - { SPACE }\n",
            "9\t{ 3 } - { 5 }\n",
            "9\t{ . } - { ? }\n",
            "9\t{ 5 } - { 6 }\n",
            "9\t{ E } - { l }\n",
            "9\t{ k } - { l }\n",
            "9\t{ W } - { w }\n",
            "9\t{ 8 } - { 0 }\n",
            "9\t{ 2 } - { 8 }\n",
            "8\t{ u } - { h }\n",
            "8\t{ i } - { y }\n",
            "8\t{ v } - { a }\n",
            "8\t{ 2 } - { 3 }\n",
            "8\t{ p } - { i }\n",
            "8\t{ r } - { l }\n",
            "8\t{ . } - { e }\n",
            "8\t{ SPACE } - { - }\n",
            "8\t{ f } - { e }\n",
            "8\t{ f } - { SPACE }\n",
            "8\t{ y } - { r }\n",
            "8\t{ - } - { e }\n",
            "8\t{ C } - { f }\n",
            "8\t{ v } - { m }\n",
            "8\t{ y } - { e }\n",
            "8\t{ d } - { i }\n",
            "8\t{ SPACE } - { m }\n",
            "8\t{ h } - { n }\n",
            "8\t{ A } - { a }\n",
            "8\t{ P } - { B }\n",
            "8\t{  } - { I }\n",
            "8\t{ a } - { x }\n",
            "8\t{ / } - { e }\n",
            "8\t{ t } - { T }\n",
            "8\t{ x } - { o }\n",
            "8\t{ : } - { = }\n",
            "8\t{ d } - { r }\n",
            "8\t{ B } - { W }\n",
            "8\t{ l } - { C }\n",
            "8\t{ _ } - { . }\n",
            "7\t{ h } - { r }\n",
            "7\t{ u } - { s }\n",
            "7\t{ e } - { v }\n",
            "7\t{ n } - { c }\n",
            "7\t{ s } - { , }\n",
            "7\t{ m } - { v }\n",
            "7\t{ SPACE } - { d }\n",
            "7\t{ H } - { P }\n",
            "7\t{ o } - { . }\n",
            "7\t{ n } - { y }\n",
            "7\t{ e } - { . }\n",
            "7\t{ A } - { t }\n",
            "7\t{ I } - { h }\n",
            "7\t{ V } - { t }\n",
            "7\t{ a } - { v }\n",
            "7\t{ &amp; } - { o }\n",
            "7\t{ . } - { o }\n",
            "7\t{ p } - { e }\n",
            "7\t{ v } - { t }\n",
            "7\t{ j } - { J }\n",
            "7\t{ o } - { &amp; }\n",
            "7\t{ x } - { e }\n",
            "7\t{ i } - { l }\n",
            "7\t{  } - { ( }\n",
            "7\t{ g } - { SPACE }\n",
            "7\t{ y } - { , }\n",
            "7\t{ F } - { t }\n",
            "7\t{ = } - { . }\n",
            "7\t{ g } - { o }\n",
            "7\t{ h } - { p }\n",
            "7\t{ G } - {  }\n",
            "7\t{ S } - { f }\n",
            "7\t{ y } - { i }\n",
            "7\t{ SPACE } - { 3 }\n",
            "7\t{ - } - { s }\n",
            "7\t{ s } - { l }\n",
            "7\t{ £ } - {  }\n",
            "7\t{ SPACE } - { T }\n",
            "7\t{ 9 } - { 7 }\n",
            "7\t{  } - { W }\n",
            "7\t{ M } - { t }\n",
            "7\t{ R } - { S }\n",
            "7\t{  } - { £ }\n",
            "6\t{ b } - { d }\n",
            "6\t{ i } - { f }\n",
            "6\t{ P } - { W }\n",
            "6\t{ H } - { t }\n",
            "6\t{ g } - { f }\n",
            "6\t{ G } - { C }\n",
            "6\t{ : } - { o }\n",
            "6\t{ r } - { p }\n",
            "6\t{ 1 } - { SPACE }\n",
            "6\t{ . } - { 1 }\n",
            "6\t{ r } - { y }\n",
            "6\t{ b } - { p }\n",
            "6\t{ b } - { o }\n",
            "6\t{  } - { 2 }\n",
            "6\t{ u } - { d }\n",
            "6\t{ e } - { f }\n",
            "6\t{ t } - { . }\n",
            "6\t{ A } - { I }\n",
            "6\t{ b } - { e }\n",
            "6\t{ b } - { a }\n",
            "6\t{ SPACE } - { y }\n",
            "6\t{ o } - { d }\n",
            "6\t{ f } - { h }\n",
            "6\t{ p } - { u }\n",
            "6\t{ g } - { u }\n",
            "6\t{ d } - { SPACE }\n",
            "6\t{ p } - { y }\n",
            "6\t{ S } - { H }\n",
            "6\t{ 4 } - { 6 }\n",
            "6\t{ N } - { M }\n",
            "6\t{ y } - { Y }\n",
            "6\t{ A } - { B }\n",
            "6\t{ a } - { g }\n",
            "6\t{ ) } - { ( }\n",
            "6\t{ / } - { t }\n",
            "6\t{ A } - { SPACE }\n",
            "6\t{ s } - { x }\n",
            "6\t{ SPACE } - { 7 }\n",
            "6\t{ K } - {  }\n",
            "6\t{ v } - { SPACE }\n",
            "6\t{ w } - { W }\n",
            "6\t{ W } - { t }\n",
            "6\t{ V } - { 1 }\n",
            "6\t{ SPACE } - { ; }\n",
            "6\t{ H } - { S }\n",
            "6\t{ h } - { f }\n",
            "6\t{ R } - { H }\n",
            "6\t{ a } - { b }\n",
            "6\t{ B } - { A }\n",
            "6\t{ T } - { F }\n",
            "6\t{ M } - { h }\n",
            "6\t{ SPACE } - { ? }\n",
            "6\t{ e } - { E }\n",
            "6\t{ ? } - { . }\n",
            "6\t{  } - { &#39; }\n",
            "6\t{ m } - { M }\n",
            "6\t{ l } - { L }\n",
            "6\t{ r } - { f }\n",
            "6\t{ &#34; } - { ? }\n",
            "6\t{ y } - { p }\n",
            "5\t{ T } - { h }\n",
            "5\t{ m } - { a }\n",
            "5\t{ m } - { w }\n",
            "5\t{ f } - { i }\n",
            "5\t{ j } - { i }\n",
            "5\t{ p } - { SPACE }\n",
            "5\t{ r } - { . }\n",
            "5\t{ p } - { a }\n",
            "5\t{ P } - { H }\n",
            "5\t{ x } - { c }\n",
            "5\t{ m } - { c }\n",
            "5\t{ b } - { f }\n",
            "5\t{ X } - {  }\n",
            "5\t{ , } - { e }\n",
            "5\t{ 3 } - { 1 }\n",
            "5\t{ l } - { a }\n",
            "5\t{ w } - { c }\n",
            "5\t{ v } - { e }\n",
            "5\t{ m } - { s }\n",
            "5\t{ SPACE } - { p }\n",
            "5\t{ S } - { h }\n",
            "5\t{ , } - { i }\n",
            "5\t{ 1 } - { 7 }\n",
            "5\t{ e } - { - }\n",
            "5\t{ j } - { g }\n",
            "5\t{ S } - { b }\n",
            "5\t{ 6 } - { 8 }\n",
            "5\t{ J } - { I }\n",
            "5\t{ SPACE } - { 2 }\n",
            "5\t{ V } - { W }\n",
            "5\t{ SPACE } - { B }\n",
            "5\t{ ( } - { SPACE }\n",
            "5\t{  } - { T }\n",
            "5\t{ D } - { E }\n",
            "5\t{ S } - { o }\n",
            "5\t{ b } - { SPACE }\n",
            "5\t{ &gt; } - { e }\n",
            "5\t{ SPACE } - { : }\n",
            "5\t{ SPACE } - { S }\n",
            "5\t{ &amp; } - { 1 }\n",
            "5\t{ SPACE } - { 8 }\n",
            "5\t{ R } - { A }\n",
            "5\t{ 8 } - { 5 }\n",
            "5\t{ o } - { b }\n",
            "5\t{ a } - { l }\n",
            "5\t{ o } - { l }\n",
            "5\t{ e } - { p }\n",
            "5\t{ l } - { r }\n",
            "5\t{ = } - { - }\n",
            "5\t{ 2 } - { C }\n",
            "5\t{ s } - { b }\n",
            "5\t{ C } - { G }\n",
            "5\t{ T } - { . }\n",
            "5\t{  } - { S }\n",
            "5\t{ k } - { b }\n",
            "5\t{ b } - { &amp; }\n",
            "5\t{ i } - { m }\n",
            "5\t{ n } - { - }\n",
            "5\t{ L } - { d }\n",
            "5\t{  } - { 7 }\n",
            "5\t{ , } - { t }\n",
            "5\t{ L } - { b }\n",
            "5\t{ V } - { B }\n",
            "5\t{ p } - { P }\n",
            "5\t{ P } - { R }\n",
            "5\t{ d } - { h }\n",
            "5\t{ 0 } - { o }\n",
            "5\t{ 5 } - { 0 }\n",
            "5\t{ _ } - { SPACE }\n",
            "4\t{ D } - { T }\n",
            "4\t{ h } - { s }\n",
            "4\t{ C } - { t }\n",
            "4\t{ S } - { i }\n",
            "4\t{ x } - { d }\n",
            "4\t{ f } - { C }\n",
            "4\t{ N } - { W }\n",
            "4\t{ s } - { . }\n",
            "4\t{ M } - { W }\n",
            "4\t{ x } - { p }\n",
            "4\t{ - } - { n }\n",
            "4\t{ p } - { G }\n",
            "4\t{ y } - { o }\n",
            "4\t{ Q } - {  }\n",
            "4\t{ f } - { u }\n",
            "4\t{ t } - { 1 }\n",
            "4\t{ J } - { f }\n",
            "4\t{ ( } - { 1 }\n",
            "4\t{ § } - {  }\n",
            "4\t{ o } - { p }\n",
            "4\t{ I } - { T }\n",
            "4\t{ b } - { n }\n",
            "4\t{ . } - { 2 }\n",
            "4\t{ . } - { h }\n",
            "4\t{ I } - { i }\n",
            "4\t{ , } - { s }\n",
            "4\t{ j } - { p }\n",
            "4\t{ u } - { l }\n",
            "4\t{ F } - { D }\n",
            "4\t{ SPACE } - { 0 }\n",
            "4\t{ - } - { b }\n",
            "4\t{ F } - { I }\n",
            "4\t{ p } - { 1 }\n",
            "4\t{ i } - { = }\n",
            "4\t{ C } - { B }\n",
            "4\t{ P } - { b }\n",
            "4\t{ &lt; } - { t }\n",
            "4\t{ B } - { SPACE }\n",
            "4\t{ n } - { g }\n",
            "4\t{ h } - { u }\n",
            "4\t{ &lt; } - { l }\n",
            "4\t{ - } - { r }\n",
            "4\t{ E } - { W }\n",
            "4\t{ f } - { F }\n",
            "4\t{ a } - { f }\n",
            "4\t{ f } - { g }\n",
            "4\t{ E } - { G }\n",
            "4\t{ I } - { o }\n",
            "4\t{ 8 } - { 2 }\n",
            "4\t{  } - { &amp; }\n",
            "4\t{ A } - { l }\n",
            "4\t{  } - { O }\n",
            "4\t{ SPACE } - { A }\n",
            "4\t{ O } - { W }\n",
            "4\t{ SPACE } - { ( }\n",
            "4\t{ 6 } - { t }\n",
            "4\t{ ; } - { : }\n",
            "4\t{ f } - { o }\n",
            "4\t{ a } - { m }\n",
            "4\t{ b } - { B }\n",
            "4\t{ 4 } - { t }\n",
            "4\t{ C } - { 6 }\n",
            "4\t{  } - { C }\n",
            "4\t{ 0 } - { 2 }\n",
            "4\t{ d } - { k }\n",
            "4\t{ P } - { C }\n",
            "4\t{ E } - { D }\n",
            "4\t{ . } - { a }\n",
            "4\t{ 2 } - { 0 }\n",
            "4\t{ l } - { E }\n",
            "4\t{ M } - { A }\n",
            "4\t{ i } - { v }\n",
            "4\t{ &amp; } - { I }\n",
            "4\t{ S } - { P }\n",
            "4\t{ O } - { B }\n",
            "4\t{ I } - { P }\n",
            "4\t{ &#34; } - { n }\n",
            "4\t{ U } - { A }\n",
            "4\t{ i } - { d }\n",
            "4\t{ O } - { C }\n",
            "4\t{ 6 } - { 1 }\n",
            "4\t{ 1 } - { 2 }\n",
            "4\t{  } - { 5 }\n",
            "4\t{ 3 } - { 0 }\n",
            "4\t{ 4 } - { 0 }\n",
            "4\t{ ! } - { ? }\n",
            "4\t{ P } - { F }\n",
            "4\t{ * } - {  }\n",
            "3\t{ u } - { y }\n",
            "3\t{ P } - { h }\n",
            "3\t{ t } - { u }\n",
            "3\t{ k } - { c }\n",
            "3\t{ P } - { A }\n",
            "3\t{ t } - { a }\n",
            "3\t{ k } - { d }\n",
            "3\t{ x } - { t }\n",
            "3\t{ f } - { n }\n",
            "3\t{ , } - { : }\n",
            "3\t{ h } - { . }\n",
            "3\t{ . } - { _ }\n",
            "3\t{ 6 } - { 5 }\n",
            "3\t{ P } - { E }\n",
            "3\t{ 5 } - { o }\n",
            "3\t{ d } - { . }\n",
            "3\t{ &#34; } - { s }\n",
            "3\t{ m } - { f }\n",
            "3\t{ &#34; } - { e }\n",
            "3\t{ c } - { p }\n",
            "3\t{ J } - { b }\n",
            "3\t{ f } - { l }\n",
            "3\t{ , } - { h }\n",
            "3\t{ o } - { y }\n",
            "3\t{ x } - { SPACE }\n",
            "3\t{ . } - { u }\n",
            "3\t{ d } - { p }\n",
            "3\t{ J } - { h }\n",
            "3\t{ N } - { T }\n",
            "3\t{ S } - { 1 }\n",
            "3\t{ : } - { i }\n",
            "3\t{ S } - { W }\n",
            "3\t{ c } - { g }\n",
            "3\t{ 2 } - { . }\n",
            "3\t{ e } - { 1 }\n",
            "3\t{ 7 } - { 2 }\n",
            "3\t{ J } - { P }\n",
            "3\t{ C } - { a }\n",
            "3\t{ . } - { i }\n",
            "3\t{ 9 } - { 3 }\n",
            "3\t{ g } - { n }\n",
            "3\t{ p } - { d }\n",
            "3\t{ - } - { h }\n",
            "3\t{ , } - { r }\n",
            "3\t{ T } - { H }\n",
            "3\t{ : } - { n }\n",
            "3\t{ T } - { I }\n",
            "3\t{ A } - { U }\n",
            "3\t{ 1 } - { ( }\n",
            "3\t{ h } - { H }\n",
            "3\t{ ( } - { [ }\n",
            "3\t{ F } - { A }\n",
            "3\t{ SPACE } - { k }\n",
            "3\t{ SPACE } - { O }\n",
            "3\t{ F } - { f }\n",
            "3\t{ Y } - { f }\n",
            "3\t{ [ } - { ( }\n",
            "3\t{ S } - { e }\n",
            "3\t{ ) } - { , }\n",
            "3\t{ T } - { P }\n",
            "3\t{ ] } - { SPACE }\n",
            "3\t{ SPACE } - { b }\n",
            "3\t{ n } - { f }\n",
            "3\t{ i } - { w }\n",
            "3\t{ g } - { i }\n",
            "3\t{ : } - { t }\n",
            "3\t{ . } - { I }\n",
            "3\t{ / } - { o }\n",
            "3\t{ V } - { P }\n",
            "3\t{ O } - { b }\n",
            "3\t{ M } - { H }\n",
            "3\t{ a } - { y }\n",
            "3\t{ E } - { A }\n",
            "3\t{ 1 } - { 5 }\n",
            "3\t{ H } - { T }\n",
            "3\t{ W } - { T }\n",
            "3\t{ f } - { S }\n",
            "3\t{ 3 } - { I }\n",
            "3\t{ f } - { r }\n",
            "3\t{ o } - { f }\n",
            "3\t{ n } - { , }\n",
            "3\t{ c } - { x }\n",
            "3\t{ i } - { p }\n",
            "3\t{ / } - { s }\n",
            "3\t{ SPACE } - { _ }\n",
            "3\t{ I } - { H }\n",
            "3\t{ p } - { 7 }\n",
            "3\t{ g } - { q }\n",
            "3\t{ z } - { v }\n",
            "3\t{ N } - { H }\n",
            "3\t{ Y } - {  }\n",
            "3\t{ SPACE } - { w }\n",
            "3\t{ SPACE } - { &#34; }\n",
            "3\t{ n } - { p }\n",
            "3\t{ p } - { l }\n",
            "3\t{ g } - { c }\n",
            "3\t{ E } - { i }\n",
            "3\t{ &#34; } - { t }\n",
            "3\t{ ; } - { . }\n",
            "3\t{ M } - { N }\n",
            "3\t{ a } - { &amp; }\n",
            "3\t{ G } - { f }\n",
            "3\t{ R } - { W }\n",
            "3\t{ R } - { l }\n",
            "3\t{ V } - { 2 }\n",
            "3\t{ R } - { T }\n",
            "3\t{ b } - { s }\n",
            "3\t{ &#39; } - { s }\n",
            "3\t{ E } - { h }\n",
            "3\t{ O } - { n }\n",
            "3\t{ T } - { D }\n",
            "3\t{ w } - { p }\n",
            "3\t{ T } - { s }\n",
            "3\t{ y } - { f }\n",
            "3\t{ 8 } - { C }\n",
            "3\t{ &amp; } - { e }\n",
            "3\t{ S } - { SPACE }\n",
            "3\t{ s } - { T }\n",
            "3\t{ - } - { w }\n",
            "3\t{ L } - { e }\n",
            "3\t{ F } - { N }\n",
            "3\t{ k } - { SPACE }\n",
            "3\t{ x } - { 1 }\n",
            "3\t{ N } - { R }\n",
            "3\t{ t } - { C }\n",
            "3\t{ + } - { &#34; }\n",
            "3\t{ C } - { E }\n",
            "3\t{ l } - { . }\n",
            "3\t{ &#34; } - { i }\n",
            "3\t{ u } - { U }\n",
            "3\t{ ) } - { f }\n",
            "3\t{ d } - { y }\n",
            "3\t{ O } - { A }\n",
            "3\t{ ? } - { SPACE }\n",
            "3\t{ SPACE } - { v }\n",
            "3\t{ A } - { W }\n",
            "3\t{ 2 } - { 7 }\n",
            "3\t{ p } - { j }\n",
            "3\t{ 1 } - { 8 }\n",
            "3\t{ SPACE } - { I }\n",
            "3\t{ i } - { I }\n",
            "3\t{ &#34; } - { ) }\n",
            "3\t{ - } - { l }\n",
            "3\t{ I } - { t }\n",
            "3\t{ B } - { t }\n",
            "3\t{  } - { x }\n",
            "3\t{ 9 } - { 8 }\n",
            "3\t{  } - { 8 }\n",
            "3\t{ 2 } - { t }\n",
            "3\t{ i } - { g }\n",
            "3\t{ , } - { 5 }\n",
            "3\t{ A } - { M }\n",
            "3\t{  } - { k }\n",
            "3\t{ 1 } - { p }\n",
            "3\t{  } - { 0 }\n",
            "3\t{ &#34; } - { . }\n",
            "3\t{ ! } - { . }\n",
            "3\t{ A } - { N }\n",
            "3\t{ x } - { y }\n",
            "2\t{ A } - { E }\n",
            "2\t{ B } - { C }\n",
            "2\t{ V } - { b }\n",
            "2\t{ s } - { J }\n",
            "2\t{ m } - { d }\n",
            "2\t{ &lt; } - { e }\n",
            "2\t{ x } - { q }\n",
            "2\t{ T } - { SPACE }\n",
            "2\t{ a } - { T }\n",
            "2\t{  } - { ] }\n",
            "2\t{ h } - { L }\n",
            "2\t{ q } - { e }\n",
            "2\t{ , } - { m }\n",
            "2\t{ d } - { L }\n",
            "2\t{ T } - { B }\n",
            "2\t{ A } - { i }\n",
            "2\t{ , } - { w }\n",
            "2\t{ f } - { b }\n",
            "2\t{ o } - { - }\n",
            "2\t{ l } - { p }\n",
            "2\t{ 8 } - { . }\n",
            "2\t{ g } - { . }\n",
            "2\t{ t } - { m }\n",
            "2\t{ Q } - { h }\n",
            "2\t{ b } - { u }\n",
            "2\t{ g } - { m }\n",
            "2\t{ g } - { a }\n",
            "2\t{ w } - { - }\n",
            "2\t{ C } - { o }\n",
            "2\t{ O } - { I }\n",
            "2\t{ I } - { e }\n",
            "2\t{ u } - { p }\n",
            "2\t{ Q } - { t }\n",
            "2\t{ Q } - { e }\n",
            "2\t{ A } - { p }\n",
            "2\t{ X } - { e }\n",
            "2\t{ t } - { o }\n",
            "2\t{ ( } - { 2 }\n",
            "2\t{ w } - { h }\n",
            "2\t{ s } - { - }\n",
            "2\t{ N } - { h }\n",
            "2\t{ 3 } - { . }\n",
            "2\t{ m } - { g }\n",
            "2\t{ l } - { u }\n",
            "2\t{ Q } - { A }\n",
            "2\t{ . } - { H }\n",
            "2\t{ y } - { t }\n",
            "2\t{ : } - { a }\n",
            "2\t{ J } - { e }\n",
            "2\t{ - } - { u }\n",
            "2\t{ 5 } - { 2 }\n",
            "2\t{ 6 } - { SPACE }\n",
            "2\t{ d } - { C }\n",
            "2\t{ , } - { a }\n",
            "2\t{ p } - { m }\n",
            "2\t{ P } - { i }\n",
            "2\t{ I } - { u }\n",
            "2\t{ p } - { J }\n",
            "2\t{ C } - { e }\n",
            "2\t{ T } - { u }\n",
            "2\t{ I } - { D }\n",
            "2\t{ &amp; } - { 7 }\n",
            "2\t{ G } - { P }\n",
            "2\t{ S } - { p }\n",
            "2\t{ N } - { n }\n",
            "2\t{ I } - { . }\n",
            "2\t{ I } - { f }\n",
            "2\t{ f } - { a }\n",
            "2\t{ G } - { SPACE }\n",
            "2\t{  } - { E }\n",
            "2\t{ n } - { = }\n",
            "2\t{ &lt; } - { c }\n",
            "2\t{ h } - { C }\n",
            "2\t{ SPACE } - { ] }\n",
            "2\t{ e } - { = }\n",
            "2\t{ SPACE } - { N }\n",
            "2\t{ : } - { - }\n",
            "2\t{ + } - { 7 }\n",
            "2\t{ . } - { 0 }\n",
            "2\t{ SPACE } - { 6 }\n",
            "2\t{ p } - { k }\n",
            "2\t{ c } - { S }\n",
            "2\t{ 4 } - { o }\n",
            "2\t{ F } - { h }\n",
            "2\t{ D } - { d }\n",
            "2\t{ &amp; } - { , }\n",
            "2\t{ l } - { 1 }\n",
            "2\t{ &lt; } - { h }\n",
            "2\t{ H } - { N }\n",
            "2\t{ &gt; } - { r }\n",
            "2\t{ 1 } - { e }\n",
            "2\t{ x } - { i }\n",
            "2\t{ , } - { n }\n",
            "2\t{ P } - { I }\n",
            "2\t{ E } - { B }\n",
            "2\t{ C } - { 2 }\n",
            "2\t{ A } - { n }\n",
            "2\t{ S } - { A }\n",
            "2\t{ F } - { d }\n",
            "2\t{ L } - { a }\n",
            "2\t{ 1 } - { 4 }\n",
            "2\t{ - } - { t }\n",
            "2\t{ X } - { 1 }\n",
            "2\t{ C } - { A }\n",
            "2\t{ 8 } - { 6 }\n",
            "2\t{ l } - { g }\n",
            "2\t{ = } - { e }\n",
            "2\t{ &lt; } - { a }\n",
            "2\t{ p } - { 6 }\n",
            "2\t{ w } - { y }\n",
            "2\t{ &lt; } - { p }\n",
            "2\t{ g } - { r }\n",
            "2\t{ 3 } - { 9 }\n",
            "2\t{ O } - { E }\n",
            "2\t{ r } - { x }\n",
            "2\t{ F } - { L }\n",
            "2\t{ o } - { , }\n",
            "2\t{ d } - { 3 }\n",
            "2\t{ F } - { b }\n",
            "2\t{ &lt; } - { w }\n",
            "2\t{ t } - { y }\n",
            "2\t{ SPACE } - { 5 }\n",
            "2\t{ r } - { = }\n",
            "2\t{ S } - { R }\n",
            "2\t{ &lt; } - { d }\n",
            "2\t{ ) } - { SPACE }\n",
            "2\t{ p } - { v }\n",
            "2\t{ l } - { W }\n",
            "2\t{ &lt; } - { o }\n",
            "2\t{ &gt; } - { d }\n",
            "2\t{ 2 } - { SPACE }\n",
            "2\t{ . } - { O }\n",
            "2\t{ s } - { N }\n",
            "2\t{ A } - { O }\n",
            "2\t{ : } - { &#34; }\n",
            "2\t{ L } - { F }\n",
            "2\t{ 7 } - { SPACE }\n",
            "2\t{ o } - { 2 }\n",
            "2\t{ r } - { 3 }\n",
            "2\t{ : } - { d }\n",
            "2\t{ C } - { P }\n",
            "2\t{ M } - { r }\n",
            "2\t{ p } - { b }\n",
            "2\t{ P } - { l }\n",
            "2\t{ a } - { 2 }\n",
            "2\t{ H } - { I }\n",
            "2\t{ ) } - { t }\n",
            "2\t{ n } - { l }\n",
            "2\t{ x } - { h }\n",
            "2\t{  } - { B }\n",
            "2\t{ o } - { I }\n",
            "2\t{ t } - { = }\n",
            "2\t{ z } - { c }\n",
            "2\t{ S } - { N }\n",
            "2\t{ p } - { , }\n",
            "2\t{ ( } - { f }\n",
            "2\t{ I } - { A }\n",
            "2\t{ P } - { t }\n",
            "2\t{ . } - { W }\n",
            "2\t{ g } - { l }\n",
            "2\t{ d } - { &#39; }\n",
            "2\t{ &amp; } - { b }\n",
            "2\t{ y } - { l }\n",
            "2\t{ z } - { a }\n",
            "2\t{ e } - { 0 }\n",
            "2\t{ H } - { l }\n",
            "2\t{ z } - { SPACE }\n",
            "2\t{ E } - { n }\n",
            "2\t{ O } - { &amp; }\n",
            "2\t{ U } - { t }\n",
            "2\t{ ] } - { d }\n",
            "2\t{ T } - { N }\n",
            "2\t{ . } - { n }\n",
            "2\t{ ] } - { t }\n",
            "2\t{ l } - { k }\n",
            "2\t{ ( } - { C }\n",
            "2\t{ : } - { w }\n",
            "2\t{ m } - { h }\n",
            "2\t{ 4 } - { e }\n",
            "2\t{ &#34; } - { p }\n",
            "2\t{ L } - { f }\n",
            "2\t{ a } - { 1 }\n",
            "2\t{ X } - { SPACE }\n",
            "2\t{ SPACE } - { | }\n",
            "2\t{ I } - { r }\n",
            "2\t{ 5 } - { s }\n",
            "2\t{ L } - { t }\n",
            "2\t{ N } - { S }\n",
            "2\t{ s } - { C }\n",
            "2\t{ T } - { C }\n",
            "2\t{  } - { | }\n",
            "2\t{ # } - { 7 }\n",
            "2\t{ S } - { : }\n",
            "2\t{ # } - { W }\n",
            "2\t{ O } - { T }\n",
            "2\t{ H } - { R }\n",
            "2\t{ . } - { | }\n",
            "2\t{ | } - { ? }\n",
            "2\t{ F } - { H }\n",
            "2\t{ f } - { k }\n",
            "2\t{ s } - { W }\n",
            "2\t{  } - { j }\n",
            "2\t{ F } - { C }\n",
            "2\t{ SPACE } - { C }\n",
            "2\t{ S } - { M }\n",
            "2\t{ E } - { b }\n",
            "2\t{ &#34; } - { &#39; }\n",
            "2\t{ I } - { b }\n",
            "2\t{ &#34; } - { a }\n",
            "2\t{ m } - { N }\n",
            "2\t{ F } - { V }\n",
            "2\t{ D } - { W }\n",
            "2\t{ q } - { SPACE }\n",
            "2\t{ / } - { SPACE }\n",
            "2\t{ &#34; } - { o }\n",
            "2\t{ n } - { b }\n",
            "2\t{ B } - { b }\n",
            "2\t{ b } - { k }\n",
            "2\t{ t } - { H }\n",
            "2\t{ R } - { C }\n",
            "2\t{ d } - { N }\n",
            "2\t{ 0 } - { 9 }\n",
            "2\t{ 1 } - { 6 }\n",
            "2\t{ . } - { s }\n",
            "2\t{ A } - { s }\n",
            "2\t{ s } - { = }\n",
            "2\t{ D } - { P }\n",
            "2\t{ h } - { g }\n",
            "2\t{ k } - { e }\n",
            "2\t{ SPACE } - { L }\n",
            "2\t{ M } - { R }\n",
            "2\t{ L } - { h }\n",
            "2\t{ &#39; } - { f }\n",
            "2\t{ 5 } - { 7 }\n",
            "2\t{ t } - { S }\n",
            "2\t{ 2 } - { 5 }\n",
            "2\t{ 5 } - { 4 }\n",
            "2\t{ - } - { o }\n",
            "2\t{ 2 } - { 9 }\n",
            "2\t{ f } - { &amp; }\n",
            "2\t{ x } - { g }\n",
            "2\t{ H } - { h }\n",
            "2\t{ 0 } - { 1 }\n",
            "2\t{ K } - { t }\n",
            "2\t{ A } - { e }\n",
            "2\t{  } - { 3 }\n",
            "2\t{  } - { 9 }\n",
            "2\t{ C } - { c }\n",
            "2\t{ R } - { E }\n",
            "2\t{ v } - { 1 }\n",
            "2\t{ &#34; } - { u }\n",
            "2\t{ . } - { ) }\n",
            "2\t{ N } - { SPACE }\n",
            "2\t{ q } - { y }\n",
            "2\t{ &amp; } - { N }\n",
            "2\t{ K } - { T }\n",
            "2\t{ E } - { a }\n",
            "2\t{ &#34; } - { - }\n",
            "2\t{ 9 } - { o }\n",
            "2\t{ . } - { P }\n",
            "2\t{ T } - { &#34; }\n",
            "2\t{ 9 } - { . }\n",
            "2\t{  } - { P }\n",
            "2\t{ I } - { &amp; }\n",
            "2\t{ _ } - { &#34; }\n",
            "2\t{ &#39; } - { e }\n",
            "2\t{ g } - { 9 }\n",
            "2\t{ o } - { &#34; }\n",
            "2\t{ &lt; } - { r }\n",
            "2\t{ K } - { k }\n",
            "2\t{ P } - { N }\n",
            "2\t{ &gt; } - { t }\n",
            "2\t{ G } - { p }\n",
            "2\t{ 1 } - { h }\n",
            "2\t{ _ } - { - }\n",
            "2\t{ t } - { g }\n",
            "2\t{ G } - { g }\n",
            "2\t{ 4 } - { h }\n",
            "2\t{ N } - { 1 }\n",
            "2\t{  } - { M }\n",
            "2\t{ D } - { F }\n",
            "2\t{ E } - { e }\n",
            "2\t{ SPACE } - { &amp; }\n",
            "2\t{ 4 } - { 5 }\n",
            "1\t{ 6 } - { O }\n",
            "1\t{ _ } - { k }\n",
            "1\t{ z } - { s }\n",
            "1\t{ t } - { w }\n",
            "1\t{ t } - { v }\n",
            "1\t{ ] } - { S }\n",
            "1\t{ k } - { i }\n",
            "1\t{ d } - { A }\n",
            "1\t{ x } - { f }\n",
            "1\t{ [ } - { 7 }\n",
            "1\t{ ] } - { C }\n",
            "1\t{ ] } - { f }\n",
            "1\t{ T } - { L }\n",
            "1\t{ ] } - { a }\n",
            "1\t{ C } - { 1 }\n",
            "1\t{ I } - { a }\n",
            "1\t{ p } - { q }\n",
            "1\t{ . } - { = }\n",
            "1\t{ H } - { [ }\n",
            "1\t{ ( } - { . }\n",
            "1\t{ 1 } - { O }\n",
            "1\t{ B } - { i }\n",
            "1\t{ a } - { . }\n",
            "1\t{ ; } - { n }\n",
            "1\t{ 5 } - { I }\n",
            "1\t{ W } - { u }\n",
            "1\t{ : } - { s }\n",
            "1\t{ Q } - { D }\n",
            "1\t{ - } - { A }\n",
            "1\t{ i } - { . }\n",
            "1\t{ A } - { T }\n",
            "1\t{ T } - { R }\n",
            "1\t{ Q } - { d }\n",
            "1\t{ . } - { 8 }\n",
            "1\t{ 1 } - { . }\n",
            "1\t{ J } - { i }\n",
            "1\t{ X } - { W }\n",
            "1\t{ G } - { t }\n",
            "1\t{ S } - { 3 }\n",
            "1\t{ J } - { g }\n",
            "1\t{ F } - { [ }\n",
            "1\t{ g } - { v }\n",
            "1\t{ l } - { y }\n",
            "1\t{ a } - { p }\n",
            "1\t{ 3 } - { B }\n",
            "1\t{ 1 } - { &#34; }\n",
            "1\t{ J } - { t }\n",
            "1\t{ r } - { - }\n",
            "1\t{ d } - { Q }\n",
            "1\t{ , } - { = }\n",
            "1\t{ L } - { I }\n",
            "1\t{ e } - { q }\n",
            "1\t{ o } - { T }\n",
            "1\t{ i } - { - }\n",
            "1\t{ b } - { . }\n",
            "1\t{ A } - { . }\n",
            "1\t{ d } - { T }\n",
            "1\t{ c } - { h }\n",
            "1\t{ A } - { P }\n",
            "1\t{ w } - { T }\n",
            "1\t{ &#39; } - { i }\n",
            "1\t{ . } - { f }\n",
            "1\t{ B } - { D }\n",
            "1\t{ 7 } - { 5 }\n",
            "1\t{ C } - { m }\n",
            "1\t{ o } - { = }\n",
            "1\t{ M } - { d }\n",
            "1\t{ 7 } - { . }\n",
            "1\t{ V } - { h }\n",
            "1\t{ ( } - { o }\n",
            "1\t{ ( } - { b }\n",
            "1\t{ u } - { I }\n",
            "1\t{ + } - { i }\n",
            "1\t{ D } - { r }\n",
            "1\t{ E } - { SPACE }\n",
            "1\t{ w } - { g }\n",
            "1\t{ k } - { a }\n",
            "1\t{ = } - { f }\n",
            "1\t{ F } - { SPACE }\n",
            "1\t{ j } - { I }\n",
            "1\t{ : } - { T }\n",
            "1\t{ &lt; } - { f }\n",
            "1\t{ E } - { r }\n",
            "1\t{ u } - { 1 }\n",
            "1\t{ O } - { D }\n",
            "1\t{ S } - { ( }\n",
            "1\t{ I } - { c }\n",
            "1\t{ F } - { n }\n",
            "1\t{ . } - { l }\n",
            "1\t{ ) } - { u }\n",
            "1\t{ D } - { p }\n",
            "1\t{ 7 } - { 6 }\n",
            "1\t{ x } - { w }\n",
            "1\t{ = } - { r }\n",
            "1\t{ SPACE } - { F }\n",
            "1\t{ &lt; } - { s }\n",
            "1\t{ SPACE } - { E }\n",
            "1\t{ t } - { A }\n",
            "1\t{ q } - { t }\n",
            "1\t{ n } - { k }\n",
            "1\t{ E } - { o }\n",
            "1\t{ z } - { f }\n",
            "1\t{ 4 } - { b }\n",
            "1\t{ &lt; } - { v }\n",
            "1\t{ . } - { A }\n",
            "1\t{ s } - { &amp; }\n",
            "1\t{ V } - { H }\n",
            "1\t{ 1 } - { _ }\n",
            "1\t{ 2 } - { X }\n",
            "1\t{ h } - { S }\n",
            "1\t{ / } - { l }\n",
            "1\t{ ; } - { d }\n",
            "1\t{ 1 } - { I }\n",
            "1\t{ : } - { c }\n",
            "1\t{ L } - { w }\n",
            "1\t{ Q } - { I }\n",
            "1\t{ [ } - { : }\n",
            "1\t{ ) } - { A }\n",
            "1\t{ &lt; } - { N }\n",
            "1\t{ &gt; } - { o }\n",
            "1\t{ g } - { = }\n",
            "1\t{ 6 } - { 4 }\n",
            "1\t{ ] } - { , }\n",
            "1\t{ W } - { l }\n",
            "1\t{ 2 } - { 4 }\n",
            "1\t{ n } - { M }\n",
            "1\t{ B } - { E }\n",
            "1\t{ c } - { I }\n",
            "1\t{ W } - { H }\n",
            "1\t{ D } - { R }\n",
            "1\t{ R } - { t }\n",
            "1\t{ b } - { W }\n",
            "1\t{ C } - { r }\n",
            "1\t{ H } - { A }\n",
            "1\t{ - } - { 1 }\n",
            "1\t{ y } - { 7 }\n",
            "1\t{ f } - { = }\n",
            "1\t{ N } - { m }\n",
            "1\t{ T } - { : }\n",
            "1\t{ a } - { O }\n",
            "1\t{ O } - { t }\n",
            "1\t{ t } - { E }\n",
            "1\t{ U } - { D }\n",
            "1\t{ K } - { B }\n",
            "1\t{ I } - { 3 }\n",
            "1\t{ f } - { d }\n",
            "1\t{ d } - { f }\n",
            "1\t{ - } - { i }\n",
            "1\t{ m } - { p }\n",
            "1\t{ c } - { f }\n",
            "1\t{ , } - { f }\n",
            "1\t{ f } - { J }\n",
            "1\t{ i } - { &#39; }\n",
            "1\t{ f } - { . }\n",
            "1\t{ , } - { 7 }\n",
            "1\t{ s } - { 4 }\n",
            "1\t{ S } - { &amp; }\n",
            "1\t{ L } - { £ }\n",
            "1\t{ I } - { 0 }\n",
            "1\t{ c } - { 0 }\n",
            "1\t{ B } - { s }\n",
            "1\t{ n } - { 9 }\n",
            "1\t{ . } - { T }\n",
            "1\t{ T } - { i }\n",
            "1\t{ J } - { L }\n",
            "1\t{ b } - { m }\n",
            "1\t{ W } - { S }\n",
            "1\t{ . } - { ] }\n",
            "1\t{ = } - { , }\n",
            "1\t{ Y } - { F }\n",
            "1\t{ Y } - { a }\n",
            "1\t{ t } - { 5 }\n",
            "1\t{ ] } - { . }\n",
            "1\t{ &lt; } - { n }\n",
            "1\t{ / } - { n }\n",
            "1\t{ ( } - { h }\n",
            "1\t{ = } - { s }\n",
            "1\t{ D } - { h }\n",
            "1\t{ D } - { . }\n",
            "1\t{ f } - { I }\n",
            "1\t{ n } - { d }\n",
            "1\t{ B } - { ) }\n",
            "1\t{ ] } - { o }\n",
            "1\t{ b } - { r }\n",
            "1\t{ &lt; } - { ( }\n",
            "1\t{ &lt; } - { 4 }\n",
            "1\t{ P } - { 5 }\n",
            "1\t{ D } - { f }\n",
            "1\t{ a } - { k }\n",
            "1\t{ / } - { a }\n",
            "1\t{ r } - { j }\n",
            "1\t{ = } - { a }\n",
            "1\t{ V } - { T }\n",
            "1\t{ f } - { W }\n",
            "1\t{ = } - { n }\n",
            "1\t{ = } - { o }\n",
            "1\t{ L } - { o }\n",
            "1\t{ ) } - { 1 }\n",
            "1\t{ v } - { 7 }\n",
            "1\t{ &#34; } - { , }\n",
            "1\t{ + } - { . }\n",
            "1\t{ N } - { a }\n",
            "1\t{  } - { Y }\n",
            "1\t{ T } - { W }\n",
            "1\t{ o } - { E }\n",
            "1\t{ n } - { 7 }\n",
            "1\t{ Q } - { &#34; }\n",
            "1\t{ u } - { E }\n",
            "1\t{ e } - { k }\n",
            "1\t{ Y } - { y }\n",
            "1\t{ C } - { h }\n",
            "1\t{ i } - { , }\n",
            "1\t{ ; } - { i }\n",
            "1\t{ h } - { y }\n",
            "1\t{ R } - { L }\n",
            "1\t{ p } - { - }\n",
            "1\t{ w } - { SPACE }\n",
            "1\t{ : } - { ] }\n",
            "1\t{ , } - { p }\n",
            "1\t{ V } - { 8 }\n",
            "1\t{ b } - { c }\n",
            "1\t{ b } - { ) }\n",
            "1\t{ ) } - { o }\n",
            "1\t{ [ } - { SPACE }\n",
            "1\t{ P } - { L }\n",
            "1\t{ R } - { U }\n",
            "1\t{ u } - { g }\n",
            "1\t{ u } - { = }\n",
            "1\t{ i } - { 1 }\n",
            "1\t{ = } - { t }\n",
            "1\t{ d } - { = }\n",
            "1\t{  } - { [ }\n",
            "1\t{ s } - { F }\n",
            "1\t{ f } - { T }\n",
            "1\t{ &lt; } - { C }\n",
            "1\t{ - } - { m }\n",
            "1\t{ U } - { W }\n",
            "1\t{ : } - { l }\n",
            "1\t{ P } - { n }\n",
            "1\t{ y } - { . }\n",
            "1\t{ z } - { i }\n",
            "1\t{ U } - { i }\n",
            "1\t{ I } - { £ }\n",
            "1\t{ F } - { o }\n",
            "1\t{ ! } - { : }\n",
            "1\t{ n } - { x }\n",
            "1\t{ _ } - { w }\n",
            "1\t{ D } - { ( }\n",
            "1\t{ c } - { = }\n",
            "1\t{ F } - { e }\n",
            "1\t{ ? } - { &amp; }\n",
            "1\t{ X } - { | }\n",
            "1\t{ S } - { 0 }\n",
            "1\t{ J } - { . }\n",
            "1\t{ A } - { b }\n",
            "1\t{ : } - { G }\n",
            "1\t{ V } - { R }\n",
            "1\t{ D } - { SPACE }\n",
            "1\t{ ( } - { D }\n",
            "1\t{ M } - { n }\n",
            "1\t{ o } - { W }\n",
            "1\t{ K } - { R }\n",
            "1\t{ B } - { M }\n",
            "1\t{ F } - { ) }\n",
            "1\t{ ) } - { g }\n",
            "1\t{ G } - { ) }\n",
            "1\t{ H } - { d }\n",
            "1\t{ - } - { v }\n",
            "1\t{ B } - { p }\n",
            "1\t{ ) } - { s }\n",
            "1\t{ d } - { w }\n",
            "1\t{ k } - { m }\n",
            "1\t{ SPACE } - { P }\n",
            "1\t{ p } - { c }\n",
            "1\t{ &gt; } - { i }\n",
            "1\t{ A } - { G }\n",
            "1\t{ E } - { d }\n",
            "1\t{ a } - { C }\n",
            "1\t{ m } - { SPACE }\n",
            "1\t{ T } - { p }\n",
            "1\t{ E } - { u }\n",
            "1\t{ z } - { o }\n",
            "1\t{ F } - { a }\n",
            "1\t{ f } - { O }\n",
            "1\t{ i } - { 9 }\n",
            "1\t{ o } - { 3 }\n",
            "1\t{ K } - { r }\n",
            "1\t{ w } - { b }\n",
            "1\t{ A } - { 7 }\n",
            "1\t{ b } - { P }\n",
            "1\t{ ) } - { ] }\n",
            "1\t{ # } - { t }\n",
            "1\t{ U } - { l }\n",
            "1\t{ 0 } - { t }\n",
            "1\t{ [ } - { f }\n",
            "1\t{ L } - { k }\n",
            "1\t{ F } - { 1 }\n",
            "1\t{ B } - { o }\n",
            "1\t{ ⊥ } - { . }\n",
            "1\t{ r } - { I }\n",
            "1\t{ # } - { A }\n",
            "1\t{ . } - { b }\n",
            "1\t{ n } - { j }\n",
            "1\t{ o } - { q }\n",
            "1\t{ X } - { n }\n",
            "1\t{ Y } - { o }\n",
            "1\t{ 3 } - { t }\n",
            "1\t{ A } - { d }\n",
            "1\t{ s } - { A }\n",
            "1\t{ &#39; } - { h }\n",
            "1\t{ N } - { r }\n",
            "1\t{ : } - { A }\n",
            "1\t{ [ } - { t }\n",
            "1\t{ i } - { &amp; }\n",
            "1\t{ I } - { R }\n",
            "1\t{ o } - { C }\n",
            "1\t{ + } - { 1 }\n",
            "1\t{ W } - { U }\n",
            "1\t{ x } - { u }\n",
            "1\t{ &#34; } - { G }\n",
            "1\t{ H } - { o }\n",
            "1\t{ o } - { 6 }\n",
            "1\t{ &#39; } - { R }\n",
            "1\t{ # } - { I }\n",
            "1\t{ M } - { B }\n",
            "1\t{ H } - { D }\n",
            "1\t{ B } - { c }\n",
            "1\t{ p } - { H }\n",
            "1\t{ M } - { i }\n",
            "1\t{ + } - { # }\n",
            "1\t{ ; } - { e }\n",
            "1\t{ B } - { d }\n",
            "1\t{ T } - { A }\n",
            "1\t{ | } - { [ }\n",
            "1\t{ | } - { SPACE }\n",
            "1\t{ r } - { R }\n",
            "1\t{ Q } - { L }\n",
            "1\t{ T } - { l }\n",
            "1\t{ N } - { B }\n",
            "1\t{ | } - { I }\n",
            "1\t{ r } - { : }\n",
            "1\t{ r } - { S }\n",
            "1\t{ &#34; } - { | }\n",
            "1\t{ T } - { n }\n",
            "1\t{ , } - { ) }\n",
            "1\t{ g } - { C }\n",
            "1\t{ + } - { [ }\n",
            "1\t{ f } - { L }\n",
            "1\t{ W } - { h }\n",
            "1\t{ | } - { + }\n",
            "1\t{ A } - { o }\n",
            "1\t{ Q } - { E }\n",
            "1\t{ a } - { B }\n",
            "1\t{ w } - { A }\n",
            "1\t{ ? } - { l }\n",
            "1\t{ 2 } - { h }\n",
            "1\t{ 3 } - { f }\n",
            "1\t{ | } - { A }\n",
            "1\t{ O } - { Y }\n",
            "1\t{ 8 } - { 4 }\n",
            "1\t{ ) } - { T }\n",
            "1\t{ # } - { ? }\n",
            "1\t{ A } - { S }\n",
            "1\t{ ê } - { i }\n",
            "1\t{ è } - {  }\n",
            "1\t{ à } - { a }\n",
            "1\t{ &#39; } - { t }\n",
            "1\t{ ê } - { e }\n",
            "1\t{ h } - { W }\n",
            "1\t{ , } - { v }\n",
            "1\t{ &amp; } - { O }\n",
            "1\t{ C } - { p }\n",
            "1\t{ g } - { z }\n",
            "1\t{ M } - { e }\n",
            "1\t{ Y } - { p }\n",
            "1\t{ &amp; } - { s }\n",
            "1\t{ q } - { s }\n",
            "1\t{ N } - { i }\n",
            "1\t{ &amp; } - { a }\n",
            "1\t{ h } - { a }\n",
            "1\t{ , } - { b }\n",
            "1\t{ , } - { L }\n",
            "1\t{ q } - { n }\n",
            "1\t{ T } - { &amp; }\n",
            "1\t{ g } - { - }\n",
            "1\t{ 2 } - { N }\n",
            "1\t{ w } - { d }\n",
            "1\t{ , } - { y }\n",
            "1\t{ 2 } - { i }\n",
            "1\t{  } - { L }\n",
            "1\t{ &#34; } - { A }\n",
            "1\t{ SPACE } - { M }\n",
            "1\t{ &#34; } - { h }\n",
            "1\t{ &#34; } - { r }\n",
            "1\t{ L } - { A }\n",
            "1\t{ [ } - { n }\n",
            "1\t{ Y } - { m }\n",
            "1\t{ D } - { l }\n",
            "1\t{ R } - { SPACE }\n",
            "1\t{ O } - { P }\n",
            "1\t{ u } - { f }\n",
            "1\t{ O } - { H }\n",
            "1\t{ &#39; } - { . }\n",
            "1\t{ E } - { . }\n",
            "1\t{ C } - { 8 }\n",
            "1\t{ T } - { 2 }\n",
            "1\t{ I } - { ? }\n",
            "1\t{ O } - { [ }\n",
            "1\t{ ] } - { 7 }\n",
            "1\t{ S } - { D }\n",
            "1\t{ [ } - { o }\n",
            "1\t{ C } - { W }\n",
            "1\t{ I } - { 7 }\n",
            "1\t{ . } - { m }\n",
            "1\t{ S } - { F }\n",
            "1\t{ , } - { A }\n",
            "1\t{ R } - { e }\n",
            "1\t{ &#39; } - { q }\n",
            "1\t{ - } - { [ }\n",
            "1\t{ d } - { - }\n",
            "1\t{ R } - { r }\n",
            "1\t{ v } - { h }\n",
            "1\t{ + } - { I }\n",
            "1\t{ C } - { I }\n",
            "1\t{ . } - { &amp; }\n",
            "1\t{ W } - { d }\n",
            "1\t{ 1 } - { A }\n",
            "1\t{ 3 } - { ) }\n",
            "1\t{ 2 } - { a }\n",
            "1\t{ q } - { m }\n",
            "1\t{ c } - { b }\n",
            "1\t{ e } - { S }\n",
            "1\t{ D } - { A }\n",
            "1\t{ a } - { &#39; }\n",
            "1\t{ C } - { i }\n",
            "1\t{ S } - { d }\n",
            "1\t{ &amp; } - { SPACE }\n",
            "1\t{ &amp; } - { H }\n",
            "1\t{ , } - { 4 }\n",
            "1\t{ 0 } - { 7 }\n",
            "1\t{ y } - { &#34; }\n",
            "1\t{ N } - { t }\n",
            "1\t{ W } - { e }\n",
            "1\t{ 9 } - { 0 }\n",
            "1\t{ t } - { &#39; }\n",
            "1\t{ e } - { b }\n",
            "1\t{ n } - { &amp; }\n",
            "1\t{ C } - { , }\n",
            "1\t{ u } - { L }\n",
            "1\t{ , } - { d }\n",
            "1\t{ 4 } - { 2 }\n",
            "1\t{ r } - { z }\n",
            "1\t{ &amp; } - { ) }\n",
            "1\t{ T } - { O }\n",
            "1\t{ 7 } - { [ }\n",
            "1\t{ v } - { b }\n",
            "1\t{ G } - { b }\n",
            "1\t{ U } - { u }\n",
            "1\t{ P } - { O }\n",
            "1\t{ ] } - { _ }\n",
            "1\t{ : } - { r }\n",
            "1\t{ 3 } - { S }\n",
            "1\t{ s } - { j }\n",
            "1\t{ £ } - { h }\n",
            "1\t{ 6 } - { 2 }\n",
            "1\t{ N } - { A }\n",
            "1\t{ 1 } - { &amp; }\n",
            "1\t{ P } - { s }\n",
            "1\t{ 7 } - { o }\n",
            "1\t{ 7 } - { 9 }\n",
            "1\t{ D } - { 2 }\n",
            "1\t{ 1 } - { ? }\n",
            "1\t{ 1 } - { , }\n",
            "1\t{  } - { N }\n",
            "1\t{ c } - { M }\n",
            "1\t{ a } - { M }\n",
            "1\t{ z } - { t }\n",
            "1\t{ n } - { 1 }\n",
            "1\t{ s } - { P }\n",
            "1\t{ n } - { N }\n",
            "1\t{ £ } - { 5 }\n",
            "1\t{ M } - { D }\n",
            "1\t{ g } - { j }\n",
            "1\t{ 3 } - { o }\n",
            "1\t{ P } - { f }\n",
            "1\t{ 4 } - { , }\n",
            "1\t{ : } - { 3 }\n",
            "1\t{ 5 } - { , }\n",
            "1\t{ b } - { 4 }\n",
            "1\t{ D } - { a }\n",
            "1\t{ , } - { 9 }\n",
            "1\t{ 8 } - { £ }\n",
            "1\t{ , } - { 6 }\n",
            "1\t{ / } - { 6 }\n",
            "1\t{ T } - { M }\n",
            "1\t{ J } - { m }\n",
            "1\t{  } - { R }\n",
            "1\t{ J } - { , }\n",
            "1\t{ R } - { M }\n",
            "1\t{ R } - { h }\n",
            "1\t{ 7 } - { 8 }\n",
            "1\t{ H } - { SPACE }\n",
            "1\t{ E } - { 1 }\n",
            "1\t{ s } - { 7 }\n",
            "1\t{ &amp; } - { . }\n",
            "1\t{ g } - { ) }\n",
            "1\t{ £ } - { 1 }\n",
            "1\t{ E } - { &amp; }\n",
            "1\t{ s } - { E }\n",
            "1\t{ z } - { m }\n",
            "1\t{ P } - { 1 }\n",
            "1\t{  } - { U }\n",
            "1\t{ S } - { J }\n",
            "1\t{ / } - { ( }\n",
            "1\t{ 6 } - { 0 }\n",
            "1\t{ 2 } - { L }\n",
            "1\t{ n } - { S }\n",
            "1\t{ g } - { S }\n",
            "1\t{ h } - { &amp; }\n",
            "1\t{ &lt; } - { i }\n",
            "1\t{ &#34; } - { W }\n",
            "1\t{ ; } - { h }\n",
            "1\t{ p } - { L }\n",
            "1\t{ P } - { e }\n",
            "1\t{ ; } - { u }\n",
            "1\t{ 1 } - { f }\n",
            "1\t{ , } - { 0 }\n",
            "1\t{ w } - { f }\n",
            "1\t{ s } - { &#34; }\n",
            "1\t{ 5 } - { § }\n",
            "1\t{ m } - { l }\n",
            "1\t{ C } - { SPACE }\n",
            "1\t{ K } - { &#34; }\n",
            "1\t{  } - { H }\n",
            "1\t{ k } - { q }\n",
            "1\t{ 9 } - { 2 }\n",
            "1\t{ . } - { &#34; }\n",
            "1\t{ &#34; } - { _ }\n",
            "1\t{ ) } - { e }\n",
            "1\t{ &lt; } - { u }\n",
            "1\t{ 9 } - { r }\n",
            "1\t{ . } - { S }\n",
            "1\t{ z } - { y }\n",
            "1\t{ 8 } - { O }\n",
            "1\t{ 6 } - { C }\n",
            "1\t{ y } - { u }\n",
            "1\t{ P } - { [ }\n",
            "1\t{ v } - { f }\n",
            "1\t{ c } - { E }\n",
            "1\t{ &#34; } - { w }\n",
            "1\t{ N } - { . }\n",
            "1\t{ SPACE } - { J }\n",
            "1\t{ q } - { r }\n",
            "1\t{ n } - { 2 }\n",
            "1\t{ ! } - { SPACE }\n",
            "1\t{ I } - { O }\n",
            "1\t{ M } - { SPACE }\n",
            "1\t{ B } - { N }\n",
            "1\t{ v } - { &amp; }\n",
            "1\t{ v } - { 2 }\n",
            "1\t{ W } - { . }\n",
            "1\t{ E } - { P }\n",
            "1\t{ A } - { 8 }\n",
            "1\t{ 6 } - { b }\n",
            "1\t{ &lt; } - { _ }\n",
            "1\t{ g } - { d }\n",
            "1\t{ t } - { I }\n",
            "1\t{ c } - { 4 }\n",
            "1\t{ 4 } - { SPACE }\n",
            "1\t{ S } - { l }\n",
            "1\t{ / } - { c }\n",
            "1\t{ I } - { W }\n",
            "1\t{ N } - { I }\n",
            "1\t{ / } - { k }\n",
            "1\t{ z } - { : }\n",
            "1\t{ / } - { i }\n",
            "1\t{ &gt; } - { n }\n",
            "1\t{ E } - { t }\n",
            "1\t{ W } - { o }\n",
            "1\t{ § } - { 8 }\n",
            "1\t{ . } - { M }\n",
            "1\t{ i } - { : }\n",
            "1\t{ § } - { 6 }\n",
            "1\t{ _ } - { : }\n",
            "1\t{ K } - { H }\n",
            "1\t{ D } - { O }\n",
            "1\t{ ( } - { , }\n",
            "1\t{ _ } - { , }\n",
            "1\t{ 9 } - { 5 }\n",
            "1\t{ k } - { s }\n",
            "1\t{ C } - { O }\n",
            "1\t{ + } - { ) }\n",
            "1\t{ p } - { &#39; }\n",
            "1\t{  } - { F }\n",
            "1\t{ [ } - { 3 }\n",
            "1\t{ 3 } - { SPACE }\n",
            "1\t{ W } - { G }\n",
            "1\t{ q } - { o }\n",
            "1\t{ b } - { v }\n",
            "1\t{ ? } - { &#34; }\n",
            "1\t{ i } - { 2 }\n",
            "1\t{ J } - { Y }\n",
            "1\t{ s } - { : }\n",
            "1\t{ ) } - { 7 }\n",
            "1\t{ ( } - { t }\n",
            "1\t{ + } - { SPACE }\n",
            "1\t{ s } - { &#39; }\n",
            "1\t{ _ } - { a }\n",
            "1\t{ t } - { G }\n",
            "1\t{ 9 } - { f }\n",
            "1\t{ &amp; } - { d }\n",
            "1\t{ H } - { B }\n",
            "1\t{ SPACE } - { 9 }\n",
            "1\t{ H } - { 1 }\n",
            "1\t{ M } - { . }\n",
            "1\t{  } - { 4 }\n",
            "1\t{ &amp; } - { 2 }\n",
            "1\t{ n } - { W }\n",
            "1\t{ o } - { 5 }\n",
            "1\t{ 2 } - { E }\n",
            "1\t{ k } - { r }\n",
            "1\t{ _ } - { T }\n",
            "1\t{ N } - { 7 }\n",
            "1\t{ I } - { s }\n",
            "1\t{ F } - { § }\n",
            "1\t{ 2 } - { o }\n",
            "1\t{ M } - { I }\n",
            "1\t{ d } - { u }\n",
            "1\t{ o } - { k }\n",
            "1\t{ P } - { D }\n",
            "1\t{ M } - { P }\n",
            "1\t{ , } - { W }\n",
            "1\t{ v } - { k }\n",
            "1\t{ W } - { 1 }\n",
            "1\t{ . } - { C }\n",
            "1\t{ b } - { = }\n",
            "1\t{ : } - { 1 }\n",
            "1\t{ a } - { W }\n",
            "1\t{ 0 } - { SPACE }\n",
            "1\t{ l } - { G }\n",
            "1\t{ d } - { 2 }\n",
            "1\t{ 2 } - { A }\n",
            "1\t{ s } - { _ }\n",
            "1\t{ B } - { , }\n",
            "1\t{ 3 } - { 7 }\n",
            "1\t{ ( } - { a }\n",
            "1\t{ _ } - { h }\n",
            "1\t{ L } - { s }\n",
            "1\t{ f } - { P }\n",
            "1\t{ 8 } - { o }\n",
            "1\t{ 8 } - { 9 }\n",
            "1\t{ * } - { 1 }\n",
            "1\t{ G } - { &#34; }\n",
            "1\t{ 6 } - { o }\n",
            "1\t{ d } - { ? }\n",
            "1\t{ &#34; } - { &amp; }\n",
            "1\t{ n } - { : }\n",
            "1\t{ i } - { D }\n",
            "1\t{ L } - { i }\n",
            "1\t{ o } - { G }\n",
            "1\t{ Y } - { B }\n",
            "1\t{ 6 } - { , }\n",
            "1\t{ G } - { d }\n",
            "1\t{ g } - { , }\n",
            "1\t{ * } - { SPACE }\n",
            "1\t{ B } - { S }\n",
            "1\t{ * } - { I }\n",
            "1\t{ s } - { 1 }\n",
            "1\t{ v } - { &#34; }\n",
            "1\t{ C } - { S }\n",
            "1\t{ é } - {  }\n",
            "1\t{ &amp; } - { i }\n",
            "1\t{ s } - { k }\n",
            "1\t{ k } - { f }\n",
            "1\t{ J } - { j }\n",
            "1\t{ â } - { d }\n",
            "1\t{ ? } - { y }\n",
            "1\t{ r } - { &amp; }\n",
            "1\t{ F } - { B }\n",
            "1\t{ k } - { R }\n",
            "1\t{ £ } - { 2 }\n",
            "1\t{ B } - { P }\n",
            "1\t{ x } - { 0 }\n",
            "1\t{ x } - { , }\n",
            "1\t{ M } - { w }\n",
            "1\t{ 4 } - { W }\n",
            "1\t{ SPACE } - { W }\n",
            "1\t{ a } - { &#34; }\n",
            "1\t{ c } - { . }\n",
            "1\t{ / } - { r }\n",
            "1\t{ m } - { y }\n",
            "1\t{ t } - { P }\n",
            "1\t{ H } - { 6 }\n",
            "1\t{ + } - { t }\n",
            "1\t{ H } - { M }\n",
            "1\t{ w } - { I }\n",
            "1\t{ 9 } - { y }\n",
            "\u001b[0m\n",
            "Average character accuracy: 92.14%, (stddev: 0.00)\u001b[0m\n",
            "Average word accuracy: 77.16%, (stddev: 0.00)\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!ketos test \\\n",
        "  --model bentham_kraken_21.mlmodel \\\n",
        "  /content/kraken_bentham/lines/*.png"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FIbu_DUKkUDu",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIbu_DUKkUDu",
        "outputId": "baec4f2d-8944-4fa9-e31e-32c7952457b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Usage: ketos test [OPTIONS] [TEST_SET]...\n",
            "\n",
            "  Evaluate on a test set.\n",
            "\n",
            "Options:\n",
            "  -B, --batch-size INTEGER        Batch sample size  [default: 1]\n",
            "  -m, --model PATH                Model(s) to evaluate\n",
            "  -e, --evaluation-files FILENAME\n",
            "                                  File(s) with paths to evaluation data.\n",
            "  --pad INTEGER                   Left and right padding around lines\n",
            "                                  [default: 16]\n",
            "  --reorder / --no-reorder        Reordering of code points to display order\n",
            "                                  [default: reorder]\n",
            "  --base-dir [L|R|auto]           Set base text direction.  This should be set\n",
            "                                  to the direction used during the creation of\n",
            "                                  the training data. If set to `auto` it will\n",
            "                                  be overridden by any explicit value given in\n",
            "                                  the input files.  [default: auto]\n",
            "  -u, --normalization [NFD|NFKD|NFC|NFKC]\n",
            "                                  Ground truth normalization\n",
            "  -n, --normalize-whitespace / --no-normalize-whitespace\n",
            "                                  Normalizes unicode whitespace  [default: n]\n",
            "  --force-binarization / --no-binarization\n",
            "                                  Forces input images to be binary, otherwise\n",
            "                                  the appropriate color format will be auto-\n",
            "                                  determined through the network\n",
            "                                  specification. Will be ignored in `path`\n",
            "                                  mode.  [default: no-binarization]\n",
            "  -f, --format-type [path|xml|alto|page|binary]\n",
            "                                  Sets the training data format. In ALTO and\n",
            "                                  PageXML mode all data is extracted from xml\n",
            "                                  files containing both baselines and a link\n",
            "                                  to source images. In `path` mode arguments\n",
            "                                  are image files sharing a prefix up to the\n",
            "                                  last extension with JSON `.path` files\n",
            "                                  containing the baseline information. In\n",
            "                                  `binary` mode files are collections of pre-\n",
            "                                  extracted text line images.\n",
            "  --fixed-splits / --ignore-fixed-split\n",
            "                                  Whether to honor fixed splits in binary\n",
            "                                  datasets.  [default: ignore-fixed-split]\n",
            "  --no-legacy-polygons            Force disable the legacy polygon extractor.\n",
            "  --help                          Show this message and exit.\n"
          ]
        }
      ],
      "source": [
        "!ketos test --help"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wdMQAdMdkZz6",
      "metadata": {
        "id": "wdMQAdMdkZz6"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ptJ3LCiMVQ9u",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptJ3LCiMVQ9u",
        "outputId": "5954b83e-d3ea-42dd-a34e-a0bfb641eadb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root root 16M Dec  8 10:22 bentham_kraken_best.mlmodel\n",
            "bentham_kraken_best.mlmodel: data\n"
          ]
        }
      ],
      "source": [
        "!ls -lh bentham_kraken_best.mlmodel\n",
        "!file bentham_kraken_best.mlmodel\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "u6Vz5L53Vcq2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "u6Vz5L53Vcq2",
        "outputId": "107ffba9-3e81-4d06-dabc-a0474bb886c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kraken in /usr/local/lib/python3.12/dist-packages (6.0.2)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.12/dist-packages (from kraken) (4.25.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from kraken) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kraken) (2.32.4)\n",
            "Requirement already satisfied: click<8.3,>=8.1 in /usr/local/lib/python3.12/dist-packages (from kraken) (8.2.1)\n",
            "Requirement already satisfied: numpy~=2.0.0 in /usr/local/lib/python3.12/dist-packages (from kraken) (2.0.2)\n",
            "Requirement already satisfied: Pillow>=9.2.0 in /usr/local/lib/python3.12/dist-packages (from kraken) (11.3.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from kraken) (2025.11.3)\n",
            "Requirement already satisfied: scipy~=1.13.0 in /usr/local/lib/python3.12/dist-packages (from kraken) (1.13.1)\n",
            "Requirement already satisfied: protobuf>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from kraken) (5.29.5)\n",
            "Requirement already satisfied: coremltools~=8.1 in /usr/local/lib/python3.12/dist-packages (from kraken) (8.3.0)\n",
            "Requirement already satisfied: jinja2~=3.0 in /usr/local/lib/python3.12/dist-packages (from kraken) (3.1.6)\n",
            "Requirement already satisfied: python-bidi~=0.6.0 in /usr/local/lib/python3.12/dist-packages (from kraken) (0.6.7)\n",
            "Requirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from kraken) (0.22.1)\n",
            "Requirement already satisfied: torch<2.8.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from kraken) (2.7.1)\n",
            "Requirement already satisfied: scikit-learn~=1.5.0 in /usr/local/lib/python3.12/dist-packages (from kraken) (1.5.2)\n",
            "Requirement already satisfied: scikit-image~=0.24.0 in /usr/local/lib/python3.12/dist-packages (from kraken) (0.24.0)\n",
            "Requirement already satisfied: shapely>=2.0.6,~=2.0.6 in /usr/local/lib/python3.12/dist-packages (from kraken) (2.0.7)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.12/dist-packages (from kraken) (18.1.0)\n",
            "Requirement already satisfied: htrmopo>=0.3,~=0.3 in /usr/local/lib/python3.12/dist-packages (from kraken) (0.3.0)\n",
            "Requirement already satisfied: lightning~=2.4.0 in /usr/local/lib/python3.12/dist-packages (from kraken) (2.4.0)\n",
            "Requirement already satisfied: torchmetrics>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from kraken) (1.8.2)\n",
            "Requirement already satisfied: threadpoolctl~=3.5.0 in /usr/local/lib/python3.12/dist-packages (from kraken) (3.5.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from kraken) (4.5.0)\n",
            "Requirement already satisfied: rich!=14.1.0 in /usr/local/lib/python3.12/dist-packages (from kraken) (13.9.4)\n",
            "Requirement already satisfied: iso639-lang in /usr/local/lib/python3.12/dist-packages (from kraken) (2.6.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from coremltools~=8.1->kraken) (1.14.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from coremltools~=8.1->kraken) (4.67.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from coremltools~=8.1->kraken) (24.2)\n",
            "Requirement already satisfied: attrs>=21.3.0 in /usr/local/lib/python3.12/dist-packages (from coremltools~=8.1->kraken) (25.4.0)\n",
            "Requirement already satisfied: cattrs in /usr/local/lib/python3.12/dist-packages (from coremltools~=8.1->kraken) (25.3.0)\n",
            "Requirement already satisfied: pyaml in /usr/local/lib/python3.12/dist-packages (from coremltools~=8.1->kraken) (25.7.0)\n",
            "Requirement already satisfied: flufl.lock in /usr/local/lib/python3.12/dist-packages (from htrmopo>=0.3,~=0.3->kraken) (9.0.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from htrmopo>=0.3,~=0.3->kraken) (6.0.3)\n",
            "Requirement already satisfied: sickle in /usr/local/lib/python3.12/dist-packages (from htrmopo>=0.3,~=0.3->kraken) (0.7.0)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.12/dist-packages (from htrmopo>=0.3,~=0.3->kraken) (3.10)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from htrmopo>=0.3,~=0.3->kraken) (2.9.0.post0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2~=3.0->kraken) (3.0.3)\n",
            "Requirement already satisfied: fsspec<2026.0,>=2022.5.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning~=2.4.0->kraken) (2025.3.0)\n",
            "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from lightning~=2.4.0->kraken) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions<6.0,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from lightning~=2.4.0->kraken) (4.15.0)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.12/dist-packages (from lightning~=2.4.0->kraken) (2.6.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich!=14.1.0->kraken) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich!=14.1.0->kraken) (2.19.2)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.12/dist-packages (from scikit-image~=0.24.0->kraken) (3.6)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image~=0.24.0->kraken) (2.37.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image~=0.24.0->kraken) (2025.10.16)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image~=0.24.0->kraken) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn~=1.5.0->kraken) (1.5.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.4.0->kraken) (3.20.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.4.0->kraken) (75.2.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.4.0->kraken) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.4.0->kraken) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.4.0->kraken) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.4.0->kraken) (9.5.1.17)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.4.0->kraken) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.4.0->kraken) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.4.0->kraken) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.4.0->kraken) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.4.0->kraken) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.4.0->kraken) (0.6.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.4.0->kraken) (2.26.2)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.4.0->kraken) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.4.0->kraken) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.4.0->kraken) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.3.1 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.4.0->kraken) (3.3.1)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema->kraken) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema->kraken) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema->kraken) (0.29.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kraken) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->kraken) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->kraken) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->kraken) (2025.11.12)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning~=2.4.0->kraken) (3.13.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich!=14.1.0->kraken) (0.1.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->coremltools~=8.1->kraken) (1.3.0)\n",
            "Requirement already satisfied: atpublic in /usr/local/lib/python3.12/dist-packages (from flufl.lock->htrmopo>=0.3,~=0.3->kraken) (5.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from flufl.lock->htrmopo>=0.3,~=0.3->kraken) (5.9.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil->htrmopo>=0.3,~=0.3->kraken) (1.17.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning~=2.4.0->kraken) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning~=2.4.0->kraken) (1.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning~=2.4.0->kraken) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning~=2.4.0->kraken) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning~=2.4.0->kraken) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning~=2.4.0->kraken) (1.22.0)\n",
            "<kraken.lib.models.TorchSeqRecognizer object at 0x7c1fd0217e30>\n"
          ]
        }
      ],
      "source": [
        "!pip install -U kraken\n",
        "from kraken.lib import models\n",
        "m = models.load_any(\"bentham_kraken_best.mlmodel\")\n",
        "print(m)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "k58POAG1wiLa",
      "metadata": {
        "id": "k58POAG1wiLa"
      },
      "source": [
        "# Python helper to evaluate and collect per-line results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iFHDrEzGwngR",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFHDrEzGwngR",
        "outputId": "1b55e8e5-a417-4214-92bc-4aea405aee03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded model: <kraken.lib.models.TorchSeqRecognizer object at 0x7c1fc7f1bad0>\n",
            "Found 11473 total line images (using 10).\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/002_080_001_01_01.png, skipping this sample.\n",
            "\n",
            "Summary of evaluation:\n",
            "  Used images:           10\n",
            "  Evaluated successfully:9\n",
            "  Skipped (no GT):       0\n",
            "  Skipped (no lines):    1\n",
            "  Skipped (no prediction): 0\n",
            "--------------------------------------------------------------------------------\n",
            "Image: /content/kraken_bentham/lines/002_080_001_03_01.png\n",
            "Char accuracy: 81.67%\n",
            "GT:    6 . The evidence of the engagement , consigned to a portable\n",
            "Pred:  6 The evidence of the ongagement , consagnad to  port 2athew\n",
            "--------------------------------------------------------------------------------\n",
            "Image: /content/kraken_bentham/lines/002_080_001_03_02.png\n",
            "Char accuracy: 65.00%\n",
            "GT:    instrument , instead of a fixed Book .  _  Taken from Exche-\n",
            "Pred:  asbement ainstead of a fined Stook . taken fomm Couche.\n",
            "--------------------------------------------------------------------------------\n",
            "Image: /content/kraken_bentham/lines/002_080_001_03_08.png\n",
            "Char accuracy: 56.72%\n",
            "GT:    7 . The Paper , by its size , shape , texture , are thinness , par-\n",
            "Pred:  7 The Weaper y 6s sire , shape datline , oannd Whanmes , fd\n",
            "--------------------------------------------------------------------------------\n",
            "Image: /content/kraken_bentham/lines/002_080_001_03_03.png\n",
            "Char accuracy: 40.00%\n",
            "GT:    quer Bills , _  Differs from Stock Annuities  _  Agrees with\n",
            "Pred:  ue Webhsw ittes fons thout Ednmindeto lngeet ith\n",
            "--------------------------------------------------------------------------------\n",
            "Image: /content/kraken_bentham/lines/002_080_001_03_06.png\n",
            "Char accuracy: 37.93%\n",
            "GT:    also with India Bonds , Bank Notes , Banker ' s Promissory\n",
            "Pred:  lahse ith Mndns Ptrads un oes hunhns eomctteng\n",
            "--------------------------------------------------------------------------------\n",
            "Image: /content/kraken_bentham/lines/002_080_001_03_07.png\n",
            "Char accuracy: 33.33%\n",
            "GT:    Notes ; and private Promissory Notes and Bills of Exchange .\n",
            "Pred:  Aont larnid ennnvntes Wonnsoy at Sls eaaaed Whath of blohinn .\n",
            "--------------------------------------------------------------------------------\n",
            "Image: /content/kraken_bentham/lines/002_080_001_03_04.png\n",
            "Char accuracy: 28.00%\n",
            "GT:    Irish Debentures , and the now disused Navy Victu-\n",
            "Pred:  Jwh ihendaret coitth ns lnsanved as Pexay Eten\n",
            "--------------------------------------------------------------------------------\n",
            "Image: /content/kraken_bentham/lines/002_080_001_03_05.png\n",
            "Char accuracy: 27.27%\n",
            "GT:    alling Transport and Ordnance Bills or Debentures :   _\n",
            "Pred:  tains atd dnseah Ond Wednamm  tg ron t hnnment\n",
            "--------------------------------------------------------------------------------\n",
            "Image: /content/kraken_bentham/lines/002_080_001_02_01.png\n",
            "Char accuracy: 18.18%\n",
            "GT:    16 Aug 1800\n",
            "Pred:  t Cw133\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "import os\n",
        "from dataclasses import dataclass\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "from kraken.lib import models\n",
        "from kraken import rpred, pageseg, binarization\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 1. Load the recognition model\n",
        "# --------------------------------------------------\n",
        "MODEL_PATH = \"bentham_kraken_21.mlmodel\"\n",
        "rec_model = models.load_any(MODEL_PATH)\n",
        "print(\"Loaded model:\", rec_model)\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 2. Small helper: Levenshtein distance and accuracies\n",
        "# --------------------------------------------------\n",
        "def levenshtein(a: str, b: str) -> int:\n",
        "    \"\"\"Simple Levenshtein distance for accuracy computation.\"\"\"\n",
        "    m, n = len(a), len(b)\n",
        "    if m == 0:\n",
        "        return n\n",
        "    if n == 0:\n",
        "        return m\n",
        "    dp = [[0] * (n + 1) for _ in range(m + 1)]\n",
        "    for i in range(m + 1):\n",
        "        dp[i][0] = i\n",
        "    for j in range(n + 1):\n",
        "        dp[0][j] = j\n",
        "    for i in range(1, m + 1):\n",
        "        for j in range(1, n + 1):\n",
        "            cost = 0 if a[i - 1] == b[j - 1] else 1\n",
        "            dp[i][j] = min(\n",
        "                dp[i - 1][j] + 1,      # deletion\n",
        "                dp[i][j - 1] + 1,      # insertion\n",
        "                dp[i - 1][j - 1] + cost  # substitution\n",
        "            )\n",
        "    return dp[m][n]\n",
        "\n",
        "def char_accuracy(gt: str, pred: str) -> float:\n",
        "    if not gt:\n",
        "        return 1.0 if not pred else 0.0\n",
        "    dist = levenshtein(gt, pred)\n",
        "    return 1.0 - dist / len(gt)\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 3. Collect per-line results for a small subset\n",
        "# --------------------------------------------------\n",
        "def evaluate_subset(\n",
        "    lines_glob=\"/content/kraken_bentham/lines/*.png\",\n",
        "    max_examples=10,   # None -> use ALL\n",
        "):\n",
        "    all_paths = sorted(glob.glob(lines_glob))\n",
        "\n",
        "    if max_examples is None:\n",
        "        image_paths = all_paths\n",
        "    else:\n",
        "        image_paths = all_paths[:max_examples]\n",
        "\n",
        "    print(f\"Found {len(all_paths)} total line images (using {len(image_paths)}).\")\n",
        "\n",
        "    results = []\n",
        "    skipped_no_gt = 0\n",
        "    skipped_no_lines = 0\n",
        "    skipped_no_pred = 0\n",
        "\n",
        "    for img_path in image_paths:\n",
        "        # ---- GT ----\n",
        "        gt_path = os.path.splitext(img_path)[0] + \".gt.txt\"\n",
        "        if not os.path.exists(gt_path):\n",
        "            print(f\"[WARN] No GT file for {img_path}, skipping.\")\n",
        "            skipped_no_gt += 1\n",
        "            continue\n",
        "\n",
        "        with open(gt_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            gt_text = f.read().strip()\n",
        "\n",
        "        # ---- Load + binarize ----\n",
        "        im = Image.open(img_path)\n",
        "        bw = binarization.nlbin(im)\n",
        "\n",
        "        # ---- Segment ----\n",
        "        seg = pageseg.segment(bw, text_direction=\"horizontal-lr\")\n",
        "\n",
        "        if not (seg and hasattr(seg, \"lines\") and seg.lines):\n",
        "            print(f\"[WARN] No lines detected for {img_path}, skipping this sample.\")\n",
        "            skipped_no_lines += 1\n",
        "            continue\n",
        "\n",
        "        # ---- Recognize ----\n",
        "        pred_iter = rpred.rpred(rec_model, bw, seg)\n",
        "        try:\n",
        "            record = next(pred_iter)\n",
        "            pred_text = record.prediction\n",
        "        except StopIteration:\n",
        "            print(f\"[WARN] rpred yielded no results for {img_path}, skipping this sample.\")\n",
        "            skipped_no_pred += 1\n",
        "            continue\n",
        "\n",
        "        # ---- Accuracy ----\n",
        "        acc = char_accuracy(gt_text, pred_text)\n",
        "\n",
        "        results.append(\n",
        "            {\n",
        "                \"image\": img_path,\n",
        "                \"gt\": gt_text,\n",
        "                \"pred\": pred_text,\n",
        "                \"char_accuracy\": acc,\n",
        "            }\n",
        "        )\n",
        "\n",
        "    print(\"\\nSummary of evaluation:\")\n",
        "    print(f\"  Used images:           {len(image_paths)}\")\n",
        "    print(f\"  Evaluated successfully:{len(results)}\")\n",
        "    print(f\"  Skipped (no GT):       {skipped_no_gt}\")\n",
        "    print(f\"  Skipped (no lines):    {skipped_no_lines}\")\n",
        "    print(f\"  Skipped (no prediction): {skipped_no_pred}\")\n",
        "\n",
        "    return results\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 4. Example: run and inspect the best lines\n",
        "# --------------------------------------------------\n",
        "results = evaluate_subset(\n",
        "    lines_glob=\"/content/kraken_bentham/lines/*.png\",\n",
        "    max_examples=10,\n",
        ")\n",
        "\n",
        "# Sort by accuracy, best first\n",
        "results_sorted = sorted(results, key=lambda r: r[\"char_accuracy\"], reverse=True)\n",
        "\n",
        "for r in results_sorted:\n",
        "    print(\"-\" * 80)\n",
        "    print(\"Image:\", r[\"image\"])\n",
        "    print(f\"Char accuracy: {r['char_accuracy']*100:.2f}%\")\n",
        "    print(\"GT:   \", r[\"gt\"])\n",
        "    print(\"Pred: \", r[\"pred\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "htNCWv4w3ocP",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htNCWv4w3ocP",
        "outputId": "6ade9e7b-6f35-4be5-acf2-a6975ec4423b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 11473 total line images (using 11473).\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/002_080_001_01_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:kraken.pageseg:Too many connected components for a page image: 2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/002_112_001_03_07.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n",
            "WARNING:kraken.pageseg:Too many connected components for a page image: 17\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/002_541_001_01_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:kraken.pageseg:Too many connected components for a page image: 13\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/002_579_001_01_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/027_029_001_02_07.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/027_029_001_02_09.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/027_029_001_02_15.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/027_029_001_02_18.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/027_029_001_02_23.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/027_029_001_02_30.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/fromnumeric.py:3596: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "WARNING:kraken.pageseg:Exception in column finder (probably empty image) for <PIL.Image.Image image mode=L size=61x88 at 0x7C1F67164590>\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/035_320_001_01_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/fromnumeric.py:3596: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "WARNING:kraken.pageseg:Exception in column finder (probably empty image) for <PIL.Image.Image image mode=L size=88x94 at 0x7C1FAF23C140>\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/035_321_001_02_24.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/035_322_001_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/035_324_001_02_20.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/035_324_001_02_24.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/035_325_001_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/035_325_001_02_24.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/035_327_001_02_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/fromnumeric.py:3596: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "WARNING:kraken.pageseg:Exception in column finder (probably empty image) for <PIL.Image.Image image mode=L size=95x78 at 0x7C1F67166DE0>\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/035_327_001_02_23.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/035_328_001_01_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:kraken.rpred:Conversion of line BBoxLine(id='_50a7fd4f-ab70-41c1-a5af-757836d0d366', bbox=[434, 0, 774, 64], text=None, base_dir=None, type='bbox', imagename=None, tags=None, split=None, regions=None, text_direction='horizontal-lr', language=None) failed. Emitting empty record..\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_002_002_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_003_003_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_003_003_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_003_003_04_02.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_003_003_04_25.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_003_004_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_008_004_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_008_004_03_18.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:kraken.pageseg:Too many connected components for a page image: 9\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_010_002_04_12.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_010_003_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_010_003_04_24.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_018_002_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_018_002_04_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_018_002_05_19.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/fromnumeric.py:3596: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "WARNING:kraken.pageseg:Exception in column finder (probably empty image) for <PIL.Image.Image image mode=L size=106x51 at 0x7C1F67167170>\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_021_002_04_03.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_022_003_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_030_001_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_030_001_04_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_030_001_04_13.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_030_001_04_18.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_030_001_04_20.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:kraken.pageseg:Too many connected components for a page image: 8\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_030_001_04_25.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:kraken.pageseg:Too many connected components for a page image: 5\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_030_001_04_27.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_030_001_04_32.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_032_001_01_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/fromnumeric.py:3596: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "WARNING:kraken.pageseg:Exception in column finder (probably empty image) for <PIL.Image.Image image mode=L size=91x79 at 0x7C1F67166F60>\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_032_001_04_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_032_001_04_05.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_032_001_04_13.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_032_001_04_21.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_032_002_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_032_002_04_06.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_032_002_04_26.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_035_002_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_035_002_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_035_003_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_035_003_04_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/fromnumeric.py:3596: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "WARNING:kraken.pageseg:Exception in column finder (probably empty image) for <PIL.Image.Image image mode=L size=120x123 at 0x7C1F671E75C0>\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/fromnumeric.py:3596: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "WARNING:kraken.pageseg:Exception in column finder (probably empty image) for <PIL.Image.Image image mode=L size=128x124 at 0x7C1F90BC72F0>\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_035_003_07_03.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_036_001_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_036_001_02_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/fromnumeric.py:3596: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "WARNING:kraken.pageseg:Exception in column finder (probably empty image) for <PIL.Image.Image image mode=L size=37x58 at 0x7C1F5DE37FE0>\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_042_001_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_042_001_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_042_002_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_042_002_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_043_003_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_043_003_02_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_043_003_04_23.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_043_004_04_05.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:kraken.pageseg:Too many connected components for a page image: 2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_043_004_04_27.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_053_003_03_07.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_053_003_03_10.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_053_004_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_053_004_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_053_004_03_09.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_054_001_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_054_001_02_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:kraken.pageseg:Too many connected components for a page image: 295\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_054_001_03_04.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_054_002_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_054_002_03_05.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_059_003_04_09.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_101_002_01_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_101_002_04_21.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_101_003_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_101_003_04_20.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_101_004_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_102_001_04_11.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_102_002_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_102_002_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_102_002_05_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_102_003_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_103_002_02_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_106_001_04_14.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_106_002_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_106_002_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_107_001_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_107_001_02_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_107_002_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_108_001_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_108_001_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_108_002_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_108_002_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_109_001_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_109_001_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_111_001_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_111_001_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_111_002_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_112_001_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_112_003_02_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_117_002_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_117_002_02_02.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_117_002_03_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_120_001_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_120_002_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_120_002_02_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_128_001_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_128_001_02_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_128_001_05_23.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_128_003_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_128_003_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_129_002_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_129_002_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_130_003_02_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:kraken.pageseg:Too many connected components for a page image: 470\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_130_003_04_05.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_131_002_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_131_002_04_10.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_131_002_04_16.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_131_004_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_131_004_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_132_001_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_133_002_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_133_003_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_139_003_02_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n",
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_139_003_04_21.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_139_004_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_140_001_01_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_140_001_04_18.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_141_001_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_141_001_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_141_001_04_19.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n",
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_142_001_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_142_001_02_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_144_002_02_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_146_001_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_146_001_02_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:kraken.pageseg:Too many connected components for a page image: 11\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_146_001_04_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_146_002_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_146_003_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_151_003_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_156_002_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_156_002_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_157_001_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_157_002_02_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:kraken.pageseg:Too many connected components for a page image: 9\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_158_002_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_158_002_02_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_159_001_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_159_001_02_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/fromnumeric.py:3596: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "WARNING:kraken.pageseg:Exception in column finder (probably empty image) for <PIL.Image.Image image mode=L size=68x111 at 0x7C1F5DC0ECF0>\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_159_002_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_159_002_04_14.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_159_003_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_159_003_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_162_001_01_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_162_001_04_03.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_162_001_04_20.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_162_002_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_163_001_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_163_002_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_163_002_04_11.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_163_003_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_163_004_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_163_004_02_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n",
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_164_001_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_164_001_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_164_002_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_165_001_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_165_003_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_165_003_02_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:kraken.pageseg:Too many connected components for a page image: 4\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_165_003_04_02.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_165_003_04_14.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_166_001_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_166_001_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_166_001_04_17.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_166_001_04_20.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_167_001_01_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_167_001_04_02.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_167_002_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_168_003_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_168_004_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_168_004_02_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_168_004_04_04.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_169_001_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_169_001_02_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n",
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_169_001_05_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_169_001_05_21.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_169_002_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_169_002_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_169_004_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_169_004_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_169_004_04_02.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_169_004_05_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/fromnumeric.py:3596: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "WARNING:kraken.pageseg:Exception in column finder (probably empty image) for <PIL.Image.Image image mode=L size=183x86 at 0x7C1F5DC598B0>\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_169_004_05_06.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_169_004_05_13.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_169_004_05_23.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_180_003_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_180_003_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_180_003_04_02.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_180_003_05_02.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_180_003_05_04.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_180_004_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_180_004_02_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_181_001_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_181_002_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_181_002_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_181_003_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_181_004_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_181_004_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_182_001_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_182_002_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_182_004_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_183_001_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_183_001_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_183_001_04_03.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_183_004_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_183_004_04_20.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_184_001_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_184_001_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_184_002_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_184_002_02_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_184_003_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_184_003_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_184_004_01_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_185_002_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_185_002_02_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_185_002_04_19.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_185_003_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_185_003_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_185_004_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_186_002_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_186_002_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_186_003_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_186_003_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_186_003_04_19.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_186_004_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_190_002_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_192_002_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_192_002_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_192_002_04_15.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_192_004_02_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n",
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_192_004_04_21.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_201_001_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_201_003_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_201_003_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/071_202_001_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_031_001_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_032_002_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_032_002_02_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/fromnumeric.py:3596: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "WARNING:kraken.pageseg:Exception in column finder (probably empty image) for <PIL.Image.Image image mode=L size=128x87 at 0x7C1F7B72B080>\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_036_002_02_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/fromnumeric.py:3596: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "WARNING:kraken.pageseg:Exception in column finder (probably empty image) for <PIL.Image.Image image mode=L size=126x92 at 0x7C1F671E4B00>\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_036_002_04_20.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_047_002_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_048_003_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_049_001_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_049_001_04_12.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_049_001_04_23.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_049_002_01_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:kraken.pageseg:Too many connected components for a page image: 498\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_049_002_04_05.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_049_004_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_050_001_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_050_003_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_050_003_04_23.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_051_003_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_054_001_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_054_001_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_054_002_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_054_003_03_22.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_054_003_04_06.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_066_001_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_066_001_04_12.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_066_002_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_066_002_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_066_003_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_066_003_02_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_066_003_04_02.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_069_002_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_070_002_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_070_002_05_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_071_004_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_071_004_04_07.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_094_003_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_094_003_02_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/fromnumeric.py:3596: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "WARNING:kraken.pageseg:Exception in column finder (probably empty image) for <PIL.Image.Image image mode=L size=93x115 at 0x7C1FC7CF6C30>\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_094_004_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_094_004_02_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/fromnumeric.py:3596: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "WARNING:kraken.pageseg:Exception in column finder (probably empty image) for <PIL.Image.Image image mode=L size=105x109 at 0x7C1F7B729B20>\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_095_001_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_095_001_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_099_001_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_099_001_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_099_001_04_21.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_100_001_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_100_002_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_100_003_04_07.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_100_003_04_19.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_101_002_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_101_002_04_20.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_101_003_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_101_004_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_101_004_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_101_004_04_19.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_102_002_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_102_002_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_102_002_04_14.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_102_003_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_102_003_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_102_004_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_102_004_04_06.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/fromnumeric.py:3596: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "WARNING:kraken.pageseg:Exception in column finder (probably empty image) for <PIL.Image.Image image mode=L size=83x80 at 0x7C1F5C535F40>\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_102_004_04_13.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_103_001_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_103_001_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_103_002_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_103_002_04_19.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_103_004_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_104_002_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_104_002_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_105_002_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_105_002_02_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_105_003_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_167_002_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_167_002_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_168_001_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_168_001_04_04.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_168_003_04_13.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:kraken.pageseg:Too many connected components for a page image: 3\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_169_002_01_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_169_003_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_210_001_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_210_001_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_210_001_03_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_210_001_04_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_210_002_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_210_004_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_212_001_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_213_001_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_213_001_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/072_213_001_04_04.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/073_001_001_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/073_001_001_02_24.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/073_001_001_02_27.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/073_001_003_01_03.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/073_001_003_01_20.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/073_002_001_01_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/fromnumeric.py:3596: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "WARNING:kraken.pageseg:Exception in column finder (probably empty image) for <PIL.Image.Image image mode=L size=95x113 at 0x7C1F7B729D90>\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/073_031_001_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/073_031_001_02_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/073_031_001_04_03.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/073_031_001_04_08.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/073_050_001_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/073_051_001_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/073_052_001_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/073_052_001_03_13.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/073_053_001_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/073_053_001_03_09.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/073_054_001_01_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/073_054_001_03_09.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/073_054_001_03_22.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/073_056_001_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/073_056_001_03_02.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/073_056_001_03_21.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/fromnumeric.py:3596: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "WARNING:kraken.pageseg:Exception in column finder (probably empty image) for <PIL.Image.Image image mode=L size=75x54 at 0x7C1F66FFDA00>\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/073_056_001_03_25.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/073_058_001_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/073_060_001_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/073_060_001_02_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n",
            "WARNING:kraken.pageseg:Too many connected components for a page image: 4\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/073_060_001_03_21.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/073_061_001_01_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/073_063_001_01_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/073_063_001_03_17.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/073_067_001_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/073_068_001_03_14.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/073_069_001_02_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/073_069_001_03_23.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/073_070_001_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/073_070_001_03_22.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/073_070_002_01_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:kraken.pageseg:Too many connected components for a page image: 2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/073_070_002_03_24.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/073_071_001_01_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/073_071_001_03_23.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/073_071_003_01_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/073_071_003_03_16.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/073_071_003_03_24.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/073_072_001_01_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/073_072_002_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/073_072_003_01_09.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:kraken.pageseg:Too many connected components for a page image: 3\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/073_073_001_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/073_073_001_03_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/073_073_001_03_17.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/073_073_001_03_24.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/073_074_001_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/073_074_001_03_20.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:kraken.pageseg:Too many connected components for a page image: 4\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/073_074_002_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/073_083_001_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/073_083_001_03_19.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/073_083_001_03_22.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/096_002_003_02_15.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/096_003_002_01_08.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/096_015_002_01_08.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/096_017_003_02_14.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/096_021_003_02_15.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/096_028_001_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/096_028_001_01_02.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/096_032_004_02_14.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/096_038_003_01_16.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/096_051_001_02_11.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/096_051_002_01_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/096_051_002_04_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/096_051_004_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/096_051_004_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/096_051_004_04_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/096_052_002_03_02.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/096_052_002_03_11.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/096_052_002_03_23.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n",
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/096_052_002_03_27.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/096_052_002_04_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/096_052_003_02_12.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/096_053_004_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/096_053_004_03_17.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/096_053_004_04_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/096_098_002_01_03.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/096_098_003_01_22.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/fromnumeric.py:3596: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "WARNING:kraken.pageseg:Exception in column finder (probably empty image) for <PIL.Image.Image image mode=L size=83x67 at 0x7C1F7B7B6420>\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/096_098_003_01_25.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:kraken.pageseg:Too many connected components for a page image: 3\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/096_099_003_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/096_099_003_02_03.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:kraken.pageseg:Too many connected components for a page image: 3\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/096_100_001_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/096_100_001_02_03.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/096_100_001_02_13.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/096_100_001_02_20.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/096_100_002_01_04.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/096_101_001_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/115_007_002_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/115_007_003_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/115_007_003_02_14.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/115_007_004_01_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/fromnumeric.py:3596: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "WARNING:kraken.pageseg:Exception in column finder (probably empty image) for <PIL.Image.Image image mode=L size=76x91 at 0x7C1F5C56A270>\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/115_008_002_01_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/fromnumeric.py:3596: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "WARNING:kraken.pageseg:Exception in column finder (probably empty image) for <PIL.Image.Image image mode=L size=136x146 at 0x7C1F5DC0E600>\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/115_009_001_03_03.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/115_009_002_02_21.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/115_009_004_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/115_009_004_02_29.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/115_010_001_01_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/fromnumeric.py:3596: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "WARNING:kraken.pageseg:Exception in column finder (probably empty image) for <PIL.Image.Image image mode=L size=133x128 at 0x7C1F7B728980>\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/115_011_001_02_03.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/115_011_001_02_38.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:kraken.pageseg:Too many connected components for a page image: 2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/115_011_002_02_17.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/115_016_001_01_04.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/115_016_001_01_23.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/115_016_003_01_05.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/115_065_003_01_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:kraken.pageseg:Too many connected components for a page image: 6\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/115_065_003_02_06.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:kraken.pageseg:Too many connected components for a page image: 20\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/115_065_003_02_22.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/115_067_002_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/115_067_004_01_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:kraken.pageseg:Too many connected components for a page image: 28\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/115_067_004_02_26.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/115_069_001_01_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:kraken.pageseg:Too many connected components for a page image: 12\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/115_070_002_01_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:kraken.pageseg:Too many connected components for a page image: 12\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/115_073_001_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/115_075_001_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/115_075_003_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/115_076_002_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/115_077_001_01_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:kraken.pageseg:Too many connected components for a page image: 4\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/115_077_003_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/115_078_002_02_37.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/115_079_001_02_07.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/115_079_001_02_09.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:kraken.pageseg:Too many connected components for a page image: 4\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/115_080_001_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/115_080_001_02_20.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:kraken.pageseg:Too many connected components for a page image: 2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/115_080_002_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/115_080_002_02_14.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/115_080_003_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/115_080_004_02_09.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/115_080_004_02_29.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:kraken.pageseg:Too many connected components for a page image: 7\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/115_082_004_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/115_084_001_01_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/fromnumeric.py:3596: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "WARNING:kraken.pageseg:Exception in column finder (probably empty image) for <PIL.Image.Image image mode=L size=41x59 at 0x7C1F61C7D3A0>\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/115_084_002_01_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:kraken.pageseg:Too many connected components for a page image: 5\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/115_084_003_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/115_084_003_02_33.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/115_084_004_01_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/115_085_003_01_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:kraken.pageseg:Too many connected components for a page image: 7\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/115_085_004_01_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:kraken.pageseg:Too many connected components for a page image: 3\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/115_086_001_01_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:kraken.pageseg:Too many connected components for a page image: 7\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/115_086_003_01_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:kraken.pageseg:Too many connected components for a page image: 9\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/115_087_001_01_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:kraken.pageseg:Too many connected components for a page image: 9\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/115_087_004_01_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:kraken.pageseg:Too many connected components for a page image: 2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/115_101_001_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/115_101_001_02_31.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/fromnumeric.py:3596: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "WARNING:kraken.pageseg:Exception in column finder (probably empty image) for <PIL.Image.Image image mode=L size=104x35 at 0x7C1F8E8A0500>\n",
            "WARNING:kraken.pageseg:Too many connected components for a page image: 6\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/115_101_002_01_30.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/115_101_003_01_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:kraken.pageseg:Too many connected components for a page image: 4\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/115_102_001_01_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/fromnumeric.py:3596: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "WARNING:kraken.pageseg:Exception in column finder (probably empty image) for <PIL.Image.Image image mode=L size=47x39 at 0x7C1FC7CA9610>\n",
            "WARNING:kraken.pageseg:Too many connected components for a page image: 73\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/115_110_001_03_19.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/115_110_002_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/115_110_002_02_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/fromnumeric.py:3596: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "WARNING:kraken.pageseg:Exception in column finder (probably empty image) for <PIL.Image.Image image mode=L size=167x74 at 0x7C1FC7CA9FA0>\n",
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/115_110_002_04_13.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/115_110_003_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/115_110_004_01_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:kraken.pageseg:Too many connected components for a page image: 2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/115_111_001_01_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/115_111_002_01_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/115_111_004_01_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/115_112_001_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/115_112_003_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/116_055_001_01_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:kraken.pageseg:Too many connected components for a page image: 5\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/116_063_001_01_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:kraken.pageseg:Too many connected components for a page image: 59\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/116_064_001_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/116_068_001_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/116_070_001_01_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/116_073_001_01_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n",
            "WARNING:kraken.pageseg:Too many connected components for a page image: 13\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/116_076_001_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/116_100_001_01_05.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/116_100_002_01_08.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/116_131_001_01_03.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/116_131_001_01_24.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:kraken.rpred:Conversion of line BBoxLine(id='_78a7eeaa-56b3-4a79-8a18-c97b3c9ddf08', bbox=[111, 0, 517, 74], text=None, base_dir=None, type='bbox', imagename=None, tags=None, split=None, regions=None, text_direction='horizontal-lr', language=None) failed. Emitting empty record..\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/116_244_001_01_11.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:kraken.pageseg:Too many connected components for a page image: 11\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/116_279_001_01_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n",
            "WARNING:kraken.pageseg:Too many connected components for a page image: 5\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/116_279_001_03_30.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/116_279_002_01_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:kraken.pageseg:Too many connected components for a page image: 3\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/116_280_001_01_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:kraken.pageseg:Too many connected components for a page image: 86\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/116_287_001_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/116_287_002_01_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:kraken.pageseg:Too many connected components for a page image: 53\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/116_288_001_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/116_288_001_02_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:kraken.pageseg:Too many connected components for a page image: 9\n",
            "WARNING:kraken.pageseg:Too many connected components for a page image: 67\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/116_290_001_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/116_290_001_02_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/116_290_001_03_10.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/116_291_001_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/116_291_001_03_13.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/116_291_002_01_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/116_294_001_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/116_294_002_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/116_294_002_02_31.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/116_295_001_01_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:kraken.pageseg:Too many connected components for a page image: 9\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/116_301_002_01_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:kraken.pageseg:Too many connected components for a page image: 4\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/116_303_002_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/116_387_001_01_18.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/116_393_003_03_13.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/116_405_004_01_21.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/fromnumeric.py:3596: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "WARNING:kraken.pageseg:Exception in column finder (probably empty image) for <PIL.Image.Image image mode=L size=52x66 at 0x7C1F5DC5B6B0>\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/116_606_001_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/116_607_001_01_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:kraken.pageseg:Too many connected components for a page image: 7\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/116_618_001_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/116_618_001_03_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:kraken.pageseg:Too many connected components for a page image: 7\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/116_619_001_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/116_620_001_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/116_620_001_03_24.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/116_626_002_01_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kraken/pageseg.py:204: RuntimeWarning: invalid value encountered in divide\n",
            "  return v/np.amax(v)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/116_627_001_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/116_627_002_01_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:kraken.pageseg:Too many connected components for a page image: 13\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/116_630_002_01_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:kraken.pageseg:Too many connected components for a page image: 7\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/116_631_001_01_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:kraken.pageseg:Too many connected components for a page image: 8\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/116_631_002_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/116_633_002_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/116_636_002_02_20.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/116_639_001_01_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:kraken.pageseg:Too many connected components for a page image: 17\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/116_639_002_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/116_641_001_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/116_642_001_02_04.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/116_642_001_02_05.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:kraken.pageseg:Too many connected components for a page image: 5\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/116_642_002_01_01.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/fromnumeric.py:3596: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "WARNING:kraken.pageseg:Exception in column finder (probably empty image) for <PIL.Image.Image image mode=L size=76x72 at 0x7C1FA0EB7500>\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/116_643_002_01_01.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/116_643_002_02_19.png, skipping this sample.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:kraken.pageseg:Too many connected components for a page image: 56\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] No lines detected for /content/kraken_bentham/lines/116_643_002_02_31.png, skipping this sample.\n",
            "[WARN] No lines detected for /content/kraken_bentham/lines/116_648_001_01_01.png, skipping this sample.\n",
            "\n",
            "Summary of evaluation:\n",
            "  Used images:           11473\n",
            "  Evaluated successfully:10915\n",
            "  Skipped (no GT):       0\n",
            "  Skipped (no lines):    558\n",
            "  Skipped (no prediction): 0\n"
          ]
        }
      ],
      "source": [
        "results = evaluate_subset(\n",
        "    lines_glob=\"/content/kraken_bentham/lines/*.png\",\n",
        "    max_examples=None,   # <- ALL LINES\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NjKgE8My6Aet",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjKgE8My6Aet",
        "outputId": "79e7b7e8-e76f-47c0-e055-900dd83d4fc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filtered results: kept 9644 out of 10915 samples.\n",
            "\n",
            "Top 30 highest-accuracy FULL-SENTENCE examples:\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Image: /content/kraken_bentham/lines/071_132_001_01_01.png\n",
            "Char accuracy: 100.00%\n",
            "GT: 17 .\n",
            "Pred: 17 .\n",
            "--------------------------------------------------------------------------------\n",
            "Image: /content/kraken_bentham/lines/071_184_003_03_01.png\n",
            "Char accuracy: 100.00%\n",
            "GT: Of Frauds relative to the Coin\n",
            "Pred: Of Frauds relative to the Coin\n",
            "--------------------------------------------------------------------------------\n",
            "Image: /content/kraken_bentham/lines/071_192_004_01_01.png\n",
            "Char accuracy: 100.00%\n",
            "GT: 16 .\n",
            "Pred: 16 .\n",
            "--------------------------------------------------------------------------------\n",
            "Image: /content/kraken_bentham/lines/073_070_001_03_05.png\n",
            "Char accuracy: 100.00%\n",
            "GT: that of\n",
            "Pred: that of\n",
            "--------------------------------------------------------------------------------\n",
            "Image: /content/kraken_bentham/lines/073_073_001_03_13.png\n",
            "Char accuracy: 97.30%\n",
            "GT: implies any such Thing . The ordinary\n",
            "Pred: implies any such Thing . he ordinary\n",
            "--------------------------------------------------------------------------------\n",
            "Image: /content/kraken_bentham/lines/073_003_001_02_02.png\n",
            "Char accuracy: 95.56%\n",
            "GT: inserting under one Title a proposition which\n",
            "Pred: inserting under one Tithe a poposition which\n",
            "--------------------------------------------------------------------------------\n",
            "Image: /content/kraken_bentham/lines/071_186_002_04_11.png\n",
            "Char accuracy: 95.08%\n",
            "GT: stand altogether upon so good a footing :  since the distress\n",
            "Pred: stand allogether upon , so good a footing :  since the distress\n",
            "--------------------------------------------------------------------------------\n",
            "Image: /content/kraken_bentham/lines/072_049_004_04_19.png\n",
            "Char accuracy: 94.44%\n",
            "GT: As to the mischief there would be in\n",
            "Pred: As to the mischif there would bhe in\n",
            "--------------------------------------------------------------------------------\n",
            "Image: /content/kraken_bentham/lines/073_003_002_01_15.png\n",
            "Char accuracy: 93.75%\n",
            "GT: give the Reality , without contenting themselves\n",
            "Pred: give the Reality , without ententing themselvs\n",
            "--------------------------------------------------------------------------------\n",
            "Image: /content/kraken_bentham/lines/071_186_002_04_06.png\n",
            "Char accuracy: 93.33%\n",
            "GT: in general nobody can know )  , whether the least part of it\n",
            "Pred: in general nobedy can know  , whether the least part of i\n",
            "--------------------------------------------------------------------------------\n",
            "Image: /content/kraken_bentham/lines/096_101_001_02_12.png\n",
            "Char accuracy: 93.33%\n",
            "GT: can be assigned\n",
            "Pred: can be assignes\n",
            "--------------------------------------------------------------------------------\n",
            "Image: /content/kraken_bentham/lines/072_052_002_03_01.png\n",
            "Char accuracy: 92.45%\n",
            "GT: Offences against the external Security of the State .\n",
            "Pred: Offences against the external Decurity of the Sate\n",
            "--------------------------------------------------------------------------------\n",
            "Image: /content/kraken_bentham/lines/096_099_004_01_05.png\n",
            "Char accuracy: 92.45%\n",
            "GT: if instead of the Fine we take for the Punishment any\n",
            "Pred: if instead of the Tine we take for the Jurishment ony\n",
            "--------------------------------------------------------------------------------\n",
            "Image: /content/kraken_bentham/lines/072_066_003_03_01.png\n",
            "Char accuracy: 92.31%\n",
            "GT: Of Idleness .\n",
            "Pred: O Idleness .\n",
            "--------------------------------------------------------------------------------\n",
            "Image: /content/kraken_bentham/lines/096_100_001_02_24.png\n",
            "Char accuracy: 91.84%\n",
            "GT: would have nothing to do but to pay his third and\n",
            "Pred: would have nothiny 10 do But to pay his third and\n",
            "--------------------------------------------------------------------------------\n",
            "Image: /content/kraken_bentham/lines/071_120_002_05_01.png\n",
            "Char accuracy: 91.67%\n",
            "GT: Exposition .\n",
            "Pred: Expoition .\n",
            "--------------------------------------------------------------------------------\n",
            "Image: /content/kraken_bentham/lines/071_111_002_04_18.png\n",
            "Char accuracy: 90.79%\n",
            "GT: impostor :  the party falsely pretended to possess the character in question\n",
            "Pred: empostor  :  the party tulsels prelended to possess the character in quistion\n",
            "--------------------------------------------------------------------------------\n",
            "Image: /content/kraken_bentham/lines/073_003_001_02_05.png\n",
            "Char accuracy: 90.70%\n",
            "GT: him to look for he may chance to meet under\n",
            "Pred: Thim to look tor be may chance to mect under\n",
            "--------------------------------------------------------------------------------\n",
            "Image: /content/kraken_bentham/lines/097_186_001_01_28.png\n",
            "Char accuracy: 90.62%\n",
            "GT: be prevailed upon not to overstock us with the worst description\n",
            "Pred: be prevaited Spossnt to overstock us with the worst  description\n",
            "--------------------------------------------------------------------------------\n",
            "Image: /content/kraken_bentham/lines/027_029_001_02_22.png\n",
            "Char accuracy: 90.48%\n",
            "GT: ceived without them .\n",
            "Pred: ccaived without them .\n",
            "--------------------------------------------------------------------------------\n",
            "Image: /content/kraken_bentham/lines/073_068_001_03_13.png\n",
            "Char accuracy: 90.48%\n",
            "GT: it might have this Inconvenience, that the\n",
            "Pred: it might have this Inconvenitnce , Whak the\n",
            "--------------------------------------------------------------------------------\n",
            "Image: /content/kraken_bentham/lines/027_029_001_02_17.png\n",
            "Char accuracy: 90.00%\n",
            "GT: duration .\n",
            "Pred: doration .\n",
            "--------------------------------------------------------------------------------\n",
            "Image: /content/kraken_bentham/lines/071_111_002_04_12.png\n",
            "Char accuracy: 90.00%\n",
            "GT: The Punishment of a Suborner shall be as follows :\n",
            "Pred: The bunishment of a Jubormer shall be as tollows .\n",
            "--------------------------------------------------------------------------------\n",
            "Image: /content/kraken_bentham/lines/116_405_001_01_17.png\n",
            "Char accuracy: 90.00%\n",
            "GT: the Jews .\n",
            "Pred: the Lews .\n",
            "--------------------------------------------------------------------------------\n",
            "Image: /content/kraken_bentham/lines/071_111_002_04_14.png\n",
            "Char accuracy: 89.47%\n",
            "GT: -y of an Impostor .\n",
            "Pred: 7y of an Impoistor .\n",
            "--------------------------------------------------------------------------------\n",
            "Image: /content/kraken_bentham/lines/116_405_001_01_21.png\n",
            "Char accuracy: 89.47%\n",
            "GT: from a Magistrate .\n",
            "Pred: pom a Magistrate .\n",
            "--------------------------------------------------------------------------------\n",
            "Image: /content/kraken_bentham/lines/116_405_004_01_10.png\n",
            "Char accuracy: 89.13%\n",
            "GT: and pass the word to the Lamp-lighter , at the\n",
            "Pred: and pass the word to tha Lamp lightet , or the\n",
            "--------------------------------------------------------------------------------\n",
            "Image: /content/kraken_bentham/lines/073_056_001_03_06.png\n",
            "Char accuracy: 88.89%\n",
            "GT: a Question , by whom is it to be determined , in every\n",
            "Pred: a Question , by whom is it to be determined , in\n",
            "--------------------------------------------------------------------------------\n",
            "Image: /content/kraken_bentham/lines/096_051_002_03_13.png\n",
            "Char accuracy: 88.89%\n",
            "GT: In short if we may be allowed to say what it ought not to be :  it ought\n",
            "Pred: In short of wmy allowed to vay what it ought not to be :  it ought\n",
            "--------------------------------------------------------------------------------\n",
            "Image: /content/kraken_bentham/lines/071_188_002_03_01.png\n",
            "Char accuracy: 88.24%\n",
            "GT: plan the order of the chapters or titles relative to offences of the\n",
            "Pred: plan the ordern of the chaptes or . litles rolative &o oftences of the\n"
          ]
        }
      ],
      "source": [
        "# -------------------------------------------\n",
        "# 1. Filter out invalid or meaningless results\n",
        "# -------------------------------------------\n",
        "\n",
        "filtered = []\n",
        "\n",
        "for r in results:\n",
        "    acc = r[\"char_accuracy\"]\n",
        "    gt = r[\"gt\"].strip()\n",
        "\n",
        "    # Skip invalid/meaningless examples:\n",
        "    if acc <= 0:                    # negative or zero accuracy\n",
        "        continue\n",
        "    if len(gt) < 3:                 # too short, e.g., 1–2 letters\n",
        "        continue\n",
        "    if len(gt.split()) < 2:         # require at least TWO words\n",
        "        continue\n",
        "\n",
        "    filtered.append(r)\n",
        "\n",
        "print(f\"Filtered results: kept {len(filtered)} out of {len(results)} samples.\")\n",
        "\n",
        "\n",
        "# -------------------------------------------\n",
        "# 2. Sort filtered results (best → worst)\n",
        "# -------------------------------------------\n",
        "filtered_sorted = sorted(filtered, key=lambda r: r[\"char_accuracy\"], reverse=True)\n",
        "\n",
        "\n",
        "# -------------------------------------------\n",
        "# 3. Print Top 10\n",
        "# -------------------------------------------\n",
        "top_k = 30\n",
        "top_examples = filtered_sorted[:top_k]\n",
        "\n",
        "print(f\"\\nTop {top_k} highest-accuracy FULL-SENTENCE examples:\\n\")\n",
        "for r in top_examples:\n",
        "    print(\"-\" * 80)\n",
        "    print(\"Image:\", r[\"image\"])\n",
        "    print(f\"Char accuracy: {r['char_accuracy']*100:.2f}%\")\n",
        "    print(\"GT:\", r[\"gt\"])\n",
        "    print(\"Pred:\", r[\"pred\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JgukbXH3cBn-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgukbXH3cBn-",
        "outputId": "cc70fc07-c16c-4477-f899-5bdcc7448e5b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'image': '/content/kraken_bentham/lines/071_132_001_01_01.png',\n",
              "  'gt': '17 .',\n",
              "  'pred': '17 .',\n",
              "  'char_accuracy': 1.0},\n",
              " {'image': '/content/kraken_bentham/lines/071_184_003_03_01.png',\n",
              "  'gt': 'Of Frauds relative to the Coin',\n",
              "  'pred': 'Of Frauds relative to the Coin',\n",
              "  'char_accuracy': 1.0},\n",
              " {'image': '/content/kraken_bentham/lines/071_192_004_01_01.png',\n",
              "  'gt': '16 .',\n",
              "  'pred': '16 .',\n",
              "  'char_accuracy': 1.0},\n",
              " {'image': '/content/kraken_bentham/lines/073_070_001_03_05.png',\n",
              "  'gt': 'that of',\n",
              "  'pred': 'that of',\n",
              "  'char_accuracy': 1.0},\n",
              " {'image': '/content/kraken_bentham/lines/073_073_001_03_13.png',\n",
              "  'gt': 'implies any such Thing . The ordinary',\n",
              "  'pred': 'implies any such Thing . he ordinary',\n",
              "  'char_accuracy': 0.972972972972973},\n",
              " {'image': '/content/kraken_bentham/lines/073_003_001_02_02.png',\n",
              "  'gt': 'inserting under one Title a proposition which',\n",
              "  'pred': 'inserting under one Tithe a poposition which',\n",
              "  'char_accuracy': 0.9555555555555556},\n",
              " {'image': '/content/kraken_bentham/lines/071_186_002_04_11.png',\n",
              "  'gt': 'stand altogether upon so good a footing :  since the distress',\n",
              "  'pred': 'stand allogether upon , so good a footing :  since the distress',\n",
              "  'char_accuracy': 0.9508196721311475},\n",
              " {'image': '/content/kraken_bentham/lines/072_049_004_04_19.png',\n",
              "  'gt': 'As to the mischief there would be in',\n",
              "  'pred': 'As to the mischif there would bhe in',\n",
              "  'char_accuracy': 0.9444444444444444},\n",
              " {'image': '/content/kraken_bentham/lines/073_003_002_01_15.png',\n",
              "  'gt': 'give the Reality , without contenting themselves',\n",
              "  'pred': 'give the Reality , without ententing themselvs',\n",
              "  'char_accuracy': 0.9375},\n",
              " {'image': '/content/kraken_bentham/lines/071_186_002_04_06.png',\n",
              "  'gt': 'in general nobody can know )  , whether the least part of it',\n",
              "  'pred': 'in general nobedy can know  , whether the least part of i',\n",
              "  'char_accuracy': 0.9333333333333333},\n",
              " {'image': '/content/kraken_bentham/lines/096_101_001_02_12.png',\n",
              "  'gt': 'can be assigned',\n",
              "  'pred': 'can be assignes',\n",
              "  'char_accuracy': 0.9333333333333333},\n",
              " {'image': '/content/kraken_bentham/lines/072_052_002_03_01.png',\n",
              "  'gt': 'Offences against the external Security of the State .',\n",
              "  'pred': 'Offences against the external Decurity of the Sate',\n",
              "  'char_accuracy': 0.9245283018867925},\n",
              " {'image': '/content/kraken_bentham/lines/096_099_004_01_05.png',\n",
              "  'gt': 'if instead of the Fine we take for the Punishment any',\n",
              "  'pred': 'if instead of the Tine we take for the Jurishment ony',\n",
              "  'char_accuracy': 0.9245283018867925},\n",
              " {'image': '/content/kraken_bentham/lines/072_066_003_03_01.png',\n",
              "  'gt': 'Of Idleness .',\n",
              "  'pred': 'O Idleness .',\n",
              "  'char_accuracy': 0.9230769230769231},\n",
              " {'image': '/content/kraken_bentham/lines/096_100_001_02_24.png',\n",
              "  'gt': 'would have nothing to do but to pay his third and',\n",
              "  'pred': 'would have nothiny 10 do But to pay his third and',\n",
              "  'char_accuracy': 0.9183673469387755},\n",
              " {'image': '/content/kraken_bentham/lines/071_120_002_05_01.png',\n",
              "  'gt': 'Exposition .',\n",
              "  'pred': 'Expoition .',\n",
              "  'char_accuracy': 0.9166666666666666},\n",
              " {'image': '/content/kraken_bentham/lines/071_111_002_04_18.png',\n",
              "  'gt': 'impostor :  the party falsely pretended to possess the character in question',\n",
              "  'pred': 'empostor  :  the party tulsels prelended to possess the character in quistion',\n",
              "  'char_accuracy': 0.9078947368421053},\n",
              " {'image': '/content/kraken_bentham/lines/073_003_001_02_05.png',\n",
              "  'gt': 'him to look for he may chance to meet under',\n",
              "  'pred': 'Thim to look tor be may chance to mect under',\n",
              "  'char_accuracy': 0.9069767441860466},\n",
              " {'image': '/content/kraken_bentham/lines/097_186_001_01_28.png',\n",
              "  'gt': 'be prevailed upon not to overstock us with the worst description',\n",
              "  'pred': 'be prevaited Spossnt to overstock us with the worst  description',\n",
              "  'char_accuracy': 0.90625},\n",
              " {'image': '/content/kraken_bentham/lines/027_029_001_02_22.png',\n",
              "  'gt': 'ceived without them .',\n",
              "  'pred': 'ccaived without them .',\n",
              "  'char_accuracy': 0.9047619047619048},\n",
              " {'image': '/content/kraken_bentham/lines/073_068_001_03_13.png',\n",
              "  'gt': 'it might have this Inconvenience, that the',\n",
              "  'pred': 'it might have this Inconvenitnce , Whak the',\n",
              "  'char_accuracy': 0.9047619047619048},\n",
              " {'image': '/content/kraken_bentham/lines/027_029_001_02_17.png',\n",
              "  'gt': 'duration .',\n",
              "  'pred': 'doration .',\n",
              "  'char_accuracy': 0.9},\n",
              " {'image': '/content/kraken_bentham/lines/071_111_002_04_12.png',\n",
              "  'gt': 'The Punishment of a Suborner shall be as follows :',\n",
              "  'pred': 'The bunishment of a Jubormer shall be as tollows .',\n",
              "  'char_accuracy': 0.9},\n",
              " {'image': '/content/kraken_bentham/lines/116_405_001_01_17.png',\n",
              "  'gt': 'the Jews .',\n",
              "  'pred': 'the Lews .',\n",
              "  'char_accuracy': 0.9},\n",
              " {'image': '/content/kraken_bentham/lines/071_111_002_04_14.png',\n",
              "  'gt': '-y of an Impostor .',\n",
              "  'pred': '7y of an Impoistor .',\n",
              "  'char_accuracy': 0.8947368421052632},\n",
              " {'image': '/content/kraken_bentham/lines/116_405_001_01_21.png',\n",
              "  'gt': 'from a Magistrate .',\n",
              "  'pred': 'pom a Magistrate .',\n",
              "  'char_accuracy': 0.8947368421052632},\n",
              " {'image': '/content/kraken_bentham/lines/116_405_004_01_10.png',\n",
              "  'gt': 'and pass the word to the Lamp-lighter , at the',\n",
              "  'pred': 'and pass the word to tha Lamp lightet , or the',\n",
              "  'char_accuracy': 0.8913043478260869},\n",
              " {'image': '/content/kraken_bentham/lines/073_056_001_03_06.png',\n",
              "  'gt': 'a Question , by whom is it to be determined , in every',\n",
              "  'pred': 'a Question , by whom is it to be determined , in',\n",
              "  'char_accuracy': 0.8888888888888888},\n",
              " {'image': '/content/kraken_bentham/lines/096_051_002_03_13.png',\n",
              "  'gt': 'In short if we may be allowed to say what it ought not to be :  it ought',\n",
              "  'pred': 'In short of wmy allowed to vay what it ought not to be :  it ought',\n",
              "  'char_accuracy': 0.8888888888888888},\n",
              " {'image': '/content/kraken_bentham/lines/071_188_002_03_01.png',\n",
              "  'gt': 'plan the order of the chapters or titles relative to offences of the',\n",
              "  'pred': 'plan the ordern of the chaptes or . litles rolative &o oftences of the',\n",
              "  'char_accuracy': 0.8823529411764706}]"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "top_examples"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dJPtA0pic45N",
      "metadata": {
        "id": "dJPtA0pic45N"
      },
      "source": [
        "# Save top_examples as an Excel file (.xlsx) and copy to Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QeUc7Nbzc7MN",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeUc7Nbzc7MN",
        "outputId": "af01d2b7-b0a7-4799-efa4-99f47ca966ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved Excel file locally at: /content/top_kraken_examples.xlsx\n",
            "Copied Excel file to Google Drive at: /content/drive/MyDrive/top_kraken_examples.xlsx\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Convert list of dicts (top_examples) to a DataFrame\n",
        "df_top = pd.DataFrame(top_examples)\n",
        "\n",
        "# Local save path in Colab\n",
        "xlsx_path = \"/content/top_kraken_examples.xlsx\"\n",
        "\n",
        "# Save DataFrame as an Excel file\n",
        "df_top.to_excel(xlsx_path, index=False, engine=\"openpyxl\")\n",
        "print(\"Saved Excel file locally at:\", xlsx_path)\n",
        "\n",
        "# Copy to Google Drive (Drive must be mounted!)\n",
        "drive_path = \"/content/drive/MyDrive/top_kraken_examples.xlsx\"\n",
        "os.system(f\"cp '{xlsx_path}' '{drive_path}'\")\n",
        "print(\"Copied Excel file to Google Drive at:\", drive_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cFbEO0vudEsl",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFbEO0vudEsl",
        "outputId": "69059a79-5b33-4212-c8cd-132d54e48b79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved CSV locally at: /content/top_kraken_examples.csv\n",
            "Copied CSV to Google Drive at: /content/drive/MyDrive/top_kraken_examples.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Convert top examples to a DataFrame\n",
        "df_top = pd.DataFrame(top_examples)\n",
        "\n",
        "# Path to save locally in Colab\n",
        "csv_path = \"/content/top_kraken_examples.csv\"\n",
        "\n",
        "# Save as CSV\n",
        "df_top.to_csv(csv_path, index=False, encoding=\"utf-8\")\n",
        "print(\"Saved CSV locally at:\", csv_path)\n",
        "\n",
        "# Copy to Google Drive (your drive must be mounted!)\n",
        "drive_path = \"/content/drive/MyDrive/top_kraken_examples.csv\"\n",
        "os.system(f\"cp {csv_path} '{drive_path}'\")\n",
        "print(\"Copied CSV to Google Drive at:\", drive_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "z3eGV_wZdP7c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "z3eGV_wZdP7c",
        "outputId": "20a907a6-29e1-45a0-db3a-78b9693d1033"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df_top\",\n  \"rows\": 30,\n  \"fields\": [\n    {\n      \"column\": \"image\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          \"/content/kraken_bentham/lines/073_056_001_03_06.png\",\n          \"/content/kraken_bentham/lines/071_120_002_05_01.png\",\n          \"/content/kraken_bentham/lines/116_405_001_01_17.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          \"a Question , by whom is it to be determined , in every\",\n          \"Exposition .\",\n          \"the Jews .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          \"a Question , by whom is it to be determined , in\",\n          \"Expoition .\",\n          \"the Lews .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"char_accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.036266484894971654,\n        \"min\": 0.8823529411764706,\n        \"max\": 1.0,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          1.0,\n          0.8913043478260869,\n          0.9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df_top"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-a7446ee2-5a28-4e5d-b048-4bf67252ed27\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>gt</th>\n",
              "      <th>pred</th>\n",
              "      <th>char_accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/kraken_bentham/lines/071_132_001_01_0...</td>\n",
              "      <td>17 .</td>\n",
              "      <td>17 .</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/kraken_bentham/lines/071_184_003_03_0...</td>\n",
              "      <td>Of Frauds relative to the Coin</td>\n",
              "      <td>Of Frauds relative to the Coin</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/kraken_bentham/lines/071_192_004_01_0...</td>\n",
              "      <td>16 .</td>\n",
              "      <td>16 .</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/kraken_bentham/lines/073_070_001_03_0...</td>\n",
              "      <td>that of</td>\n",
              "      <td>that of</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/kraken_bentham/lines/073_073_001_03_1...</td>\n",
              "      <td>implies any such Thing . The ordinary</td>\n",
              "      <td>implies any such Thing . he ordinary</td>\n",
              "      <td>0.972973</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a7446ee2-5a28-4e5d-b048-4bf67252ed27')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a7446ee2-5a28-4e5d-b048-4bf67252ed27 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a7446ee2-5a28-4e5d-b048-4bf67252ed27');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-b6b5f50e-fd6e-422e-8d61-432b601fb77a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b6b5f50e-fd6e-422e-8d61-432b601fb77a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-b6b5f50e-fd6e-422e-8d61-432b601fb77a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                               image  \\\n",
              "0  /content/kraken_bentham/lines/071_132_001_01_0...   \n",
              "1  /content/kraken_bentham/lines/071_184_003_03_0...   \n",
              "2  /content/kraken_bentham/lines/071_192_004_01_0...   \n",
              "3  /content/kraken_bentham/lines/073_070_001_03_0...   \n",
              "4  /content/kraken_bentham/lines/073_073_001_03_1...   \n",
              "\n",
              "                                      gt  \\\n",
              "0                                   17 .   \n",
              "1         Of Frauds relative to the Coin   \n",
              "2                                   16 .   \n",
              "3                                that of   \n",
              "4  implies any such Thing . The ordinary   \n",
              "\n",
              "                                   pred  char_accuracy  \n",
              "0                                  17 .       1.000000  \n",
              "1        Of Frauds relative to the Coin       1.000000  \n",
              "2                                  16 .       1.000000  \n",
              "3                               that of       1.000000  \n",
              "4  implies any such Thing . he ordinary       0.972973  "
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_top.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "nLJXuWEevrXO",
      "metadata": {
        "id": "nLJXuWEevrXO"
      },
      "source": [
        "# Normalize Results with NLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ul65GnLHvvbz",
      "metadata": {
        "id": "ul65GnLHvvbz"
      },
      "outputs": [],
      "source": [
        "# 0. Install dependencies (run once per Colab session)\n",
        "!pip install -q transformers accelerate sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AzFjTC9hv12Q",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362,
          "referenced_widgets": [
            "e7abf648439e41eda193f44004fe8ea7",
            "e509163200f247d290e250795f376ac0",
            "4066b2cd82144ff38b37e6da6eb97250",
            "68da279ebeb74a468da07192c0901728",
            "6e8842a2198041f9a1ccea2d5c027230",
            "15f2635a7e6747a0ad08788125e9e62a",
            "9c51df9fc520472e8b39bdb0ef163d47",
            "511fc9286973472e85ba63f6a99b2af5",
            "ddda57744e7b4f3abeb59bc834cd2c3b",
            "5df232590a7d4eb29d61768acb0ddcf4",
            "74b4222b8a784be3b7646fd1d7beb358",
            "80fcab8023f54fe89fef526561cbe342",
            "2ad787b5decf46a5bf2929ef2097fac8",
            "93edfe99d9114e7a9b714a5d17a377d1",
            "30c43287851e4421beb3945c9c15f2c2",
            "c222e97eadb8432c9e74d71c2221b632",
            "77c492b539964f8da00f2d3a3c1e80ff",
            "0f10ec3d2ca04de58f43c6a733dd748c",
            "cf7abfc02db743108d65e9c2cd8cfedb",
            "8511f0fd840e4126b61308abc17a353a",
            "aba0489817b340f5825f1d63baf1d355",
            "5cc5310312cb4c28b85aac2ef8c0cee2",
            "9faf732018594b228376117623d0ccdf",
            "e6e8e8cd0c684e89b7593b654fe6e695",
            "c06520a8ef20448984a8d7a40a3ee76a",
            "86655ce9dc604faab769f91c12ee6597",
            "bf23bb8689974b788e5a99170819c261",
            "a21d35bca42c47c7a793cb81243b7ac1",
            "f7ae9d4c043e4eb3b37c1553ade4d014",
            "9136cd0a4e3f4005841cda102a2d04d4",
            "e4e4e792ab774db986d629aef118811d",
            "3232b06fa890401691a3ebfbf87ae647",
            "51e104d558ba47578e4255dfc0a36d1a",
            "565c8e5dac184f4196a59e1d9fc13908",
            "bcded2d5c6134d079dc6e3633bdc21b7",
            "160cf643a0434e17b013f135c9e67178",
            "5f4347215b4e4560b0f7aaa336b64050",
            "6623617909f84cc8b52fea45d07e8663",
            "55db0e908da7414587eedc31e9ed050f",
            "cd012c0f10d949e2ba092ecde1221c5e",
            "a21b477112054b75be3b1da65f03ea01",
            "b67f52574f5441c9945206bb70900cf9",
            "aaaf6168a60346c8bec54bebc7d9862e",
            "52f41bacf33d4b248fa64be7e77674d2",
            "4531b03b11394caf80aceac09342764e",
            "bf67a88d975e4cf4b73d7966798006e3",
            "fb07c430958c49fcbe03a927499d4afb",
            "29ddf3b6009e49d2ad00d6cc8d3563ef",
            "40c802a96dba49baa3237957afc814bb",
            "8174d06daab347ba95ff3aeaede34c32",
            "b83fa705596d4eb69ce1f3bf958b0207",
            "463c6619bb74423f95442b3a38f03840",
            "70b9bf493be44b9b846f429adc160e2d",
            "b0f17db4587247b786620ffb9c48fcd3",
            "492aa3e2d71c420a8e09a61f3d6ef356",
            "f74251c42cc848b1bae2f05aa1e08000",
            "72590a076f2f4904952877f10a2df9b9",
            "71e0f5e821fe42a7b02c2f28a11073f9",
            "df35567881554e70b6abea545a0f4bdd",
            "74b661c8d2bd4283b2297a2088430eb2",
            "e52cb16b70364de1bfae9877d560876f",
            "2702c0fc06c041588685efe6085f7f3f",
            "a2766b7e251640a2bf642175756118d7",
            "ce8a80c5847d46fa919adfbda3dcc9a2",
            "4b13492a0d3e461c80a8e1f4c3dbb696",
            "fe866cc181424624915fd0b530e3ceed",
            "c5a9015ac179460ab77b78f7a21866a1",
            "11b688b8d80743a5905441a2b2c9a353",
            "7e71d68b6b21467e9a5ffe72169116d9",
            "6db63339a46d436d89de254f494d138c",
            "0515d7e119084f6996666348071a9f87",
            "382633c886fb479286bbb124b2c9ebe9",
            "441ff29a557d4aa986311b3575d4e520",
            "59639aecd1d943018780adb59cf5074f",
            "1d699feee53d43aba84a3ae4f4d63af1",
            "4deb5dbd9e824987b9fcd54071e6767b",
            "1940670e100e402bb464a405bf0df90d"
          ]
        },
        "id": "AzFjTC9hv12Q",
        "outputId": "28237826-e600-4301-8d0f-6d685713a7fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded DataFrame with columns: ['image', 'gt', 'pred', 'char_accuracy']\n",
            "Number of rows: 30\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e7abf648439e41eda193f44004fe8ea7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "80fcab8023f54fe89fef526561cbe342",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9faf732018594b228376117623d0ccdf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "565c8e5dac184f4196a59e1d9fc13908",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4531b03b11394caf80aceac09342764e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/662 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f74251c42cc848b1bae2f05aa1e08000",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/3.13G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c5a9015ac179460ab77b78f7a21866a1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "Processed 10 / 30 predictions\n",
            "Processed 20 / 30 predictions\n",
            "Processed 30 / 30 predictions\n",
            "Saved normalized results to: /content/drive/MyDrive/top_kraken_examples_normalized.xlsx\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "# 1. Load the DataFrame from your Drive\n",
        "input_path = \"/content/drive/MyDrive/top_kraken_examples.xlsx\"\n",
        "df = pd.read_excel(input_path)\n",
        "\n",
        "print(\"Loaded DataFrame with columns:\", df.columns.tolist())\n",
        "print(\"Number of rows:\", len(df))\n",
        "\n",
        "# 2. Load an instruction-tuned T5 model (good for sentence correction)\n",
        "model_name = \"google/flan-t5-large\"   # you can try \"google/flan-t5-large\" if you have more VRAM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# 3. Normalization function using the language model\n",
        "def normalize_ocr_sentence(text: str, max_new_tokens: int = 64) -> str:\n",
        "    \"\"\"\n",
        "    Use an instruction-tuned seq2seq model (e.g. FLAN-T5) to correct OCR errors\n",
        "    in a single sentence of English text.\n",
        "\n",
        "    The prompt is designed to be general and robust, not tailored to specific examples.\n",
        "    \"\"\"\n",
        "    if not isinstance(text, str):\n",
        "        return text\n",
        "    stripped = text.strip()\n",
        "    if not stripped:\n",
        "        return text\n",
        "\n",
        "    prompt = (\n",
        "        \"You are a post-OCR correction model for English text. \"\n",
        "        \"Your job is to correct typical OCR errors while preserving the original \"\n",
        "        \"meaning and style of the sentence.\\n\\n\"\n",
        "        \"Follow these rules strictly:\\n\"\n",
        "        \"1. Fix spelling mistakes and non-words caused by OCR (for example: \"\n",
        "        \"missing letters, extra letters, or letter swaps).\\n\"\n",
        "        \"2. Fix common OCR character confusions such as:\\n\"\n",
        "        \"   - t ↔ f\\n\"\n",
        "        \"   - l / I / 1\\n\"\n",
        "        \"   - rn ↔ m\\n\"\n",
        "        \"   - h ↔ b\\n\"\n",
        "        \"   - u ↔ v\\n\"\n",
        "        \"   - c ↔ e\\n\"\n",
        "        \"3. Prefer real English words that fit the sentence context over strings \"\n",
        "        \"that are not valid words.\\n\"\n",
        "        \"4. Do NOT add or remove whole ideas or clauses. Only correct surface \"\n",
        "        \"errors in the existing sentence.\\n\"\n",
        "        \"5. Keep the original sentence structure, punctuation, and capitalization \"\n",
        "        \"as much as possible, only fixing them when they are clearly wrong.\\n\"\n",
        "        \"6. Output ONLY the corrected sentence, with no explanations or extra text.\\n\\n\"\n",
        "        f\"Sentence to correct:\\n{stripped}\\n\\n\"\n",
        "        \"Corrected sentence:\"\n",
        "    )\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            num_beams=6,         # a bit more search than before\n",
        "            length_penalty=1.0,\n",
        "            early_stopping=True,\n",
        "        )\n",
        "\n",
        "    corrected = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return corrected.strip()\n",
        "\n",
        "\n",
        "# 4. Apply the model to the 'pred' column\n",
        "#    (this may take a bit of time if you have many rows)\n",
        "normalized_preds = []\n",
        "for i, txt in enumerate(df[\"pred\"].tolist()):\n",
        "    norm = normalize_ocr_sentence(txt)\n",
        "    normalized_preds.append(norm)\n",
        "    if (i + 1) % 10 == 0:  # small progress log every 10 lines\n",
        "        print(f\"Processed {i+1} / {len(df)} predictions\")\n",
        "\n",
        "df[\"pred_normalized\"] = normalized_preds\n",
        "\n",
        "# 5. Save the updated DataFrame as a new Excel file on Drive\n",
        "output_path = \"/content/drive/MyDrive/top_kraken_examples_normalized.xlsx\"\n",
        "df.to_excel(output_path, index=False)\n",
        "print(\"Saved normalized results to:\", output_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wxqMoGbZwbci",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wxqMoGbZwbci",
        "outputId": "4780d407-e4bb-4b9c-c447-68015494421d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 30,\n  \"fields\": [\n    {\n      \"column\": \"image\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          \"/content/kraken_bentham/lines/073_056_001_03_06.png\",\n          \"/content/kraken_bentham/lines/071_120_002_05_01.png\",\n          \"/content/kraken_bentham/lines/116_405_001_01_17.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          \"a Question , by whom is it to be determined , in every\",\n          \"Exposition .\",\n          \"the Jews .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          \"a Question , by whom is it to be determined , in\",\n          \"Expoition .\",\n          \"the Lews .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"char_accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.036266484894971654,\n        \"min\": 0.8823529411764706,\n        \"max\": 1.0,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          1.0,\n          0.8913043478260869,\n          0.9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_normalized\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          \"A Question , by whom is it to be determined , in\",\n          \"Exposion .\",\n          \"the Lews .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-c1209de3-4092-4b57-bc21-afebe2c382c3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>gt</th>\n",
              "      <th>pred</th>\n",
              "      <th>char_accuracy</th>\n",
              "      <th>pred_normalized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/kraken_bentham/lines/071_132_001_01_0...</td>\n",
              "      <td>17 .</td>\n",
              "      <td>17 .</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>17 .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/kraken_bentham/lines/071_184_003_03_0...</td>\n",
              "      <td>Of Frauds relative to the Coin</td>\n",
              "      <td>Of Frauds relative to the Coin</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>Of Frauds relative to the Coin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/kraken_bentham/lines/071_192_004_01_0...</td>\n",
              "      <td>16 .</td>\n",
              "      <td>16 .</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>16 .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/kraken_bentham/lines/073_070_001_03_0...</td>\n",
              "      <td>that of</td>\n",
              "      <td>that of</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>that of</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/kraken_bentham/lines/073_073_001_03_1...</td>\n",
              "      <td>implies any such Thing . The ordinary</td>\n",
              "      <td>implies any such Thing . he ordinary</td>\n",
              "      <td>0.972973</td>\n",
              "      <td>imply any such Thing . he ordinary</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>/content/kraken_bentham/lines/073_003_001_02_0...</td>\n",
              "      <td>inserting under one Title a proposition which</td>\n",
              "      <td>inserting under one Tithe a poposition which</td>\n",
              "      <td>0.955556</td>\n",
              "      <td>inserting under one Tithe a poposition which</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>/content/kraken_bentham/lines/071_186_002_04_1...</td>\n",
              "      <td>stand altogether upon so good a footing :  sin...</td>\n",
              "      <td>stand allogether upon , so good a footing :  s...</td>\n",
              "      <td>0.950820</td>\n",
              "      <td>stand allogether upon, so good a footing : sin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>/content/kraken_bentham/lines/072_049_004_04_1...</td>\n",
              "      <td>As to the mischief there would be in</td>\n",
              "      <td>As to the mischif there would bhe in</td>\n",
              "      <td>0.944444</td>\n",
              "      <td>As to the mischif there would be bhe in</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>/content/kraken_bentham/lines/073_003_002_01_1...</td>\n",
              "      <td>give the Reality , without contenting themselves</td>\n",
              "      <td>give the Reality , without ententing themselvs</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>give the Reality , without ententing themselvs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>/content/kraken_bentham/lines/071_186_002_04_0...</td>\n",
              "      <td>in general nobody can know )  , whether the le...</td>\n",
              "      <td>in general nobedy can know  , whether the leas...</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>in general nobedy can know , whether the least...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>/content/kraken_bentham/lines/096_101_001_02_1...</td>\n",
              "      <td>can be assigned</td>\n",
              "      <td>can be assignes</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>Can be assigned</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>/content/kraken_bentham/lines/072_052_002_03_0...</td>\n",
              "      <td>Offences against the external Security of the ...</td>\n",
              "      <td>Offences against the external Decurity of the ...</td>\n",
              "      <td>0.924528</td>\n",
              "      <td>Offences against the internal Decurity of the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>/content/kraken_bentham/lines/096_099_004_01_0...</td>\n",
              "      <td>if instead of the Fine we take for the Punishm...</td>\n",
              "      <td>if instead of the Tine we take for the Jurishm...</td>\n",
              "      <td>0.924528</td>\n",
              "      <td>if instead of the Tine we take for the Jurishment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>/content/kraken_bentham/lines/072_066_003_03_0...</td>\n",
              "      <td>Of Idleness .</td>\n",
              "      <td>O Idleness .</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>Idleness .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>/content/kraken_bentham/lines/096_100_001_02_2...</td>\n",
              "      <td>would have nothing to do but to pay his third and</td>\n",
              "      <td>would have nothiny 10 do But to pay his third and</td>\n",
              "      <td>0.918367</td>\n",
              "      <td>would have nothiny 10 do But to pay his third and</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>/content/kraken_bentham/lines/071_120_002_05_0...</td>\n",
              "      <td>Exposition .</td>\n",
              "      <td>Expoition .</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>Exposion .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>/content/kraken_bentham/lines/071_111_002_04_1...</td>\n",
              "      <td>impostor :  the party falsely pretended to pos...</td>\n",
              "      <td>empostor  :  the party tulsels prelended to po...</td>\n",
              "      <td>0.907895</td>\n",
              "      <td>The party tulsels prelended to possess the cha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>/content/kraken_bentham/lines/073_003_001_02_0...</td>\n",
              "      <td>him to look for he may chance to meet under</td>\n",
              "      <td>Thim to look tor be may chance to mect under</td>\n",
              "      <td>0.906977</td>\n",
              "      <td>Thim to look tor be may chance to mect under</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>/content/kraken_bentham/lines/097_186_001_01_2...</td>\n",
              "      <td>be prevailed upon not to overstock us with the...</td>\n",
              "      <td>be prevaited Spossnt to overstock us with the ...</td>\n",
              "      <td>0.906250</td>\n",
              "      <td>be prevaited Spossnt to overstock us with the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>/content/kraken_bentham/lines/027_029_001_02_2...</td>\n",
              "      <td>ceived without them .</td>\n",
              "      <td>ccaived without them .</td>\n",
              "      <td>0.904762</td>\n",
              "      <td>ccaived without them .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>/content/kraken_bentham/lines/073_068_001_03_1...</td>\n",
              "      <td>it might have this Inconvenience, that the</td>\n",
              "      <td>it might have this Inconvenitnce , Whak the</td>\n",
              "      <td>0.904762</td>\n",
              "      <td>it might have this Inconvenitnce, Whak</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>/content/kraken_bentham/lines/027_029_001_02_1...</td>\n",
              "      <td>duration .</td>\n",
              "      <td>doration .</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>doration .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>/content/kraken_bentham/lines/071_111_002_04_1...</td>\n",
              "      <td>The Punishment of a Suborner shall be as follo...</td>\n",
              "      <td>The bunishment of a Jubormer shall be as tollo...</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>The bunishment of a Jubormer shall be as tollo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>/content/kraken_bentham/lines/116_405_001_01_1...</td>\n",
              "      <td>the Jews .</td>\n",
              "      <td>the Lews .</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>the Lews .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>/content/kraken_bentham/lines/071_111_002_04_1...</td>\n",
              "      <td>-y of an Impostor .</td>\n",
              "      <td>7y of an Impoistor .</td>\n",
              "      <td>0.894737</td>\n",
              "      <td>7y of an Impoistor .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>/content/kraken_bentham/lines/116_405_001_01_2...</td>\n",
              "      <td>from a Magistrate .</td>\n",
              "      <td>pom a Magistrate .</td>\n",
              "      <td>0.894737</td>\n",
              "      <td>pom a Magistrate .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>/content/kraken_bentham/lines/116_405_004_01_1...</td>\n",
              "      <td>and pass the word to the Lamp-lighter , at the</td>\n",
              "      <td>and pass the word to tha Lamp lightet , or the</td>\n",
              "      <td>0.891304</td>\n",
              "      <td>and pass the word to tha Lamp lightet , or</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>/content/kraken_bentham/lines/073_056_001_03_0...</td>\n",
              "      <td>a Question , by whom is it to be determined , ...</td>\n",
              "      <td>a Question , by whom is it to be determined , in</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>A Question , by whom is it to be determined , in</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>/content/kraken_bentham/lines/096_051_002_03_1...</td>\n",
              "      <td>In short if we may be allowed to say what it o...</td>\n",
              "      <td>In short of wmy allowed to vay what it ought n...</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>In short of wmy allowed to vay what it ought n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>/content/kraken_bentham/lines/071_188_002_03_0...</td>\n",
              "      <td>plan the order of the chapters or titles relat...</td>\n",
              "      <td>plan the ordern of the chaptes or . litles rol...</td>\n",
              "      <td>0.882353</td>\n",
              "      <td>the ordern of the chaptes or . litles rolative...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c1209de3-4092-4b57-bc21-afebe2c382c3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c1209de3-4092-4b57-bc21-afebe2c382c3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c1209de3-4092-4b57-bc21-afebe2c382c3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a15a4cd7-a6fe-4a61-9672-2f0f0d60811a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a15a4cd7-a6fe-4a61-9672-2f0f0d60811a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a15a4cd7-a6fe-4a61-9672-2f0f0d60811a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_e9786a4e-2fff-43fc-a3b6-2de75c8f69af\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_e9786a4e-2fff-43fc-a3b6-2de75c8f69af button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                image  \\\n",
              "0   /content/kraken_bentham/lines/071_132_001_01_0...   \n",
              "1   /content/kraken_bentham/lines/071_184_003_03_0...   \n",
              "2   /content/kraken_bentham/lines/071_192_004_01_0...   \n",
              "3   /content/kraken_bentham/lines/073_070_001_03_0...   \n",
              "4   /content/kraken_bentham/lines/073_073_001_03_1...   \n",
              "5   /content/kraken_bentham/lines/073_003_001_02_0...   \n",
              "6   /content/kraken_bentham/lines/071_186_002_04_1...   \n",
              "7   /content/kraken_bentham/lines/072_049_004_04_1...   \n",
              "8   /content/kraken_bentham/lines/073_003_002_01_1...   \n",
              "9   /content/kraken_bentham/lines/071_186_002_04_0...   \n",
              "10  /content/kraken_bentham/lines/096_101_001_02_1...   \n",
              "11  /content/kraken_bentham/lines/072_052_002_03_0...   \n",
              "12  /content/kraken_bentham/lines/096_099_004_01_0...   \n",
              "13  /content/kraken_bentham/lines/072_066_003_03_0...   \n",
              "14  /content/kraken_bentham/lines/096_100_001_02_2...   \n",
              "15  /content/kraken_bentham/lines/071_120_002_05_0...   \n",
              "16  /content/kraken_bentham/lines/071_111_002_04_1...   \n",
              "17  /content/kraken_bentham/lines/073_003_001_02_0...   \n",
              "18  /content/kraken_bentham/lines/097_186_001_01_2...   \n",
              "19  /content/kraken_bentham/lines/027_029_001_02_2...   \n",
              "20  /content/kraken_bentham/lines/073_068_001_03_1...   \n",
              "21  /content/kraken_bentham/lines/027_029_001_02_1...   \n",
              "22  /content/kraken_bentham/lines/071_111_002_04_1...   \n",
              "23  /content/kraken_bentham/lines/116_405_001_01_1...   \n",
              "24  /content/kraken_bentham/lines/071_111_002_04_1...   \n",
              "25  /content/kraken_bentham/lines/116_405_001_01_2...   \n",
              "26  /content/kraken_bentham/lines/116_405_004_01_1...   \n",
              "27  /content/kraken_bentham/lines/073_056_001_03_0...   \n",
              "28  /content/kraken_bentham/lines/096_051_002_03_1...   \n",
              "29  /content/kraken_bentham/lines/071_188_002_03_0...   \n",
              "\n",
              "                                                   gt  \\\n",
              "0                                                17 .   \n",
              "1                      Of Frauds relative to the Coin   \n",
              "2                                                16 .   \n",
              "3                                             that of   \n",
              "4               implies any such Thing . The ordinary   \n",
              "5       inserting under one Title a proposition which   \n",
              "6   stand altogether upon so good a footing :  sin...   \n",
              "7                As to the mischief there would be in   \n",
              "8    give the Reality , without contenting themselves   \n",
              "9   in general nobody can know )  , whether the le...   \n",
              "10                                    can be assigned   \n",
              "11  Offences against the external Security of the ...   \n",
              "12  if instead of the Fine we take for the Punishm...   \n",
              "13                                      Of Idleness .   \n",
              "14  would have nothing to do but to pay his third and   \n",
              "15                                       Exposition .   \n",
              "16  impostor :  the party falsely pretended to pos...   \n",
              "17        him to look for he may chance to meet under   \n",
              "18  be prevailed upon not to overstock us with the...   \n",
              "19                              ceived without them .   \n",
              "20         it might have this Inconvenience, that the   \n",
              "21                                         duration .   \n",
              "22  The Punishment of a Suborner shall be as follo...   \n",
              "23                                         the Jews .   \n",
              "24                                -y of an Impostor .   \n",
              "25                                from a Magistrate .   \n",
              "26     and pass the word to the Lamp-lighter , at the   \n",
              "27  a Question , by whom is it to be determined , ...   \n",
              "28  In short if we may be allowed to say what it o...   \n",
              "29  plan the order of the chapters or titles relat...   \n",
              "\n",
              "                                                 pred  char_accuracy  \\\n",
              "0                                                17 .       1.000000   \n",
              "1                      Of Frauds relative to the Coin       1.000000   \n",
              "2                                                16 .       1.000000   \n",
              "3                                             that of       1.000000   \n",
              "4                implies any such Thing . he ordinary       0.972973   \n",
              "5        inserting under one Tithe a poposition which       0.955556   \n",
              "6   stand allogether upon , so good a footing :  s...       0.950820   \n",
              "7                As to the mischif there would bhe in       0.944444   \n",
              "8      give the Reality , without ententing themselvs       0.937500   \n",
              "9   in general nobedy can know  , whether the leas...       0.933333   \n",
              "10                                    can be assignes       0.933333   \n",
              "11  Offences against the external Decurity of the ...       0.924528   \n",
              "12  if instead of the Tine we take for the Jurishm...       0.924528   \n",
              "13                                       O Idleness .       0.923077   \n",
              "14  would have nothiny 10 do But to pay his third and       0.918367   \n",
              "15                                        Expoition .       0.916667   \n",
              "16  empostor  :  the party tulsels prelended to po...       0.907895   \n",
              "17       Thim to look tor be may chance to mect under       0.906977   \n",
              "18  be prevaited Spossnt to overstock us with the ...       0.906250   \n",
              "19                             ccaived without them .       0.904762   \n",
              "20        it might have this Inconvenitnce , Whak the       0.904762   \n",
              "21                                         doration .       0.900000   \n",
              "22  The bunishment of a Jubormer shall be as tollo...       0.900000   \n",
              "23                                         the Lews .       0.900000   \n",
              "24                               7y of an Impoistor .       0.894737   \n",
              "25                                 pom a Magistrate .       0.894737   \n",
              "26     and pass the word to tha Lamp lightet , or the       0.891304   \n",
              "27   a Question , by whom is it to be determined , in       0.888889   \n",
              "28  In short of wmy allowed to vay what it ought n...       0.888889   \n",
              "29  plan the ordern of the chaptes or . litles rol...       0.882353   \n",
              "\n",
              "                                      pred_normalized  \n",
              "0                                                17 .  \n",
              "1                      Of Frauds relative to the Coin  \n",
              "2                                                16 .  \n",
              "3                                             that of  \n",
              "4                  imply any such Thing . he ordinary  \n",
              "5        inserting under one Tithe a poposition which  \n",
              "6   stand allogether upon, so good a footing : sin...  \n",
              "7             As to the mischif there would be bhe in  \n",
              "8      give the Reality , without ententing themselvs  \n",
              "9   in general nobedy can know , whether the least...  \n",
              "10                                    Can be assigned  \n",
              "11  Offences against the internal Decurity of the ...  \n",
              "12  if instead of the Tine we take for the Jurishment  \n",
              "13                                         Idleness .  \n",
              "14  would have nothiny 10 do But to pay his third and  \n",
              "15                                         Exposion .  \n",
              "16  The party tulsels prelended to possess the cha...  \n",
              "17       Thim to look tor be may chance to mect under  \n",
              "18  be prevaited Spossnt to overstock us with the ...  \n",
              "19                             ccaived without them .  \n",
              "20             it might have this Inconvenitnce, Whak  \n",
              "21                                         doration .  \n",
              "22  The bunishment of a Jubormer shall be as tollo...  \n",
              "23                                         the Lews .  \n",
              "24                               7y of an Impoistor .  \n",
              "25                                 pom a Magistrate .  \n",
              "26         and pass the word to tha Lamp lightet , or  \n",
              "27   A Question , by whom is it to be determined , in  \n",
              "28  In short of wmy allowed to vay what it ought n...  \n",
              "29  the ordern of the chaptes or . litles rolative...  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rLASqzFkz-wl",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLASqzFkz-wl",
        "outputId": "f43b290e-a753-41c6-a836-c04899774983"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "GT:   17 .\n",
            "PRED: 17 .\n",
            "NORM: 17 .\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   Of Frauds relative to the Coin\n",
            "PRED: Of Frauds relative to the Coin\n",
            "NORM: Of Frauds relative to the Coin\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   16 .\n",
            "PRED: 16 .\n",
            "NORM: 16 .\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   that of\n",
            "PRED: that of\n",
            "NORM: that of\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   implies any such Thing . The ordinary\n",
            "PRED: implies any such Thing . he ordinary\n",
            "NORM: imply any such Thing . he ordinary\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   inserting under one Title a proposition which\n",
            "PRED: inserting under one Tithe a poposition which\n",
            "NORM: inserting under one Tithe a poposition which\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   stand altogether upon so good a footing :  since the distress\n",
            "PRED: stand allogether upon , so good a footing :  since the distress\n",
            "NORM: stand allogether upon, so good a footing : since the distress\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   As to the mischief there would be in\n",
            "PRED: As to the mischif there would bhe in\n",
            "NORM: As to the mischif there would be bhe in\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   give the Reality , without contenting themselves\n",
            "PRED: give the Reality , without ententing themselvs\n",
            "NORM: give the Reality , without ententing themselvs\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   in general nobody can know )  , whether the least part of it\n",
            "PRED: in general nobedy can know  , whether the least part of i\n",
            "NORM: in general nobedy can know , whether the least part of i\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   can be assigned\n",
            "PRED: can be assignes\n",
            "NORM: Can be assigned\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   Offences against the external Security of the State .\n",
            "PRED: Offences against the external Decurity of the Sate\n",
            "NORM: Offences against the internal Decurity of the Sate\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   if instead of the Fine we take for the Punishment any\n",
            "PRED: if instead of the Tine we take for the Jurishment ony\n",
            "NORM: if instead of the Tine we take for the Jurishment\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   Of Idleness .\n",
            "PRED: O Idleness .\n",
            "NORM: Idleness .\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   would have nothing to do but to pay his third and\n",
            "PRED: would have nothiny 10 do But to pay his third and\n",
            "NORM: would have nothiny 10 do But to pay his third and\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   Exposition .\n",
            "PRED: Expoition .\n",
            "NORM: Exposion .\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   impostor :  the party falsely pretended to possess the character in question\n",
            "PRED: empostor  :  the party tulsels prelended to possess the character in quistion\n",
            "NORM: The party tulsels prelended to possess the character in quistion\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   him to look for he may chance to meet under\n",
            "PRED: Thim to look tor be may chance to mect under\n",
            "NORM: Thim to look tor be may chance to mect under\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   be prevailed upon not to overstock us with the worst description\n",
            "PRED: be prevaited Spossnt to overstock us with the worst  description\n",
            "NORM: be prevaited Spossnt to overstock us with the best description\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   ceived without them .\n",
            "PRED: ccaived without them .\n",
            "NORM: ccaived without them .\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   it might have this Inconvenience, that the\n",
            "PRED: it might have this Inconvenitnce , Whak the\n",
            "NORM: it might have this Inconvenitnce, Whak\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   duration .\n",
            "PRED: doration .\n",
            "NORM: doration .\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   The Punishment of a Suborner shall be as follows :\n",
            "PRED: The bunishment of a Jubormer shall be as tollows .\n",
            "NORM: The bunishment of a Jubormer shall be as tollows .\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   the Jews .\n",
            "PRED: the Lews .\n",
            "NORM: the Lews .\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   -y of an Impostor .\n",
            "PRED: 7y of an Impoistor .\n",
            "NORM: 7y of an Impoistor .\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   from a Magistrate .\n",
            "PRED: pom a Magistrate .\n",
            "NORM: pom a Magistrate .\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   and pass the word to the Lamp-lighter , at the\n",
            "PRED: and pass the word to tha Lamp lightet , or the\n",
            "NORM: and pass the word to tha Lamp lightet , or\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   a Question , by whom is it to be determined , in every\n",
            "PRED: a Question , by whom is it to be determined , in\n",
            "NORM: A Question , by whom is it to be determined , in\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   In short if we may be allowed to say what it ought not to be :  it ought\n",
            "PRED: In short of wmy allowed to vay what it ought not to be :  it ought\n",
            "NORM: In short of wmy allowed to vay what it ought not to be : it ought\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   plan the order of the chapters or titles relative to offences of the\n",
            "PRED: plan the ordern of the chaptes or . litles rolative &o oftences of the\n",
            "NORM: the ordern of the chaptes or . litles rolative &o oftences of the\n"
          ]
        }
      ],
      "source": [
        "for idx, row in df.iterrows():\n",
        "    print(\"-\" * 80)\n",
        "    print(f\"GT:   {row['gt']}\")\n",
        "    print(f\"PRED: {row['pred']}\")\n",
        "    print(f\"NORM: {row['pred_normalized']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qXUCjRP801HE",
      "metadata": {
        "id": "qXUCjRP801HE"
      },
      "source": [
        "FLAN-T5 is not strong enough to reliably fix OCR-like errors in 18th–19th-century English, especially when:\n",
        "\n",
        "Words are rare (“Impostor”, “Idleness”, “Suborner”)\n",
        "\n",
        "Sentences contain long legal-style constructions\n",
        "\n",
        "Errors involve letter confusion (t/f, h/b, u/n, rn/m, spacing)\n",
        "\n",
        "Sentences already look somewhat English, tricking the LLM into thinking nothing is wrong"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "F8k38u_JG-SI",
      "metadata": {
        "id": "F8k38u_JG-SI"
      },
      "source": [
        "# USE a Small Language Model(SLM) To Normalize the Outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ubNNOu1R03ao",
      "metadata": {
        "id": "ubNNOu1R03ao"
      },
      "source": [
        "# Mistral-7B-Instruct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QEilfBrf1Yb-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEilfBrf1Yb-",
        "outputId": "82e8886a-c1a0-4156-f3d2-3ae0f6931876"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "#!pip install -q transformers accelerate sentencepiece bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "evMXRIYA3iLj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evMXRIYA3iLj",
        "outputId": "5ccbeabb-a006-46ad-90c6-5777feed163b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: bitsandbytes>=0.43.0 in /usr/local/lib/python3.12/dist-packages (0.48.2)\n",
            "Requirement already satisfied: transformers>=4.40.0 in /usr/local/lib/python3.12/dist-packages (4.57.3)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
            "Requirement already satisfied: torch<3,>=2.3 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes>=0.43.0) (2.9.0+cu126)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes>=0.43.0) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes>=0.43.0) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers>=4.40.0) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.40.0) (0.36.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.40.0) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.40.0) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers>=4.40.0) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.40.0) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.40.0) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.40.0) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.40.0) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.40.0) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.40.0) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes>=0.43.0) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes>=0.43.0) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes>=0.43.0) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes>=0.43.0) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes>=0.43.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes>=0.43.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes>=0.43.0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes>=0.43.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes>=0.43.0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes>=0.43.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes>=0.43.0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes>=0.43.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes>=0.43.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes>=0.43.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes>=0.43.0) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes>=0.43.0) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes>=0.43.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes>=0.43.0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes>=0.43.0) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes>=0.43.0) (3.5.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.40.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.40.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.40.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.40.0) (2025.11.12)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3,>=2.3->bitsandbytes>=0.43.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3,>=2.3->bitsandbytes>=0.43.0) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U \"bitsandbytes>=0.43.0\" \"transformers>=4.40.0\" accelerate sentencepiece\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95MwMUfL4rgv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "95MwMUfL4rgv",
        "outputId": "249c06a5-6846-44b8-9909-be8a066b40f3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8dde383c-60c6-47ff-b8ed-f09d186565af\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>gt</th>\n",
              "      <th>pred</th>\n",
              "      <th>char_accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/kraken_bentham/lines/071_132_001_01_0...</td>\n",
              "      <td>17 .</td>\n",
              "      <td>17 .</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/kraken_bentham/lines/071_184_003_03_0...</td>\n",
              "      <td>Of Frauds relative to the Coin</td>\n",
              "      <td>Of Frauds relative to the Coin</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/kraken_bentham/lines/071_192_004_01_0...</td>\n",
              "      <td>16 .</td>\n",
              "      <td>16 .</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/kraken_bentham/lines/073_070_001_03_0...</td>\n",
              "      <td>that of</td>\n",
              "      <td>that of</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/kraken_bentham/lines/073_073_001_03_1...</td>\n",
              "      <td>implies any such Thing . The ordinary</td>\n",
              "      <td>implies any such Thing . he ordinary</td>\n",
              "      <td>0.972973</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "      \n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8dde383c-60c6-47ff-b8ed-f09d186565af')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "      \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8dde383c-60c6-47ff-b8ed-f09d186565af button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8dde383c-60c6-47ff-b8ed-f09d186565af');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "  \n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                               image  \\\n",
              "0  /content/kraken_bentham/lines/071_132_001_01_0...   \n",
              "1  /content/kraken_bentham/lines/071_184_003_03_0...   \n",
              "2  /content/kraken_bentham/lines/071_192_004_01_0...   \n",
              "3  /content/kraken_bentham/lines/073_070_001_03_0...   \n",
              "4  /content/kraken_bentham/lines/073_073_001_03_1...   \n",
              "\n",
              "                                      gt  \\\n",
              "0                                   17 .   \n",
              "1         Of Frauds relative to the Coin   \n",
              "2                                   16 .   \n",
              "3                                that of   \n",
              "4  implies any such Thing . The ordinary   \n",
              "\n",
              "                                   pred  char_accuracy  \n",
              "0                                  17 .       1.000000  \n",
              "1        Of Frauds relative to the Coin       1.000000  \n",
              "2                                  16 .       1.000000  \n",
              "3                               that of       1.000000  \n",
              "4  implies any such Thing . he ordinary       0.972973  "
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 1. Load the DataFrame from your Drive\n",
        "input_path = \"/content/drive/MyDrive/top_kraken_examples.xlsx\"\n",
        "df = pd.read_excel(input_path)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MOq-Ye6d1t-G",
      "metadata": {
        "id": "MOq-Ye6d1t-G"
      },
      "source": [
        "Load the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "o5l_6qvm1v53",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365,
          "referenced_widgets": [
            "fbfa0c85f1564937ae2a1509f8eced4b",
            "524ff036b9354115b43ffe58efbbb1ce",
            "687b77a90c8546fb9aec728e77b8e916",
            "e0ae03d3865348af83a9c7bced5c913a",
            "1e5d06e861f14f4985872863a832e902",
            "8b7de93975ed4fd39cdf7b7b9103b220",
            "dc5d645b9c7e460294f07409983691ab",
            "409354a6b33f47e2a7a1198d830b6899",
            "02d46a82b2cc464ca10b3df579f18568",
            "7e076fc0e12549f39be0ab5aa63583dc",
            "56b2f936545d46d7883fcf6d9de3a0fe",
            "968cdc9e91554259ba5189a8a37b3a2f",
            "bd17917c784f4cb18254b5a6eb37ffb8",
            "ecc1fd4d2d22400d8b8a83b26de0b644",
            "78446df5b14041c1aeda90e8484ee2ff",
            "c22984f69d9a4daeb8633a00497771d3",
            "ffda5f8575d04188b9aa95a1a95c48ab",
            "7ccf53a652e041bb9c3d5b2d82f99f22",
            "4addb0244cdd4b86a1d5dfb52040cbaf",
            "00712064669d4a769bdfd61ea2344f87",
            "e472d4168c1549e89f902510b6c21b03",
            "a0c7ab3c56c14afeabb53f924660fe81",
            "154fe9aba5f54f7fa1b0f3d508c2012d",
            "1ecde49d90c74cdabd9186a87111d18e",
            "cdb426bf4f304b32933764890ef6a350",
            "393fa856566d4b5bb6f3e2acbdaac0a7",
            "fb37c2af9df3479cbbe0bc9f7e403377",
            "dd71af13c48949c7881053864d48b68f",
            "fc8f1cbbd07f440e9f26d3eaed9c625b",
            "f03f3a59e40249b8a68cdaf7afb7e859",
            "89a6bdb9d1ed4d44bcd9a89de5161eda",
            "704ab816284c4077a7c06e3c8c21c838",
            "bd040b928d3b46219b2225d14da36023",
            "718c0af6195a4b1bbb16556d0d213a66",
            "453eea230116426eba6b6ceefe1d50c5",
            "fba423628f424a2eb1814e4ed156f190",
            "3ffa4c0e4d344ce4a098f41ace1bb20f",
            "90f5a4d213a44f07bfbefb9f5f5a6138",
            "865e6d791d4a4c229eb93cc275423164",
            "5e8be2dd12d74fdaab0a92645dbde0c2",
            "d3d94713732249ccb29069c1da9c1283",
            "30693954427c438a883ba97fbbd80428",
            "97a0741824d6409c8b233ad8289111a9",
            "e09134d2078d4b8f9684b408b24f0bf5",
            "a6c6b86d70cf4753b189462bb2727077",
            "f27e125fd06e430796adf3a4940d82ef",
            "7e08bcb2c5b444fe91dbd05a405f0639",
            "4a6306f640d04f0e93adc9290ca90268",
            "0b1683065338456390e9acbce148008a",
            "e465134688054fe79ea0534aef0f855c",
            "2b4f4f259f404a1a9d3e87d223640114",
            "4bc41310d2e045929fff1e8e8a686522",
            "06992f5bffd24571ba43f722de525f6c",
            "75987738a0bf4c22be496d7398933212",
            "ab3e9bbad3dd4943935c26e4136691c1",
            "c5cff8b50d8543868a39fbd12cc4cfef",
            "95400d36f23640be8feb79a149888c57",
            "6fbce48080b74665a2de54420bfae094",
            "3535e12f7a034b23b01ae4bb5b535a74",
            "f0b4823e6ba34baba573c51aba575bc8",
            "851d515c4d584621a4d1bf27dab1e78d",
            "242c021aa32b4f10ac9f5eb78892c7a3",
            "1a6ec20c59ea486ba91cdf0238b7576a",
            "24d8f3232743437c8318da6145aee83a",
            "8e780b2fa88a41c9ae7355e40cce8bdd",
            "c881962e158240a3aa370fab3973095b",
            "efbb79ed63ad449c8c8df184c2343358",
            "2532ae7dace9406c9ae6a615958459db",
            "862e52006f2245e5b80ce79b08632202",
            "c752b4f749214b4abc9571959f26887f",
            "570ec42f4ac54424b8e62ed7d214ea1b",
            "55fbbc271823489e939075fca3363416",
            "1ab3a1b24adb44dcacc49b0acdff9959",
            "60a829850d19423ebc5a5ed2df0936a8",
            "f4d6c937ecca427aa189502c05caa753",
            "6051f9a7b754496d9269e57343a01766",
            "798ac239373f469f924a4d3b2a6f476f"
          ]
        },
        "id": "o5l_6qvm1v53",
        "outputId": "4cc62e8b-66ec-45bc-e92e-07b10cf5b0b7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fbfa0c85f1564937ae2a1509f8eced4b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "968cdc9e91554259ba5189a8a37b3a2f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "154fe9aba5f54f7fa1b0f3d508c2012d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00003-of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "718c0af6195a4b1bbb16556d0d213a66",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a6c6b86d70cf4753b189462bb2727077",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c5cff8b50d8543868a39fbd12cc4cfef",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "efbb79ed63ad449c8c8df184c2343358",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "import torch\n",
        "\n",
        "model_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
        "\n",
        "# 4-bit quantization config\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\",\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lndGbG0M5TEN",
      "metadata": {
        "id": "lndGbG0M5TEN"
      },
      "source": [
        "# Normalize Kraken Outputs with Mistral"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vj4l8VeH5iCN",
      "metadata": {
        "id": "vj4l8VeH5iCN"
      },
      "outputs": [],
      "source": [
        "def normalize_with_mistral(text, max_new_tokens=80):\n",
        "    if not isinstance(text, str) or not text.strip():\n",
        "        return text\n",
        "\n",
        "    system_prompt = (\n",
        "        \"You are an expert OCR post-correction system for English text, \"\n",
        "        \"specialized in correcting historical and legal documents. \"\n",
        "        \"Your task is to correct OCR errors while preserving the exact meaning.\\n\\n\"\n",
        "        \"Rules:\\n\"\n",
        "        \"- Fix misspellings and non-words.\\n\"\n",
        "        \"- Fix letter confusions typical in OCR: t↔f, h↔b, rn↔m, cl↔d, i↔l↔1, u↔v.\\n\"\n",
        "        \"- Do NOT add or remove ideas.\\n\"\n",
        "        \"- Do NOT change sentence meaning.\\n\"\n",
        "        \"- Use correct English words that best match the context.\\n\"\n",
        "        \"- Preserve sentence structure and punctuation unless clearly damaged.\\n\"\n",
        "        \"- Only output the corrected sentence.\\n\"\n",
        "    )\n",
        "\n",
        "    user_prompt = f\"Correct this OCR sentence:\\n{text}\"\n",
        "\n",
        "    prompt = f\"<s>[INST] {system_prompt}\\n{user_prompt} [/INST]\"\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        generated = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            temperature=0.2,\n",
        "            top_p=0.9,\n",
        "            repetition_penalty=1.05,\n",
        "        )\n",
        "\n",
        "    # ❗ Strip the prompt tokens: keep only what the model added after the input\n",
        "    input_len = inputs[\"input_ids\"].shape[-1]\n",
        "    gen_ids = generated[0][input_len:]          # slice off the prompt\n",
        "    corrected = tokenizer.decode(gen_ids, skip_special_tokens=True).strip()\n",
        "\n",
        "    # Optional: if model still echoes a bit, try trimming common boilerplate\n",
        "    # e.g. if it starts with something like \"[INST]\" again:\n",
        "    if \"[INST]\" in corrected:\n",
        "        corrected = corrected.split(\"[/INST]\")[-1].strip()\n",
        "\n",
        "    return corrected\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wfS2y2zZ57y-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wfS2y2zZ57y-",
        "outputId": "b3d33ed7-02c6-4c81-b9e3-81e79796f0ce"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5b314a0e-450e-4995-b462-55fe3ba492d2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>gt</th>\n",
              "      <th>pred</th>\n",
              "      <th>char_accuracy</th>\n",
              "      <th>pred_normalized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/kraken_bentham/lines/071_132_001_01_0...</td>\n",
              "      <td>17 .</td>\n",
              "      <td>17 .</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>I'm unable to correct the given OCR sentence a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/kraken_bentham/lines/071_184_003_03_0...</td>\n",
              "      <td>Of Frauds relative to the Coin</td>\n",
              "      <td>Of Frauds relative to the Coin</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>Of Frauds relating to the Coin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/kraken_bentham/lines/071_192_004_01_0...</td>\n",
              "      <td>16 .</td>\n",
              "      <td>16 .</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>It is unclear what this OCR output represents ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/kraken_bentham/lines/073_070_001_03_0...</td>\n",
              "      <td>that of</td>\n",
              "      <td>that of</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>That of [preserve the original meaning: that b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/kraken_bentham/lines/073_073_001_03_1...</td>\n",
              "      <td>implies any such Thing . The ordinary</td>\n",
              "      <td>implies any such Thing . he ordinary</td>\n",
              "      <td>0.972973</td>\n",
              "      <td>implies anything. He means the ordinary thing.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>/content/kraken_bentham/lines/073_003_001_02_0...</td>\n",
              "      <td>inserting under one Title a proposition which</td>\n",
              "      <td>inserting under one Tithe a poposition which</td>\n",
              "      <td>0.955556</td>\n",
              "      <td>inserting under one title a position which</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>/content/kraken_bentham/lines/071_186_002_04_1...</td>\n",
              "      <td>stand altogether upon so good a footing :  sin...</td>\n",
              "      <td>stand allogether upon , so good a footing :  s...</td>\n",
              "      <td>0.950820</td>\n",
              "      <td>stand altogether on such good footing: since t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>/content/kraken_bentham/lines/072_049_004_04_1...</td>\n",
              "      <td>As to the mischief there would be in</td>\n",
              "      <td>As to the mischif there would bhe in</td>\n",
              "      <td>0.944444</td>\n",
              "      <td>As to the mischief, there would be. (Here, \"mi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>/content/kraken_bentham/lines/073_003_002_01_1...</td>\n",
              "      <td>give the Reality , without contenting themselves</td>\n",
              "      <td>give the Reality , without ententing themselvs</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>give the Reality, without entering themselves</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>/content/kraken_bentham/lines/071_186_002_04_0...</td>\n",
              "      <td>in general nobody can know )  , whether the le...</td>\n",
              "      <td>in general nobedy can know  , whether the leas...</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>In general, nobody can know, whether the least...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>/content/kraken_bentham/lines/096_101_001_02_1...</td>\n",
              "      <td>can be assigned</td>\n",
              "      <td>can be assignes</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>can be assigned</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>/content/kraken_bentham/lines/072_052_002_03_0...</td>\n",
              "      <td>Offences against the external Security of the ...</td>\n",
              "      <td>Offences against the external Decurity of the ...</td>\n",
              "      <td>0.924528</td>\n",
              "      <td>Offenses against the external Security of the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>/content/kraken_bentham/lines/096_099_004_01_0...</td>\n",
              "      <td>if instead of the Fine we take for the Punishm...</td>\n",
              "      <td>if instead of the Tine we take for the Jurishm...</td>\n",
              "      <td>0.924528</td>\n",
              "      <td>if instead of the Time we take for the Jurisdi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>/content/kraken_bentham/lines/072_066_003_03_0...</td>\n",
              "      <td>Of Idleness .</td>\n",
              "      <td>O Idleness .</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>The correct OCR sentence should be: \"Of Idlene...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>/content/kraken_bentham/lines/096_100_001_02_2...</td>\n",
              "      <td>would have nothing to do but to pay his third and</td>\n",
              "      <td>would have nothiny 10 do But to pay his third and</td>\n",
              "      <td>0.918367</td>\n",
              "      <td>would not have had anything up to ten dollars ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>/content/kraken_bentham/lines/071_120_002_05_0...</td>\n",
              "      <td>Exposition .</td>\n",
              "      <td>Expoition .</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>Exposition.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>/content/kraken_bentham/lines/071_111_002_04_1...</td>\n",
              "      <td>impostor :  the party falsely pretended to pos...</td>\n",
              "      <td>empostor  :  the party tulsels prelended to po...</td>\n",
              "      <td>0.907895</td>\n",
              "      <td>emposter: the party presented themselves as po...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>/content/kraken_bentham/lines/073_003_001_02_0...</td>\n",
              "      <td>him to look for he may chance to meet under</td>\n",
              "      <td>Thim to look tor be may chance to mect under</td>\n",
              "      <td>0.906977</td>\n",
              "      <td>Them to look for being may have a chance to me...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>/content/kraken_bentham/lines/097_186_001_01_2...</td>\n",
              "      <td>be prevailed upon not to overstock us with the...</td>\n",
              "      <td>be prevaited Spossnt to overstock us with the ...</td>\n",
              "      <td>0.906250</td>\n",
              "      <td>Be prevented, please, from overstocking us wit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>/content/kraken_bentham/lines/027_029_001_02_2...</td>\n",
              "      <td>ceived without them .</td>\n",
              "      <td>ccaived without them .</td>\n",
              "      <td>0.904762</td>\n",
              "      <td>received without them.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>/content/kraken_bentham/lines/073_068_001_03_1...</td>\n",
              "      <td>it might have this Inconvenience, that the</td>\n",
              "      <td>it might have this Inconvenitnce , Whak the</td>\n",
              "      <td>0.904762</td>\n",
              "      <td>it might have this Convenience, That (or: it m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>/content/kraken_bentham/lines/027_029_001_02_1...</td>\n",
              "      <td>duration .</td>\n",
              "      <td>doration .</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>The given OCR text \"doration .\" is not a compl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>/content/kraken_bentham/lines/071_111_002_04_1...</td>\n",
              "      <td>The Punishment of a Suborner shall be as follo...</td>\n",
              "      <td>The bunishment of a Jubormer shall be as tollo...</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>The punishment of a Juror shall be as follows.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>/content/kraken_bentham/lines/116_405_001_01_1...</td>\n",
              "      <td>the Jews .</td>\n",
              "      <td>the Lews .</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>The Laws.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>/content/kraken_bentham/lines/071_111_002_04_1...</td>\n",
              "      <td>-y of an Impostor .</td>\n",
              "      <td>7y of an Impoistor .</td>\n",
              "      <td>0.894737</td>\n",
              "      <td>7 years of an Imposter.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>/content/kraken_bentham/lines/116_405_001_01_2...</td>\n",
              "      <td>from a Magistrate .</td>\n",
              "      <td>pom a Magistrate .</td>\n",
              "      <td>0.894737</td>\n",
              "      <td>The correct OCR output should be:\\n\\n\"Before a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>/content/kraken_bentham/lines/116_405_004_01_1...</td>\n",
              "      <td>and pass the word to the Lamp-lighter , at the</td>\n",
              "      <td>and pass the word to tha Lamp lightet , or the</td>\n",
              "      <td>0.891304</td>\n",
              "      <td>And pass the word to the lamp, it will light i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>/content/kraken_bentham/lines/073_056_001_03_0...</td>\n",
              "      <td>a Question , by whom is it to be determined , ...</td>\n",
              "      <td>a Question , by whom is it to be determined , in</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>A question: By whom is it to be determined?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>/content/kraken_bentham/lines/096_051_002_03_1...</td>\n",
              "      <td>In short if we may be allowed to say what it o...</td>\n",
              "      <td>In short of wmy allowed to vay what it ought n...</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>In short, we may not allow it to be other than...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>/content/kraken_bentham/lines/071_188_002_03_0...</td>\n",
              "      <td>plan the order of the chapters or titles relat...</td>\n",
              "      <td>plan the ordern of the chaptes or . litles rol...</td>\n",
              "      <td>0.882353</td>\n",
              "      <td>Plan the order of the chapters or the little r...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "      \n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5b314a0e-450e-4995-b462-55fe3ba492d2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "      \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5b314a0e-450e-4995-b462-55fe3ba492d2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5b314a0e-450e-4995-b462-55fe3ba492d2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "  \n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                image  \\\n",
              "0   /content/kraken_bentham/lines/071_132_001_01_0...   \n",
              "1   /content/kraken_bentham/lines/071_184_003_03_0...   \n",
              "2   /content/kraken_bentham/lines/071_192_004_01_0...   \n",
              "3   /content/kraken_bentham/lines/073_070_001_03_0...   \n",
              "4   /content/kraken_bentham/lines/073_073_001_03_1...   \n",
              "5   /content/kraken_bentham/lines/073_003_001_02_0...   \n",
              "6   /content/kraken_bentham/lines/071_186_002_04_1...   \n",
              "7   /content/kraken_bentham/lines/072_049_004_04_1...   \n",
              "8   /content/kraken_bentham/lines/073_003_002_01_1...   \n",
              "9   /content/kraken_bentham/lines/071_186_002_04_0...   \n",
              "10  /content/kraken_bentham/lines/096_101_001_02_1...   \n",
              "11  /content/kraken_bentham/lines/072_052_002_03_0...   \n",
              "12  /content/kraken_bentham/lines/096_099_004_01_0...   \n",
              "13  /content/kraken_bentham/lines/072_066_003_03_0...   \n",
              "14  /content/kraken_bentham/lines/096_100_001_02_2...   \n",
              "15  /content/kraken_bentham/lines/071_120_002_05_0...   \n",
              "16  /content/kraken_bentham/lines/071_111_002_04_1...   \n",
              "17  /content/kraken_bentham/lines/073_003_001_02_0...   \n",
              "18  /content/kraken_bentham/lines/097_186_001_01_2...   \n",
              "19  /content/kraken_bentham/lines/027_029_001_02_2...   \n",
              "20  /content/kraken_bentham/lines/073_068_001_03_1...   \n",
              "21  /content/kraken_bentham/lines/027_029_001_02_1...   \n",
              "22  /content/kraken_bentham/lines/071_111_002_04_1...   \n",
              "23  /content/kraken_bentham/lines/116_405_001_01_1...   \n",
              "24  /content/kraken_bentham/lines/071_111_002_04_1...   \n",
              "25  /content/kraken_bentham/lines/116_405_001_01_2...   \n",
              "26  /content/kraken_bentham/lines/116_405_004_01_1...   \n",
              "27  /content/kraken_bentham/lines/073_056_001_03_0...   \n",
              "28  /content/kraken_bentham/lines/096_051_002_03_1...   \n",
              "29  /content/kraken_bentham/lines/071_188_002_03_0...   \n",
              "\n",
              "                                                   gt  \\\n",
              "0                                                17 .   \n",
              "1                      Of Frauds relative to the Coin   \n",
              "2                                                16 .   \n",
              "3                                             that of   \n",
              "4               implies any such Thing . The ordinary   \n",
              "5       inserting under one Title a proposition which   \n",
              "6   stand altogether upon so good a footing :  sin...   \n",
              "7                As to the mischief there would be in   \n",
              "8    give the Reality , without contenting themselves   \n",
              "9   in general nobody can know )  , whether the le...   \n",
              "10                                    can be assigned   \n",
              "11  Offences against the external Security of the ...   \n",
              "12  if instead of the Fine we take for the Punishm...   \n",
              "13                                      Of Idleness .   \n",
              "14  would have nothing to do but to pay his third and   \n",
              "15                                       Exposition .   \n",
              "16  impostor :  the party falsely pretended to pos...   \n",
              "17        him to look for he may chance to meet under   \n",
              "18  be prevailed upon not to overstock us with the...   \n",
              "19                              ceived without them .   \n",
              "20         it might have this Inconvenience, that the   \n",
              "21                                         duration .   \n",
              "22  The Punishment of a Suborner shall be as follo...   \n",
              "23                                         the Jews .   \n",
              "24                                -y of an Impostor .   \n",
              "25                                from a Magistrate .   \n",
              "26     and pass the word to the Lamp-lighter , at the   \n",
              "27  a Question , by whom is it to be determined , ...   \n",
              "28  In short if we may be allowed to say what it o...   \n",
              "29  plan the order of the chapters or titles relat...   \n",
              "\n",
              "                                                 pred  char_accuracy  \\\n",
              "0                                                17 .       1.000000   \n",
              "1                      Of Frauds relative to the Coin       1.000000   \n",
              "2                                                16 .       1.000000   \n",
              "3                                             that of       1.000000   \n",
              "4                implies any such Thing . he ordinary       0.972973   \n",
              "5        inserting under one Tithe a poposition which       0.955556   \n",
              "6   stand allogether upon , so good a footing :  s...       0.950820   \n",
              "7                As to the mischif there would bhe in       0.944444   \n",
              "8      give the Reality , without ententing themselvs       0.937500   \n",
              "9   in general nobedy can know  , whether the leas...       0.933333   \n",
              "10                                    can be assignes       0.933333   \n",
              "11  Offences against the external Decurity of the ...       0.924528   \n",
              "12  if instead of the Tine we take for the Jurishm...       0.924528   \n",
              "13                                       O Idleness .       0.923077   \n",
              "14  would have nothiny 10 do But to pay his third and       0.918367   \n",
              "15                                        Expoition .       0.916667   \n",
              "16  empostor  :  the party tulsels prelended to po...       0.907895   \n",
              "17       Thim to look tor be may chance to mect under       0.906977   \n",
              "18  be prevaited Spossnt to overstock us with the ...       0.906250   \n",
              "19                             ccaived without them .       0.904762   \n",
              "20        it might have this Inconvenitnce , Whak the       0.904762   \n",
              "21                                         doration .       0.900000   \n",
              "22  The bunishment of a Jubormer shall be as tollo...       0.900000   \n",
              "23                                         the Lews .       0.900000   \n",
              "24                               7y of an Impoistor .       0.894737   \n",
              "25                                 pom a Magistrate .       0.894737   \n",
              "26     and pass the word to tha Lamp lightet , or the       0.891304   \n",
              "27   a Question , by whom is it to be determined , in       0.888889   \n",
              "28  In short of wmy allowed to vay what it ought n...       0.888889   \n",
              "29  plan the ordern of the chaptes or . litles rol...       0.882353   \n",
              "\n",
              "                                      pred_normalized  \n",
              "0   I'm unable to correct the given OCR sentence a...  \n",
              "1                      Of Frauds relating to the Coin  \n",
              "2   It is unclear what this OCR output represents ...  \n",
              "3   That of [preserve the original meaning: that b...  \n",
              "4      implies anything. He means the ordinary thing.  \n",
              "5          inserting under one title a position which  \n",
              "6   stand altogether on such good footing: since t...  \n",
              "7   As to the mischief, there would be. (Here, \"mi...  \n",
              "8       give the Reality, without entering themselves  \n",
              "9   In general, nobody can know, whether the least...  \n",
              "10                                    can be assigned  \n",
              "11  Offenses against the external Security of the ...  \n",
              "12  if instead of the Time we take for the Jurisdi...  \n",
              "13  The correct OCR sentence should be: \"Of Idlene...  \n",
              "14  would not have had anything up to ten dollars ...  \n",
              "15                                        Exposition.  \n",
              "16  emposter: the party presented themselves as po...  \n",
              "17  Them to look for being may have a chance to me...  \n",
              "18  Be prevented, please, from overstocking us wit...  \n",
              "19                             received without them.  \n",
              "20  it might have this Convenience, That (or: it m...  \n",
              "21  The given OCR text \"doration .\" is not a compl...  \n",
              "22     The punishment of a Juror shall be as follows.  \n",
              "23                                          The Laws.  \n",
              "24                            7 years of an Imposter.  \n",
              "25  The correct OCR output should be:\\n\\n\"Before a...  \n",
              "26  And pass the word to the lamp, it will light i...  \n",
              "27        A question: By whom is it to be determined?  \n",
              "28  In short, we may not allow it to be other than...  \n",
              "29  Plan the order of the chapters or the little r...  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[\"pred_normalized\"] = df[\"pred\"].apply(normalize_with_mistral)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DfHJwUqjAOru",
      "metadata": {
        "id": "DfHJwUqjAOru"
      },
      "outputs": [],
      "source": [
        "df.to_excel(\"/content/drive/MyDrive/top_kraken_examples_normalized.xlsx\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "p5bQWox36btt",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5bQWox36btt",
        "outputId": "4e3ba2b9-5cf2-4a1b-f350-8c73808e0424"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "GT:   17 .\n",
            "PRED: 17 .\n",
            "NORM: I'm unable to correct the given OCR sentence as it's incomplete and contains no text. Please provide the incorrect text for me to correct according to the rules given.\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   Of Frauds relative to the Coin\n",
            "PRED: Of Frauds relative to the Coin\n",
            "NORM: Of Frauds relating to the Coin\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   16 .\n",
            "PRED: 16 .\n",
            "NORM: It is unclear what this OCR output represents as it consists of a single number \"16\" followed by a period. There seems to be no sentence or context provided for correction. Therefore, I cannot provide a corrected sentence based on the given information.\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   that of\n",
            "PRED: that of\n",
            "NORM: That of [preserve the original meaning: that belonging to, or concerning that]\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   implies any such Thing . The ordinary\n",
            "PRED: implies any such Thing . he ordinary\n",
            "NORM: implies anything. He means the ordinary thing.\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   inserting under one Title a proposition which\n",
            "PRED: inserting under one Tithe a poposition which\n",
            "NORM: inserting under one title a position which\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   stand altogether upon so good a footing :  since the distress\n",
            "PRED: stand allogether upon , so good a footing :  since the distress\n",
            "NORM: stand altogether on such good footing: since the distress\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   As to the mischief there would be in\n",
            "PRED: As to the mischif there would bhe in\n",
            "NORM: As to the mischief, there would be. (Here, \"mischief\" is a noun meaning a harmful or annoying act, and \"there would be\" is a correct form of the verb phrase \"there would be\" in the past tense.)\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   give the Reality , without contenting themselves\n",
            "PRED: give the Reality , without ententing themselvs\n",
            "NORM: give the Reality, without entering themselves\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   in general nobody can know )  , whether the least part of it\n",
            "PRED: in general nobedy can know  , whether the least part of i\n",
            "NORM: In general, nobody can know, whether the least part of I [corrected \"nobody\" to \"nobody\", added missing \"can\" and \"the\" to make a complete sentence, corrected \"nobedy\" to \"nobody\", and corrected \"can know\" to \"can know\" and \"know\" to \"know\" to maintain the original meaning and preserve the sentence structure\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   can be assigned\n",
            "PRED: can be assignes\n",
            "NORM: can be assigned\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   Offences against the external Security of the State .\n",
            "PRED: Offences against the external Decurity of the Sate\n",
            "NORM: Offenses against the external Security of the State\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   if instead of the Fine we take for the Punishment any\n",
            "PRED: if instead of the Tine we take for the Jurishment ony\n",
            "NORM: if instead of the Time we take for the Jurisdiction only.\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   Of Idleness .\n",
            "PRED: O Idleness .\n",
            "NORM: The correct OCR sentence should be: \"Of Idleness.\"\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   would have nothing to do but to pay his third and\n",
            "PRED: would have nothiny 10 do But to pay his third and\n",
            "NORM: would not have had anything up to ten dollars to pay his third installment.\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   Exposition .\n",
            "PRED: Expoition .\n",
            "NORM: Exposition.\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   impostor :  the party falsely pretended to possess the character in question\n",
            "PRED: empostor  :  the party tulsels prelended to possess the character in quistion\n",
            "NORM: emposter: the party presented themselves as possessing the thing in question.\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   him to look for he may chance to meet under\n",
            "PRED: Thim to look tor be may chance to mect under\n",
            "NORM: Them to look for being may have a chance to meet under.\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   be prevailed upon not to overstock us with the worst description\n",
            "PRED: be prevaited Spossnt to overstock us with the worst  description\n",
            "NORM: Be prevented, please, from overstocking us with the worst descriptions.\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   ceived without them .\n",
            "PRED: ccaived without them .\n",
            "NORM: received without them.\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   it might have this Inconvenience, that the\n",
            "PRED: it might have this Inconvenitnce , Whak the\n",
            "NORM: it might have this Convenience, That (or: it might have this inconvenience, that)\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   duration .\n",
            "PRED: doration .\n",
            "NORM: The given OCR text \"doration .\" is not a complete sentence and appears to be incomplete or corrupted. It's difficult to provide a correction without additional context. However, based on the given rules, I assume it's intended to be \"donation.\" or \"dedication.\" with a period at the end. Both words fit well in the context of historical and legal documents\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   The Punishment of a Suborner shall be as follows :\n",
            "PRED: The bunishment of a Jubormer shall be as tollows .\n",
            "NORM: The punishment of a Juror shall be as follows.\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   the Jews .\n",
            "PRED: the Lews .\n",
            "NORM: The Laws.\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   -y of an Impostor .\n",
            "PRED: 7y of an Impoistor .\n",
            "NORM: 7 years of an Imposter.\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   from a Magistrate .\n",
            "PRED: pom a Magistrate .\n",
            "NORM: The correct OCR output should be:\n",
            "\n",
            "\"Before a Magistrate.\"\n",
            "\n",
            "Explanation:\n",
            "The OCR has incorrectly recognized \"pom\" as \"before\" and \"a\" as \"a\". To preserve the meaning of the original sentence, which appears to be introducing a quote or testimony before a magistrate, we correct it to \"Before a Magistr\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   and pass the word to the Lamp-lighter , at the\n",
            "PRED: and pass the word to tha Lamp lightet , or the\n",
            "NORM: And pass the word to the lamp, it will light it. (Assuming \"tha\" was meant to be \"the\" and \"it will lightet\" was meant to be \"it will light\")\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   a Question , by whom is it to be determined , in every\n",
            "PRED: a Question , by whom is it to be determined , in\n",
            "NORM: A question: By whom is it to be determined?\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   In short if we may be allowed to say what it ought not to be :  it ought\n",
            "PRED: In short of wmy allowed to vay what it ought not to be :  it ought\n",
            "NORM: In short, we may not allow it to be other than it ought to be: it ought\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   plan the order of the chapters or titles relative to offences of the\n",
            "PRED: plan the ordern of the chaptes or . litles rolative &o oftences of the\n",
            "NORM: Plan the order of the chapters or the little relative offsets of the [content] in the document.\n"
          ]
        }
      ],
      "source": [
        "for idx, row in df.iterrows():\n",
        "    print(\"-\" * 80)\n",
        "    print(f\"GT:   {row['gt']}\")\n",
        "    print(f\"PRED: {row['pred']}\")\n",
        "    print(f\"NORM: {row['pred_normalized']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f00cd12",
      "metadata": {
        "id": "0f00cd12",
        "outputId": "4cb1128f-7265-41b5-a65c-efde88953376"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>gt</th>\n",
              "      <th>pred</th>\n",
              "      <th>char_accuracy</th>\n",
              "      <th>pred_normalized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/kraken_bentham/lines/071_132_001_01_0...</td>\n",
              "      <td>17 .</td>\n",
              "      <td>17 .</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>I'm unable to correct the given OCR sentence a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/kraken_bentham/lines/071_184_003_03_0...</td>\n",
              "      <td>Of Frauds relative to the Coin</td>\n",
              "      <td>Of Frauds relative to the Coin</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>Of Frauds relating to the Coin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/kraken_bentham/lines/071_192_004_01_0...</td>\n",
              "      <td>16 .</td>\n",
              "      <td>16 .</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>It is unclear what this OCR output represents ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/kraken_bentham/lines/073_070_001_03_0...</td>\n",
              "      <td>that of</td>\n",
              "      <td>that of</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>That of [preserve the original meaning: that b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/kraken_bentham/lines/073_073_001_03_1...</td>\n",
              "      <td>implies any such Thing . The ordinary</td>\n",
              "      <td>implies any such Thing . he ordinary</td>\n",
              "      <td>0.972973</td>\n",
              "      <td>implies anything. He means the ordinary thing.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               image  \\\n",
              "0  /content/kraken_bentham/lines/071_132_001_01_0...   \n",
              "1  /content/kraken_bentham/lines/071_184_003_03_0...   \n",
              "2  /content/kraken_bentham/lines/071_192_004_01_0...   \n",
              "3  /content/kraken_bentham/lines/073_070_001_03_0...   \n",
              "4  /content/kraken_bentham/lines/073_073_001_03_1...   \n",
              "\n",
              "                                      gt  \\\n",
              "0                                   17 .   \n",
              "1         Of Frauds relative to the Coin   \n",
              "2                                   16 .   \n",
              "3                                that of   \n",
              "4  implies any such Thing . The ordinary   \n",
              "\n",
              "                                   pred  char_accuracy  \\\n",
              "0                                  17 .       1.000000   \n",
              "1        Of Frauds relative to the Coin       1.000000   \n",
              "2                                  16 .       1.000000   \n",
              "3                               that of       1.000000   \n",
              "4  implies any such Thing . he ordinary       0.972973   \n",
              "\n",
              "                                     pred_normalized  \n",
              "0  I'm unable to correct the given OCR sentence a...  \n",
              "1                     Of Frauds relating to the Coin  \n",
              "2  It is unclear what this OCR output represents ...  \n",
              "3  That of [preserve the original meaning: that b...  \n",
              "4     implies anything. He means the ordinary thing.  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 1. Load the DataFrame from your Drive\n",
        "input_path = \"top_kraken_examples_normalized.xlsx\"\n",
        "df = pd.read_excel(input_path)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69cc8377",
      "metadata": {
        "id": "69cc8377",
        "outputId": "01d0b749-8e70-44e0-82bb-074a67fef600"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>gt</th>\n",
              "      <th>pred</th>\n",
              "      <th>char_accuracy</th>\n",
              "      <th>pred_normalized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/kraken_bentham/lines/071_184_003_03_0...</td>\n",
              "      <td>Of Frauds relative to the Coin</td>\n",
              "      <td>Of Frauds relative to the Coin</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>Of Frauds relating to the Coin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/kraken_bentham/lines/073_073_001_03_1...</td>\n",
              "      <td>implies any such Thing . The ordinary</td>\n",
              "      <td>implies any such Thing . he ordinary</td>\n",
              "      <td>0.972973</td>\n",
              "      <td>implies anything. He means the ordinary thing.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>/content/kraken_bentham/lines/073_003_001_02_0...</td>\n",
              "      <td>inserting under one Title a proposition which</td>\n",
              "      <td>inserting under one Tithe a poposition which</td>\n",
              "      <td>0.955556</td>\n",
              "      <td>inserting under one title a position which</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>/content/kraken_bentham/lines/071_186_002_04_1...</td>\n",
              "      <td>stand altogether upon so good a footing :  sin...</td>\n",
              "      <td>stand allogether upon , so good a footing :  s...</td>\n",
              "      <td>0.950820</td>\n",
              "      <td>stand altogether on such good footing: since t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>/content/kraken_bentham/lines/072_049_004_04_1...</td>\n",
              "      <td>As to the mischief there would be in</td>\n",
              "      <td>As to the mischif there would bhe in</td>\n",
              "      <td>0.944444</td>\n",
              "      <td>As to the mischief, there would be. (Here, \"mi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>/content/kraken_bentham/lines/073_003_002_01_1...</td>\n",
              "      <td>give the Reality , without contenting themselves</td>\n",
              "      <td>give the Reality , without ententing themselvs</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>give the Reality, without entering themselves</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>/content/kraken_bentham/lines/071_186_002_04_0...</td>\n",
              "      <td>in general nobody can know )  , whether the le...</td>\n",
              "      <td>in general nobedy can know  , whether the leas...</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>In general, nobody can know, whether the least...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>/content/kraken_bentham/lines/096_101_001_02_1...</td>\n",
              "      <td>can be assigned</td>\n",
              "      <td>can be assignes</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>can be assigned</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>/content/kraken_bentham/lines/072_052_002_03_0...</td>\n",
              "      <td>Offences against the external Security of the ...</td>\n",
              "      <td>Offences against the external Decurity of the ...</td>\n",
              "      <td>0.924528</td>\n",
              "      <td>Offenses against the external Security of the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>/content/kraken_bentham/lines/096_099_004_01_0...</td>\n",
              "      <td>if instead of the Fine we take for the Punishm...</td>\n",
              "      <td>if instead of the Tine we take for the Jurishm...</td>\n",
              "      <td>0.924528</td>\n",
              "      <td>if instead of the Time we take for the Jurisdi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>/content/kraken_bentham/lines/072_066_003_03_0...</td>\n",
              "      <td>Of Idleness .</td>\n",
              "      <td>O Idleness .</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>The correct OCR sentence should be: \"Of Idlene...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>/content/kraken_bentham/lines/096_100_001_02_2...</td>\n",
              "      <td>would have nothing to do but to pay his third and</td>\n",
              "      <td>would have nothiny 10 do But to pay his third and</td>\n",
              "      <td>0.918367</td>\n",
              "      <td>would not have had anything up to ten dollars ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>/content/kraken_bentham/lines/071_111_002_04_1...</td>\n",
              "      <td>impostor :  the party falsely pretended to pos...</td>\n",
              "      <td>empostor  :  the party tulsels prelended to po...</td>\n",
              "      <td>0.907895</td>\n",
              "      <td>emposter: the party presented themselves as po...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>/content/kraken_bentham/lines/073_003_001_02_0...</td>\n",
              "      <td>him to look for he may chance to meet under</td>\n",
              "      <td>Thim to look tor be may chance to mect under</td>\n",
              "      <td>0.906977</td>\n",
              "      <td>Them to look for being may have a chance to me...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>/content/kraken_bentham/lines/097_186_001_01_2...</td>\n",
              "      <td>be prevailed upon not to overstock us with the...</td>\n",
              "      <td>be prevaited Spossnt to overstock us with the ...</td>\n",
              "      <td>0.906250</td>\n",
              "      <td>Be prevented, please, from overstocking us wit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>/content/kraken_bentham/lines/027_029_001_02_2...</td>\n",
              "      <td>ceived without them .</td>\n",
              "      <td>ccaived without them .</td>\n",
              "      <td>0.904762</td>\n",
              "      <td>received without them.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>/content/kraken_bentham/lines/073_068_001_03_1...</td>\n",
              "      <td>it might have this Inconvenience, that the</td>\n",
              "      <td>it might have this Inconvenitnce , Whak the</td>\n",
              "      <td>0.904762</td>\n",
              "      <td>it might have this Convenience, That (or: it m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>/content/kraken_bentham/lines/071_111_002_04_1...</td>\n",
              "      <td>The Punishment of a Suborner shall be as follo...</td>\n",
              "      <td>The bunishment of a Jubormer shall be as tollo...</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>The punishment of a Juror shall be as follows.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>/content/kraken_bentham/lines/116_405_001_01_1...</td>\n",
              "      <td>the Jews .</td>\n",
              "      <td>the Lews .</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>The Laws.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>/content/kraken_bentham/lines/071_111_002_04_1...</td>\n",
              "      <td>-y of an Impostor .</td>\n",
              "      <td>7y of an Impoistor .</td>\n",
              "      <td>0.894737</td>\n",
              "      <td>7 years of an Imposter.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>/content/kraken_bentham/lines/116_405_001_01_2...</td>\n",
              "      <td>from a Magistrate .</td>\n",
              "      <td>pom a Magistrate .</td>\n",
              "      <td>0.894737</td>\n",
              "      <td>The correct OCR output should be:\\n\\n\"Before a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>/content/kraken_bentham/lines/116_405_004_01_1...</td>\n",
              "      <td>and pass the word to the Lamp-lighter , at the</td>\n",
              "      <td>and pass the word to tha Lamp lightet , or the</td>\n",
              "      <td>0.891304</td>\n",
              "      <td>And pass the word to the lamp, it will light i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>/content/kraken_bentham/lines/073_056_001_03_0...</td>\n",
              "      <td>a Question , by whom is it to be determined , ...</td>\n",
              "      <td>a Question , by whom is it to be determined , in</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>A question: By whom is it to be determined?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>/content/kraken_bentham/lines/096_051_002_03_1...</td>\n",
              "      <td>In short if we may be allowed to say what it o...</td>\n",
              "      <td>In short of wmy allowed to vay what it ought n...</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>In short, we may not allow it to be other than...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>/content/kraken_bentham/lines/071_188_002_03_0...</td>\n",
              "      <td>plan the order of the chapters or titles relat...</td>\n",
              "      <td>plan the ordern of the chaptes or . litles rol...</td>\n",
              "      <td>0.882353</td>\n",
              "      <td>Plan the order of the chapters or the little r...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                image  \\\n",
              "1   /content/kraken_bentham/lines/071_184_003_03_0...   \n",
              "4   /content/kraken_bentham/lines/073_073_001_03_1...   \n",
              "5   /content/kraken_bentham/lines/073_003_001_02_0...   \n",
              "6   /content/kraken_bentham/lines/071_186_002_04_1...   \n",
              "7   /content/kraken_bentham/lines/072_049_004_04_1...   \n",
              "8   /content/kraken_bentham/lines/073_003_002_01_1...   \n",
              "9   /content/kraken_bentham/lines/071_186_002_04_0...   \n",
              "10  /content/kraken_bentham/lines/096_101_001_02_1...   \n",
              "11  /content/kraken_bentham/lines/072_052_002_03_0...   \n",
              "12  /content/kraken_bentham/lines/096_099_004_01_0...   \n",
              "13  /content/kraken_bentham/lines/072_066_003_03_0...   \n",
              "14  /content/kraken_bentham/lines/096_100_001_02_2...   \n",
              "16  /content/kraken_bentham/lines/071_111_002_04_1...   \n",
              "17  /content/kraken_bentham/lines/073_003_001_02_0...   \n",
              "18  /content/kraken_bentham/lines/097_186_001_01_2...   \n",
              "19  /content/kraken_bentham/lines/027_029_001_02_2...   \n",
              "20  /content/kraken_bentham/lines/073_068_001_03_1...   \n",
              "22  /content/kraken_bentham/lines/071_111_002_04_1...   \n",
              "23  /content/kraken_bentham/lines/116_405_001_01_1...   \n",
              "24  /content/kraken_bentham/lines/071_111_002_04_1...   \n",
              "25  /content/kraken_bentham/lines/116_405_001_01_2...   \n",
              "26  /content/kraken_bentham/lines/116_405_004_01_1...   \n",
              "27  /content/kraken_bentham/lines/073_056_001_03_0...   \n",
              "28  /content/kraken_bentham/lines/096_051_002_03_1...   \n",
              "29  /content/kraken_bentham/lines/071_188_002_03_0...   \n",
              "\n",
              "                                                   gt  \\\n",
              "1                      Of Frauds relative to the Coin   \n",
              "4               implies any such Thing . The ordinary   \n",
              "5       inserting under one Title a proposition which   \n",
              "6   stand altogether upon so good a footing :  sin...   \n",
              "7                As to the mischief there would be in   \n",
              "8    give the Reality , without contenting themselves   \n",
              "9   in general nobody can know )  , whether the le...   \n",
              "10                                    can be assigned   \n",
              "11  Offences against the external Security of the ...   \n",
              "12  if instead of the Fine we take for the Punishm...   \n",
              "13                                      Of Idleness .   \n",
              "14  would have nothing to do but to pay his third and   \n",
              "16  impostor :  the party falsely pretended to pos...   \n",
              "17        him to look for he may chance to meet under   \n",
              "18  be prevailed upon not to overstock us with the...   \n",
              "19                              ceived without them .   \n",
              "20         it might have this Inconvenience, that the   \n",
              "22  The Punishment of a Suborner shall be as follo...   \n",
              "23                                         the Jews .   \n",
              "24                                -y of an Impostor .   \n",
              "25                                from a Magistrate .   \n",
              "26     and pass the word to the Lamp-lighter , at the   \n",
              "27  a Question , by whom is it to be determined , ...   \n",
              "28  In short if we may be allowed to say what it o...   \n",
              "29  plan the order of the chapters or titles relat...   \n",
              "\n",
              "                                                 pred  char_accuracy  \\\n",
              "1                      Of Frauds relative to the Coin       1.000000   \n",
              "4                implies any such Thing . he ordinary       0.972973   \n",
              "5        inserting under one Tithe a poposition which       0.955556   \n",
              "6   stand allogether upon , so good a footing :  s...       0.950820   \n",
              "7                As to the mischif there would bhe in       0.944444   \n",
              "8      give the Reality , without ententing themselvs       0.937500   \n",
              "9   in general nobedy can know  , whether the leas...       0.933333   \n",
              "10                                    can be assignes       0.933333   \n",
              "11  Offences against the external Decurity of the ...       0.924528   \n",
              "12  if instead of the Tine we take for the Jurishm...       0.924528   \n",
              "13                                       O Idleness .       0.923077   \n",
              "14  would have nothiny 10 do But to pay his third and       0.918367   \n",
              "16  empostor  :  the party tulsels prelended to po...       0.907895   \n",
              "17       Thim to look tor be may chance to mect under       0.906977   \n",
              "18  be prevaited Spossnt to overstock us with the ...       0.906250   \n",
              "19                             ccaived without them .       0.904762   \n",
              "20        it might have this Inconvenitnce , Whak the       0.904762   \n",
              "22  The bunishment of a Jubormer shall be as tollo...       0.900000   \n",
              "23                                         the Lews .       0.900000   \n",
              "24                               7y of an Impoistor .       0.894737   \n",
              "25                                 pom a Magistrate .       0.894737   \n",
              "26     and pass the word to tha Lamp lightet , or the       0.891304   \n",
              "27   a Question , by whom is it to be determined , in       0.888889   \n",
              "28  In short of wmy allowed to vay what it ought n...       0.888889   \n",
              "29  plan the ordern of the chaptes or . litles rol...       0.882353   \n",
              "\n",
              "                                      pred_normalized  \n",
              "1                      Of Frauds relating to the Coin  \n",
              "4      implies anything. He means the ordinary thing.  \n",
              "5          inserting under one title a position which  \n",
              "6   stand altogether on such good footing: since t...  \n",
              "7   As to the mischief, there would be. (Here, \"mi...  \n",
              "8       give the Reality, without entering themselves  \n",
              "9   In general, nobody can know, whether the least...  \n",
              "10                                    can be assigned  \n",
              "11  Offenses against the external Security of the ...  \n",
              "12  if instead of the Time we take for the Jurisdi...  \n",
              "13  The correct OCR sentence should be: \"Of Idlene...  \n",
              "14  would not have had anything up to ten dollars ...  \n",
              "16  emposter: the party presented themselves as po...  \n",
              "17  Them to look for being may have a chance to me...  \n",
              "18  Be prevented, please, from overstocking us wit...  \n",
              "19                             received without them.  \n",
              "20  it might have this Convenience, That (or: it m...  \n",
              "22     The punishment of a Juror shall be as follows.  \n",
              "23                                          The Laws.  \n",
              "24                            7 years of an Imposter.  \n",
              "25  The correct OCR output should be:\\n\\n\"Before a...  \n",
              "26  And pass the word to the lamp, it will light i...  \n",
              "27        A question: By whom is it to be determined?  \n",
              "28  In short, we may not allow it to be other than...  \n",
              "29  Plan the order of the chapters or the little r...  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = df[df['gt'].str.split().str.len() >= 3]\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a111eb4a",
      "metadata": {
        "id": "a111eb4a",
        "outputId": "334e2665-caa7-4e5b-f3af-50587373effd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "GT:   Of Frauds relative to the Coin\n",
            "PRED: Of Frauds relative to the Coin\n",
            "NORM: Of Frauds relating to the Coin\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   implies any such Thing . The ordinary\n",
            "PRED: implies any such Thing . he ordinary\n",
            "NORM: implies anything. He means the ordinary thing.\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   inserting under one Title a proposition which\n",
            "PRED: inserting under one Tithe a poposition which\n",
            "NORM: inserting under one title a position which\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   stand altogether upon so good a footing :  since the distress\n",
            "PRED: stand allogether upon , so good a footing :  since the distress\n",
            "NORM: stand altogether on such good footing: since the distress\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   As to the mischief there would be in\n",
            "PRED: As to the mischif there would bhe in\n",
            "NORM: As to the mischief, there would be. (Here, \"mischief\" is a noun meaning a harmful or annoying act, and \"there would be\" is a correct form of the verb phrase \"there would be\" in the past tense.)\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   give the Reality , without contenting themselves\n",
            "PRED: give the Reality , without ententing themselvs\n",
            "NORM: give the Reality, without entering themselves\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   in general nobody can know )  , whether the least part of it\n",
            "PRED: in general nobedy can know  , whether the least part of i\n",
            "NORM: In general, nobody can know, whether the least part of I [corrected \"nobody\" to \"nobody\", added missing \"can\" and \"the\" to make a complete sentence, corrected \"nobedy\" to \"nobody\", and corrected \"can know\" to \"can know\" and \"know\" to \"know\" to maintain the original meaning and preserve the sentence structure\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   can be assigned\n",
            "PRED: can be assignes\n",
            "NORM: can be assigned\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   Offences against the external Security of the State .\n",
            "PRED: Offences against the external Decurity of the Sate\n",
            "NORM: Offenses against the external Security of the State\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   if instead of the Fine we take for the Punishment any\n",
            "PRED: if instead of the Tine we take for the Jurishment ony\n",
            "NORM: if instead of the Time we take for the Jurisdiction only.\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   Of Idleness .\n",
            "PRED: O Idleness .\n",
            "NORM: The correct OCR sentence should be: \"Of Idleness.\"\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   would have nothing to do but to pay his third and\n",
            "PRED: would have nothiny 10 do But to pay his third and\n",
            "NORM: would not have had anything up to ten dollars to pay his third installment.\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   impostor :  the party falsely pretended to possess the character in question\n",
            "PRED: empostor  :  the party tulsels prelended to possess the character in quistion\n",
            "NORM: emposter: the party presented themselves as possessing the thing in question.\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   him to look for he may chance to meet under\n",
            "PRED: Thim to look tor be may chance to mect under\n",
            "NORM: Them to look for being may have a chance to meet under.\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   be prevailed upon not to overstock us with the worst description\n",
            "PRED: be prevaited Spossnt to overstock us with the worst  description\n",
            "NORM: Be prevented, please, from overstocking us with the worst descriptions.\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   ceived without them .\n",
            "PRED: ccaived without them .\n",
            "NORM: received without them.\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   it might have this Inconvenience, that the\n",
            "PRED: it might have this Inconvenitnce , Whak the\n",
            "NORM: it might have this Convenience, That (or: it might have this inconvenience, that)\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   The Punishment of a Suborner shall be as follows :\n",
            "PRED: The bunishment of a Jubormer shall be as tollows .\n",
            "NORM: The punishment of a Juror shall be as follows.\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   the Jews .\n",
            "PRED: the Lews .\n",
            "NORM: The Laws.\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   -y of an Impostor .\n",
            "PRED: 7y of an Impoistor .\n",
            "NORM: 7 years of an Imposter.\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   from a Magistrate .\n",
            "PRED: pom a Magistrate .\n",
            "NORM: The correct OCR output should be:\n",
            "\n",
            "\"Before a Magistrate.\"\n",
            "\n",
            "Explanation:\n",
            "The OCR has incorrectly recognized \"pom\" as \"before\" and \"a\" as \"a\". To preserve the meaning of the original sentence, which appears to be introducing a quote or testimony before a magistrate, we correct it to \"Before a Magistr\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   and pass the word to the Lamp-lighter , at the\n",
            "PRED: and pass the word to tha Lamp lightet , or the\n",
            "NORM: And pass the word to the lamp, it will light it. (Assuming \"tha\" was meant to be \"the\" and \"it will lightet\" was meant to be \"it will light\")\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   a Question , by whom is it to be determined , in every\n",
            "PRED: a Question , by whom is it to be determined , in\n",
            "NORM: A question: By whom is it to be determined?\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   In short if we may be allowed to say what it ought not to be :  it ought\n",
            "PRED: In short of wmy allowed to vay what it ought not to be :  it ought\n",
            "NORM: In short, we may not allow it to be other than it ought to be: it ought\n",
            "--------------------------------------------------------------------------------\n",
            "GT:   plan the order of the chapters or titles relative to offences of the\n",
            "PRED: plan the ordern of the chaptes or . litles rolative &o oftences of the\n",
            "NORM: Plan the order of the chapters or the little relative offsets of the [content] in the document.\n"
          ]
        }
      ],
      "source": [
        "for idx, row in df.iterrows():\n",
        "    print(\"-\" * 80)\n",
        "    print(f\"GT:   {row['gt']}\")\n",
        "    print(f\"PRED: {row['pred']}\")\n",
        "    print(f\"NORM: {row['pred_normalized']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad09c858",
      "metadata": {
        "id": "ad09c858"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00712064669d4a769bdfd61ea2344f87": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "02d46a82b2cc464ca10b3df579f18568": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0515d7e119084f6996666348071a9f87": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06992f5bffd24571ba43f722de525f6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "08250e2ff455447eab3efa46f550c849": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b1683065338456390e9acbce148008a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0de671b623ff4fe5ba03644903a44822": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0f10ec3d2ca04de58f43c6a733dd748c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "11b688b8d80743a5905441a2b2c9a353": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_382633c886fb479286bbb124b2c9ebe9",
            "placeholder": "​",
            "style": "IPY_MODEL_441ff29a557d4aa986311b3575d4e520",
            "value": "generation_config.json: 100%"
          }
        },
        "154fe9aba5f54f7fa1b0f3d508c2012d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1ecde49d90c74cdabd9186a87111d18e",
              "IPY_MODEL_cdb426bf4f304b32933764890ef6a350",
              "IPY_MODEL_393fa856566d4b5bb6f3e2acbdaac0a7"
            ],
            "layout": "IPY_MODEL_fb37c2af9df3479cbbe0bc9f7e403377"
          }
        },
        "15f2635a7e6747a0ad08788125e9e62a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "160cf643a0434e17b013f135c9e67178": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a21b477112054b75be3b1da65f03ea01",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b67f52574f5441c9945206bb70900cf9",
            "value": 1
          }
        },
        "16570c56719f4bd6b6b926cc13a478d4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1940670e100e402bb464a405bf0df90d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "198f28c676f14bb19940ee061a948181": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a6ec20c59ea486ba91cdf0238b7576a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ab3a1b24adb44dcacc49b0acdff9959": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c91f0ade6e7412985e502217be2b7bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c25f2aa95d6480f955ef45c184470ec",
            "placeholder": "​",
            "style": "IPY_MODEL_d5d3b4062c2146fdbaf0645f28ced197",
            "value": " 2308/2308 [19:34&lt;00:00,  1.96 examples/s]"
          }
        },
        "1d699feee53d43aba84a3ae4f4d63af1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1e5d06e861f14f4985872863a832e902": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ecde49d90c74cdabd9186a87111d18e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd71af13c48949c7881053864d48b68f",
            "placeholder": "​",
            "style": "IPY_MODEL_fc8f1cbbd07f440e9f26d3eaed9c625b",
            "value": "model-00003-of-00003.safetensors: 100%"
          }
        },
        "242c021aa32b4f10ac9f5eb78892c7a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "24be26d6cba94780ac1fcef698281a86": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24d8f3232743437c8318da6145aee83a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2532ae7dace9406c9ae6a615958459db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55fbbc271823489e939075fca3363416",
            "placeholder": "​",
            "style": "IPY_MODEL_1ab3a1b24adb44dcacc49b0acdff9959",
            "value": "generation_config.json: 100%"
          }
        },
        "2702c0fc06c041588685efe6085f7f3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "27981b05d08b434980fa4ec52f818f3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "29ddf3b6009e49d2ad00d6cc8d3563ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0f17db4587247b786620ffb9c48fcd3",
            "placeholder": "​",
            "style": "IPY_MODEL_492aa3e2d71c420a8e09a61f3d6ef356",
            "value": " 662/662 [00:00&lt;00:00, 96.0kB/s]"
          }
        },
        "2ad787b5decf46a5bf2929ef2097fac8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77c492b539964f8da00f2d3a3c1e80ff",
            "placeholder": "​",
            "style": "IPY_MODEL_0f10ec3d2ca04de58f43c6a733dd748c",
            "value": "spiece.model: 100%"
          }
        },
        "2b4f4f259f404a1a9d3e87d223640114": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "30693954427c438a883ba97fbbd80428": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "30c43287851e4421beb3945c9c15f2c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aba0489817b340f5825f1d63baf1d355",
            "placeholder": "​",
            "style": "IPY_MODEL_5cc5310312cb4c28b85aac2ef8c0cee2",
            "value": " 792k/792k [00:01&lt;00:00, 150kB/s]"
          }
        },
        "3232b06fa890401691a3ebfbf87ae647": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "338816836a1640d6b3ed3e60e7cbcab2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_890d9563a78a4c57875523c216fc05bd",
            "max": 578,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_27981b05d08b434980fa4ec52f818f3b",
            "value": 578
          }
        },
        "3535e12f7a034b23b01ae4bb5b535a74": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e780b2fa88a41c9ae7355e40cce8bdd",
            "placeholder": "​",
            "style": "IPY_MODEL_c881962e158240a3aa370fab3973095b",
            "value": " 3/3 [00:16&lt;00:00,  5.49s/it]"
          }
        },
        "382633c886fb479286bbb124b2c9ebe9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "393fa856566d4b5bb6f3e2acbdaac0a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_704ab816284c4077a7c06e3c8c21c838",
            "placeholder": "​",
            "style": "IPY_MODEL_bd040b928d3b46219b2225d14da36023",
            "value": " 4.54G/4.54G [00:35&lt;00:00, 176MB/s]"
          }
        },
        "3ffa4c0e4d344ce4a098f41ace1bb20f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97a0741824d6409c8b233ad8289111a9",
            "placeholder": "​",
            "style": "IPY_MODEL_e09134d2078d4b8f9684b408b24f0bf5",
            "value": " 4.94G/4.94G [00:37&lt;00:00, 151MB/s]"
          }
        },
        "4066b2cd82144ff38b37e6da6eb97250": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_511fc9286973472e85ba63f6a99b2af5",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ddda57744e7b4f3abeb59bc834cd2c3b",
            "value": 1
          }
        },
        "409354a6b33f47e2a7a1198d830b6899": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "40c802a96dba49baa3237957afc814bb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "441ff29a557d4aa986311b3575d4e520": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4531b03b11394caf80aceac09342764e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bf67a88d975e4cf4b73d7966798006e3",
              "IPY_MODEL_fb07c430958c49fcbe03a927499d4afb",
              "IPY_MODEL_29ddf3b6009e49d2ad00d6cc8d3563ef"
            ],
            "layout": "IPY_MODEL_40c802a96dba49baa3237957afc814bb"
          }
        },
        "453eea230116426eba6b6ceefe1d50c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_865e6d791d4a4c229eb93cc275423164",
            "placeholder": "​",
            "style": "IPY_MODEL_5e8be2dd12d74fdaab0a92645dbde0c2",
            "value": "model-00001-of-00003.safetensors: 100%"
          }
        },
        "463c6619bb74423f95442b3a38f03840": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47c9914b007542ddaa3b8642dc8234e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9442884e0ea544b48ffc76c501cd5044",
            "placeholder": "​",
            "style": "IPY_MODEL_754471aba0d9455bb7797886054b96fb",
            "value": "Map: 100%"
          }
        },
        "488f8794555647debc027985ba101905": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "492aa3e2d71c420a8e09a61f3d6ef356": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a6306f640d04f0e93adc9290ca90268": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75987738a0bf4c22be496d7398933212",
            "placeholder": "​",
            "style": "IPY_MODEL_ab3e9bbad3dd4943935c26e4136691c1",
            "value": " 5.00G/5.00G [00:40&lt;00:00, 283MB/s]"
          }
        },
        "4aa96caa1347443ca2bf9303184a81bc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4addb0244cdd4b86a1d5dfb52040cbaf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b13492a0d3e461c80a8e1f4c3dbb696": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bc41310d2e045929fff1e8e8a686522": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4deb5dbd9e824987b9fcd54071e6767b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "511fc9286973472e85ba63f6a99b2af5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "51e104d558ba47578e4255dfc0a36d1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "524ff036b9354115b43ffe58efbbb1ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b7de93975ed4fd39cdf7b7b9103b220",
            "placeholder": "​",
            "style": "IPY_MODEL_dc5d645b9c7e460294f07409983691ab",
            "value": "model.safetensors.index.json: "
          }
        },
        "52f41bacf33d4b248fa64be7e77674d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "55db0e908da7414587eedc31e9ed050f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55fbbc271823489e939075fca3363416": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "565c8e5dac184f4196a59e1d9fc13908": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bcded2d5c6134d079dc6e3633bdc21b7",
              "IPY_MODEL_160cf643a0434e17b013f135c9e67178",
              "IPY_MODEL_5f4347215b4e4560b0f7aaa336b64050"
            ],
            "layout": "IPY_MODEL_6623617909f84cc8b52fea45d07e8663"
          }
        },
        "56b2f936545d46d7883fcf6d9de3a0fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "570ec42f4ac54424b8e62ed7d214ea1b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59013032548d4939ad8cc3e83e0e1e30": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa99ab89fcf14ad28c584c1828e172b0",
            "max": 2308,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0de671b623ff4fe5ba03644903a44822",
            "value": 2308
          }
        },
        "59639aecd1d943018780adb59cf5074f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a4d3785c73c4bdca5a73c5ab26ba5f3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cc5310312cb4c28b85aac2ef8c0cee2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5debda65471047bda8888d388d770256": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_addaaf3d0479444e972173bc96dc4ea4",
            "placeholder": "​",
            "style": "IPY_MODEL_dc0a50a72e494423bc0d23dd46c7f962",
            "value": "Map: 100%"
          }
        },
        "5df232590a7d4eb29d61768acb0ddcf4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e8be2dd12d74fdaab0a92645dbde0c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f4347215b4e4560b0f7aaa336b64050": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aaaf6168a60346c8bec54bebc7d9862e",
            "placeholder": "​",
            "style": "IPY_MODEL_52f41bacf33d4b248fa64be7e77674d2",
            "value": " 2.20k/? [00:00&lt;00:00, 283kB/s]"
          }
        },
        "6051f9a7b754496d9269e57343a01766": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60a829850d19423ebc5a5ed2df0936a8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6623617909f84cc8b52fea45d07e8663": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66b0f0b3f25c47a7bb5bf655cc85bda0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "687b77a90c8546fb9aec728e77b8e916": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_409354a6b33f47e2a7a1198d830b6899",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_02d46a82b2cc464ca10b3df579f18568",
            "value": 1
          }
        },
        "68da279ebeb74a468da07192c0901728": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5df232590a7d4eb29d61768acb0ddcf4",
            "placeholder": "​",
            "style": "IPY_MODEL_74b4222b8a784be3b7646fd1d7beb358",
            "value": " 2.54k/? [00:00&lt;00:00, 298kB/s]"
          }
        },
        "6c0e2e93980c42d49b5a9b06e149290e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b25f1fdab7134efb8536b22c9d9d0af1",
            "placeholder": "​",
            "style": "IPY_MODEL_e26470ffd9f346d8b6770ff3cb98a998",
            "value": "Map: 100%"
          }
        },
        "6db63339a46d436d89de254f494d138c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4deb5dbd9e824987b9fcd54071e6767b",
            "placeholder": "​",
            "style": "IPY_MODEL_1940670e100e402bb464a405bf0df90d",
            "value": " 147/147 [00:00&lt;00:00, 19.7kB/s]"
          }
        },
        "6e8842a2198041f9a1ccea2d5c027230": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fbce48080b74665a2de54420bfae094": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a6ec20c59ea486ba91cdf0238b7576a",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_24d8f3232743437c8318da6145aee83a",
            "value": 3
          }
        },
        "704ab816284c4077a7c06e3c8c21c838": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70b9bf493be44b9b846f429adc160e2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "718c0af6195a4b1bbb16556d0d213a66": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_453eea230116426eba6b6ceefe1d50c5",
              "IPY_MODEL_fba423628f424a2eb1814e4ed156f190",
              "IPY_MODEL_3ffa4c0e4d344ce4a098f41ace1bb20f"
            ],
            "layout": "IPY_MODEL_90f5a4d213a44f07bfbefb9f5f5a6138"
          }
        },
        "71e0f5e821fe42a7b02c2f28a11073f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2766b7e251640a2bf642175756118d7",
            "max": 3132668804,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ce8a80c5847d46fa919adfbda3dcc9a2",
            "value": 3132668804
          }
        },
        "72590a076f2f4904952877f10a2df9b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e52cb16b70364de1bfae9877d560876f",
            "placeholder": "​",
            "style": "IPY_MODEL_2702c0fc06c041588685efe6085f7f3f",
            "value": "model.safetensors: 100%"
          }
        },
        "74b4222b8a784be3b7646fd1d7beb358": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "74b661c8d2bd4283b2297a2088430eb2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "754471aba0d9455bb7797886054b96fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "75987738a0bf4c22be496d7398933212": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77c492b539964f8da00f2d3a3c1e80ff": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78446df5b14041c1aeda90e8484ee2ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e472d4168c1549e89f902510b6c21b03",
            "placeholder": "​",
            "style": "IPY_MODEL_a0c7ab3c56c14afeabb53f924660fe81",
            "value": " 3/3 [00:40&lt;00:00, 17.33s/it]"
          }
        },
        "798ac239373f469f924a4d3b2a6f476f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c25f2aa95d6480f955ef45c184470ec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ccf53a652e041bb9c3d5b2d82f99f22": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e076fc0e12549f39be0ab5aa63583dc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e08bcb2c5b444fe91dbd05a405f0639": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4bc41310d2e045929fff1e8e8a686522",
            "max": 4999819336,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_06992f5bffd24571ba43f722de525f6c",
            "value": 4999819336
          }
        },
        "7e71d68b6b21467e9a5ffe72169116d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59639aecd1d943018780adb59cf5074f",
            "max": 147,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1d699feee53d43aba84a3ae4f4d63af1",
            "value": 147
          }
        },
        "7e82844cfe9d4b368475c5d5556df0c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5debda65471047bda8888d388d770256",
              "IPY_MODEL_59013032548d4939ad8cc3e83e0e1e30",
              "IPY_MODEL_cc885ebe475f4ba3980301286579ae05"
            ],
            "layout": "IPY_MODEL_16570c56719f4bd6b6b926cc13a478d4"
          }
        },
        "7f9e59a0e28d495e8293900010f1a0db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "80fcab8023f54fe89fef526561cbe342": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2ad787b5decf46a5bf2929ef2097fac8",
              "IPY_MODEL_93edfe99d9114e7a9b714a5d17a377d1",
              "IPY_MODEL_30c43287851e4421beb3945c9c15f2c2"
            ],
            "layout": "IPY_MODEL_c222e97eadb8432c9e74d71c2221b632"
          }
        },
        "8174d06daab347ba95ff3aeaede34c32": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8511f0fd840e4126b61308abc17a353a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "851d515c4d584621a4d1bf27dab1e78d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "862e52006f2245e5b80ce79b08632202": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60a829850d19423ebc5a5ed2df0936a8",
            "max": 111,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f4d6c937ecca427aa189502c05caa753",
            "value": 111
          }
        },
        "865e6d791d4a4c229eb93cc275423164": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86655ce9dc604faab769f91c12ee6597": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3232b06fa890401691a3ebfbf87ae647",
            "placeholder": "​",
            "style": "IPY_MODEL_51e104d558ba47578e4255dfc0a36d1a",
            "value": " 2.42M/? [00:00&lt;00:00, 94.5MB/s]"
          }
        },
        "890d9563a78a4c57875523c216fc05bd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89a6bdb9d1ed4d44bcd9a89de5161eda": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8b7de93975ed4fd39cdf7b7b9103b220": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e780b2fa88a41c9ae7355e40cce8bdd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9075f9d3b1264d1692e1d9e4fa3c196a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90ea4c0eaed243d2958d63e0b769476c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "90f5a4d213a44f07bfbefb9f5f5a6138": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9136cd0a4e3f4005841cda102a2d04d4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "93edfe99d9114e7a9b714a5d17a377d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf7abfc02db743108d65e9c2cd8cfedb",
            "max": 791656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8511f0fd840e4126b61308abc17a353a",
            "value": 791656
          }
        },
        "9442884e0ea544b48ffc76c501cd5044": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95400d36f23640be8feb79a149888c57": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_851d515c4d584621a4d1bf27dab1e78d",
            "placeholder": "​",
            "style": "IPY_MODEL_242c021aa32b4f10ac9f5eb78892c7a3",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "968cdc9e91554259ba5189a8a37b3a2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bd17917c784f4cb18254b5a6eb37ffb8",
              "IPY_MODEL_ecc1fd4d2d22400d8b8a83b26de0b644",
              "IPY_MODEL_78446df5b14041c1aeda90e8484ee2ff"
            ],
            "layout": "IPY_MODEL_c22984f69d9a4daeb8633a00497771d3"
          }
        },
        "97a0741824d6409c8b233ad8289111a9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98a897aa173d4c3595fae62bbe32fb67": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc943b2f922e417689407c4b6ece0ced",
            "placeholder": "​",
            "style": "IPY_MODEL_b775cb54901b443bbed0dea74fd8a6f2",
            "value": "Map: 100%"
          }
        },
        "9c51df9fc520472e8b39bdb0ef163d47": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9faf732018594b228376117623d0ccdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e6e8e8cd0c684e89b7593b654fe6e695",
              "IPY_MODEL_c06520a8ef20448984a8d7a40a3ee76a",
              "IPY_MODEL_86655ce9dc604faab769f91c12ee6597"
            ],
            "layout": "IPY_MODEL_bf23bb8689974b788e5a99170819c261"
          }
        },
        "a0c7ab3c56c14afeabb53f924660fe81": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a21b477112054b75be3b1da65f03ea01": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "a21d35bca42c47c7a793cb81243b7ac1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2766b7e251640a2bf642175756118d7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6c6b86d70cf4753b189462bb2727077": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f27e125fd06e430796adf3a4940d82ef",
              "IPY_MODEL_7e08bcb2c5b444fe91dbd05a405f0639",
              "IPY_MODEL_4a6306f640d04f0e93adc9290ca90268"
            ],
            "layout": "IPY_MODEL_0b1683065338456390e9acbce148008a"
          }
        },
        "a6cd67abf3194f81b65688262b5ae184": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24be26d6cba94780ac1fcef698281a86",
            "placeholder": "​",
            "style": "IPY_MODEL_488f8794555647debc027985ba101905",
            "value": " 578/578 [00:14&lt;00:00, 41.21 examples/s]"
          }
        },
        "aa99ab89fcf14ad28c584c1828e172b0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aaaf6168a60346c8bec54bebc7d9862e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab3e9bbad3dd4943935c26e4136691c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aba0489817b340f5825f1d63baf1d355": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abcb5a11441b48aebafd6365693f0023": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ad95b7c4c3f24a0490ea820241ccdb67": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_47c9914b007542ddaa3b8642dc8234e1",
              "IPY_MODEL_338816836a1640d6b3ed3e60e7cbcab2",
              "IPY_MODEL_a6cd67abf3194f81b65688262b5ae184"
            ],
            "layout": "IPY_MODEL_198f28c676f14bb19940ee061a948181"
          }
        },
        "addaaf3d0479444e972173bc96dc4ea4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0f17db4587247b786620ffb9c48fcd3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b25f1fdab7134efb8536b22c9d9d0af1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b67f52574f5441c9945206bb70900cf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b775cb54901b443bbed0dea74fd8a6f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b83fa705596d4eb69ce1f3bf958b0207": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bcded2d5c6134d079dc6e3633bdc21b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55db0e908da7414587eedc31e9ed050f",
            "placeholder": "​",
            "style": "IPY_MODEL_cd012c0f10d949e2ba092ecde1221c5e",
            "value": "special_tokens_map.json: "
          }
        },
        "bd040b928d3b46219b2225d14da36023": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd17917c784f4cb18254b5a6eb37ffb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffda5f8575d04188b9aa95a1a95c48ab",
            "placeholder": "​",
            "style": "IPY_MODEL_7ccf53a652e041bb9c3d5b2d82f99f22",
            "value": "Fetching 3 files: 100%"
          }
        },
        "bf23bb8689974b788e5a99170819c261": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf67a88d975e4cf4b73d7966798006e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8174d06daab347ba95ff3aeaede34c32",
            "placeholder": "​",
            "style": "IPY_MODEL_b83fa705596d4eb69ce1f3bf958b0207",
            "value": "config.json: 100%"
          }
        },
        "c06520a8ef20448984a8d7a40a3ee76a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9136cd0a4e3f4005841cda102a2d04d4",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e4e4e792ab774db986d629aef118811d",
            "value": 1
          }
        },
        "c222e97eadb8432c9e74d71c2221b632": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c22984f69d9a4daeb8633a00497771d3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5a9015ac179460ab77b78f7a21866a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_11b688b8d80743a5905441a2b2c9a353",
              "IPY_MODEL_7e71d68b6b21467e9a5ffe72169116d9",
              "IPY_MODEL_6db63339a46d436d89de254f494d138c"
            ],
            "layout": "IPY_MODEL_0515d7e119084f6996666348071a9f87"
          }
        },
        "c5cff8b50d8543868a39fbd12cc4cfef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_95400d36f23640be8feb79a149888c57",
              "IPY_MODEL_6fbce48080b74665a2de54420bfae094",
              "IPY_MODEL_3535e12f7a034b23b01ae4bb5b535a74"
            ],
            "layout": "IPY_MODEL_f0b4823e6ba34baba573c51aba575bc8"
          }
        },
        "c752b4f749214b4abc9571959f26887f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6051f9a7b754496d9269e57343a01766",
            "placeholder": "​",
            "style": "IPY_MODEL_798ac239373f469f924a4d3b2a6f476f",
            "value": " 111/111 [00:00&lt;00:00, 15.0kB/s]"
          }
        },
        "c881962e158240a3aa370fab3973095b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc885ebe475f4ba3980301286579ae05": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9075f9d3b1264d1692e1d9e4fa3c196a",
            "placeholder": "​",
            "style": "IPY_MODEL_7f9e59a0e28d495e8293900010f1a0db",
            "value": " 2308/2308 [00:58&lt;00:00, 39.49 examples/s]"
          }
        },
        "cd012c0f10d949e2ba092ecde1221c5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cdb426bf4f304b32933764890ef6a350": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f03f3a59e40249b8a68cdaf7afb7e859",
            "max": 4540516344,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_89a6bdb9d1ed4d44bcd9a89de5161eda",
            "value": 4540516344
          }
        },
        "ce8a80c5847d46fa919adfbda3dcc9a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cf7abfc02db743108d65e9c2cd8cfedb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3d94713732249ccb29069c1da9c1283": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5d3b4062c2146fdbaf0645f28ced197": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d8aa4bf50f204576a494c660ad8239b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6c0e2e93980c42d49b5a9b06e149290e",
              "IPY_MODEL_dac9243c67db420f97a6e5ae881339bb",
              "IPY_MODEL_1c91f0ade6e7412985e502217be2b7bd"
            ],
            "layout": "IPY_MODEL_5a4d3785c73c4bdca5a73c5ab26ba5f3"
          }
        },
        "dac9243c67db420f97a6e5ae881339bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66b0f0b3f25c47a7bb5bf655cc85bda0",
            "max": 2308,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_abcb5a11441b48aebafd6365693f0023",
            "value": 2308
          }
        },
        "dc0a50a72e494423bc0d23dd46c7f962": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dc5d645b9c7e460294f07409983691ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd71af13c48949c7881053864d48b68f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddda57744e7b4f3abeb59bc834cd2c3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "df35567881554e70b6abea545a0f4bdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b13492a0d3e461c80a8e1f4c3dbb696",
            "placeholder": "​",
            "style": "IPY_MODEL_fe866cc181424624915fd0b530e3ceed",
            "value": " 3.13G/3.13G [00:10&lt;00:00, 524MB/s]"
          }
        },
        "e09134d2078d4b8f9684b408b24f0bf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e0ae03d3865348af83a9c7bced5c913a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e076fc0e12549f39be0ab5aa63583dc",
            "placeholder": "​",
            "style": "IPY_MODEL_56b2f936545d46d7883fcf6d9de3a0fe",
            "value": " 25.1k/? [00:00&lt;00:00, 2.85MB/s]"
          }
        },
        "e26470ffd9f346d8b6770ff3cb98a998": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e465134688054fe79ea0534aef0f855c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e472d4168c1549e89f902510b6c21b03": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4e4e792ab774db986d629aef118811d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e509163200f247d290e250795f376ac0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15f2635a7e6747a0ad08788125e9e62a",
            "placeholder": "​",
            "style": "IPY_MODEL_9c51df9fc520472e8b39bdb0ef163d47",
            "value": "tokenizer_config.json: "
          }
        },
        "e52cb16b70364de1bfae9877d560876f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6e8e8cd0c684e89b7593b654fe6e695": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a21d35bca42c47c7a793cb81243b7ac1",
            "placeholder": "​",
            "style": "IPY_MODEL_f7ae9d4c043e4eb3b37c1553ade4d014",
            "value": "tokenizer.json: "
          }
        },
        "e7abf648439e41eda193f44004fe8ea7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e509163200f247d290e250795f376ac0",
              "IPY_MODEL_4066b2cd82144ff38b37e6da6eb97250",
              "IPY_MODEL_68da279ebeb74a468da07192c0901728"
            ],
            "layout": "IPY_MODEL_6e8842a2198041f9a1ccea2d5c027230"
          }
        },
        "e87a388ea9cb46c58098ec0024227cf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc7c6197eb3c47b79edf69bb5c2a026b",
            "placeholder": "​",
            "style": "IPY_MODEL_90ea4c0eaed243d2958d63e0b769476c",
            "value": " 578/578 [04:53&lt;00:00,  1.97 examples/s]"
          }
        },
        "ecc1fd4d2d22400d8b8a83b26de0b644": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4addb0244cdd4b86a1d5dfb52040cbaf",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_00712064669d4a769bdfd61ea2344f87",
            "value": 3
          }
        },
        "efbb79ed63ad449c8c8df184c2343358": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2532ae7dace9406c9ae6a615958459db",
              "IPY_MODEL_862e52006f2245e5b80ce79b08632202",
              "IPY_MODEL_c752b4f749214b4abc9571959f26887f"
            ],
            "layout": "IPY_MODEL_570ec42f4ac54424b8e62ed7d214ea1b"
          }
        },
        "f03f3a59e40249b8a68cdaf7afb7e859": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0b4823e6ba34baba573c51aba575bc8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f16ea1d3844540c59ced5e42f8386ce1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4aa96caa1347443ca2bf9303184a81bc",
            "max": 578,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_faeb9b7259c2497c9a77b831be22366e",
            "value": 578
          }
        },
        "f27e125fd06e430796adf3a4940d82ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e465134688054fe79ea0534aef0f855c",
            "placeholder": "​",
            "style": "IPY_MODEL_2b4f4f259f404a1a9d3e87d223640114",
            "value": "model-00002-of-00003.safetensors: 100%"
          }
        },
        "f28d25b4bd044702bba2b44e0bcc961e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_98a897aa173d4c3595fae62bbe32fb67",
              "IPY_MODEL_f16ea1d3844540c59ced5e42f8386ce1",
              "IPY_MODEL_e87a388ea9cb46c58098ec0024227cf4"
            ],
            "layout": "IPY_MODEL_08250e2ff455447eab3efa46f550c849"
          }
        },
        "f4d6c937ecca427aa189502c05caa753": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f74251c42cc848b1bae2f05aa1e08000": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_72590a076f2f4904952877f10a2df9b9",
              "IPY_MODEL_71e0f5e821fe42a7b02c2f28a11073f9",
              "IPY_MODEL_df35567881554e70b6abea545a0f4bdd"
            ],
            "layout": "IPY_MODEL_74b661c8d2bd4283b2297a2088430eb2"
          }
        },
        "f7ae9d4c043e4eb3b37c1553ade4d014": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "faeb9b7259c2497c9a77b831be22366e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fb07c430958c49fcbe03a927499d4afb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_463c6619bb74423f95442b3a38f03840",
            "max": 662,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_70b9bf493be44b9b846f429adc160e2d",
            "value": 662
          }
        },
        "fb37c2af9df3479cbbe0bc9f7e403377": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fba423628f424a2eb1814e4ed156f190": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3d94713732249ccb29069c1da9c1283",
            "max": 4943162336,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_30693954427c438a883ba97fbbd80428",
            "value": 4943162336
          }
        },
        "fbfa0c85f1564937ae2a1509f8eced4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_524ff036b9354115b43ffe58efbbb1ce",
              "IPY_MODEL_687b77a90c8546fb9aec728e77b8e916",
              "IPY_MODEL_e0ae03d3865348af83a9c7bced5c913a"
            ],
            "layout": "IPY_MODEL_1e5d06e861f14f4985872863a832e902"
          }
        },
        "fc7c6197eb3c47b79edf69bb5c2a026b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc8f1cbbd07f440e9f26d3eaed9c625b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc943b2f922e417689407c4b6ece0ced": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe866cc181424624915fd0b530e3ceed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ffda5f8575d04188b9aa95a1a95c48ab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}